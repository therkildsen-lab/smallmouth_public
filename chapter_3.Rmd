# import R libraries, data from the AFRP database, and genotypes
```{r}
    library(tidyverse)
    library(poppr)
    library(readxl)
    library(cowplot)
    library(igraph)
    library(hierfstat)

base_dir <- '/workdir/smallmouth/ecological/AFRP_MAIN_121923'

ordered_amplicons<-read_csv('/workdir/smallmouth/gtseq/all_regions_primers_ordered.csv')

# import allFish
    allFish<- read_csv('/workdir/smallmouth/ecological/allFish.csv.gz')

# import snorkel data from 2021 and 2022
    snorkel<-googlesheets4::read_sheet('https://docs.google.com/spreadsheets/d/1CJVikWmzlmv0qOtG2X1iLUyslgiJ-4vmgUSnjVO_NcU/edit#gid=0', sheet = 'Sheet1')

# read in which primers were excluded for each round
    primers_excluded<-read_tsv('/workdir/smallmouth/gtseq/sequencing/primer_exlucsion_pool.tsv')
  
# My imported funciton to say not in
    `%nin%` = Negate(`%in%`)

# lML lake path
    lake_edge<-read_csv('/workdir/smallmouth/ecological/Location_LML_05-22.csv', skip=4) %>% dplyr::rename('LONG'='Longitude', 'LAT' = 'Latitude')

# First, read in all the fish I've genotyped
    allGenotyped_1<-read_xlsx('/workdir/smallmouth/gtseq/AdkLabNotebook_gtseq.xlsx', sheet = 'samples_production_1') %>% 
      filter(!str_detect(extraction_plate, '5|6|9')) %>%  # remove the plates I haven't sequenced 
      dplyr::select(GENID, GEN_N, FISH_N, tissue_source,tissue_type, extraction_type, extraction_plate, extraction_column, extraction_row) %>% 
      mutate(GENID_duplicate = paste0('gtseq_production_1--', GENID))
    
    allGenotyped<-read_xlsx('/workdir/smallmouth/gtseq/AdkLabNotebook_gtseq.xlsx', sheet = 'samples_production_2') %>% 
      dplyr::select(GENID, GEN_N, FISH_N, OLD_FISH_N, tissue_source,tissue_type, extraction_type, extraction_plate, extraction_column, extraction_row) %>% 
      mutate(GENID_duplicate = paste0('gtseq_production_2--', GENID)) %>% 
      bind_rows(allGenotyped_1) %>% 
      separate(GENID, into = c('GENID','duplicate'), sep = '-')
    
  # Then read in all snorkel data, with GPS points as lat and lon
      snorkel_genid<-snorkel %>% 
        mutate(WAYPOINT = paste0(year, '__', as.character(WAYPOINT)), # some duplicates in waypoint, so adding year to it
               ESTIMATED_TL = as.double(as.character(ESTIMATED_TL)), 
               TRANSECT = as.character(TRANSECT),
               NEST_WIDTH = as.double(as.character(NEST_WIDTH)),
               NEST_DEPTH = as.double(as.character(NEST_DEPTH))) %>% 
        pivot_longer(c(NEST_GEN_1, NEST_GEN_2, FISH_GEN), names_to = 'SAMPLE', values_to = 'GENID') %>% 
        filter(!is.na(GENID)) %>% dplyr::select(-c(NEST_DESTROYED, SUCCESSFUL, NOTES)) %>% 
        mutate(ESTIMATED_TL_parent = if_else(str_detect(SAMPLE, 'NEST'), as.double(ESTIMATED_TL), NA_real_), # set the estimated TL to be paret or adult
               ESTIMATED_TL_fish = if_else(str_detect(SAMPLE, 'FISH'), as.double(ESTIMATED_TL), NA_real_)) %>% 
        dplyr::select(-ESTIMATED_TL)
      
  # Splitting this up into several different categories depending on where data is stored
      
      # fish collected via snorkling (only have GENID's) - will have to deal with duplicates
      GENIDs<-filter(allGenotyped, str_detect(GENID_duplicate, "SMB_22_|2021_|SMB_2023")) %>%
        left_join(snorkel_genid, by = 'GENID') 
 
      # fish with GEN_N's, filling in missing WATER and year 
      GEN_Ns<-filter(allGenotyped, (GEN_N != 'NA' & is.na(FISH_N)), GENID %nin% GENIDs$GENID) %>% # , !duplicated(GEN_N)
        dplyr::select(-FISH_N) %>% 
        left_join(allFish, by = 'GEN_N') %>% 
        mutate(WATER = if_else(is.na(WATER) & str_detect(GEN_N, 'WLL'), 'WLL',
                       if_else(is.na(WATER) & str_detect(GEN_N, 'TBL'), 'TBL',
                       if_else(is.na(WATER) & str_detect(GEN_N, 'SBL'), 'SBL',
                       if_else(is.na(WATER) & str_detect(GEN_N, 'SDL'), 'SDL',
                       if_else(is.na(WATER) & str_detect(GENID, 'LML'), 'LML', WATER)))))) %>% 
        mutate(year =  if_else(is.na(year) & str_detect(GENID, '22_'), as.numeric(2022),
                       if_else(is.na(year) & str_detect(GENID, '19_'), as.numeric(2019),
                       if_else(is.na(year) & (str_detect(GENID, '_F') | str_detect(GENID, '_E')), as.numeric(2019), 
                       if_else(is.na(year) & str_detect(GEN_N, '19.'), as.numeric(2019), year)))))
      
      # The special speared fish joiner  
      speared<-googlesheets4::read_sheet('https://docs.google.com/spreadsheets/d/1CJVikWmzlmv0qOtG2X1iLUyslgiJ-4vmgUSnjVO_NcU/edit#gid=0', sheet = 'speared_fish_joiner') %>% 
        dplyr::select(GENID, GENID, GEN_N) %>% 
        left_join(dplyr::select(GENIDs, GENID, duplicate, tissue_source, tissue_type, extraction_type, GENID_duplicate, year, WATER, WAYPOINT, LONG, LAT, EARLIEST_DATE, SAMPLE, ESTIMATED_TL_parent, ESTIMATED_TL_fish, NEST_WIDTH, NEST_DEPTH, EARLIEST_STAGE), by = 'GENID') %>% 
        left_join(dplyr::select(GEN_Ns, GEN_N, FISH_N, GEAR, LENGTH, WEIGHT, GONAD_WEIGHT, newGSI, sex, ageLengthed, birthYr, yearly_length_anomaly), by = 'GEN_N')

      # put in OLD_FISH_N's
      OLD_FISH_Ns<-filter(allGenotyped, !is.na(OLD_FISH_N)) %>% dplyr::select(-FISH_N) %>% 
        filter(OLD_FISH_N != 'LML.061603.BEF.001.001') %>% # This one links with 2 FISH_N's
        left_join(read_csv('/workdir/smallmouth/ecological/AFRP_MAIN_121923/FISH_N.txt'), by = 'OLD_FISH_N') %>% 
        dplyr::select(-c(OLD_FISH_N, RECALC_FISH_N, MEASUREMENT_DATA, GEN_N)) %>% 
        left_join(allFish, by = 'FISH_N')
    
      # fish with only FISH_N's (no genN's)
      FISH_Ns<-filter(allGenotyped, FISH_N != 'NA') %>% # , !duplicated(FISH_N)
        dplyr::select(-GEN_N) %>% 
        left_join(allFish, by = 'FISH_N') %>% 
        left_join(read_csv('/workdir/smallmouth/ecological/results/FISH_N_empty.csv'), by = 'FISH_N') %>% 
        mutate(WATER = if_else(is.na(WATER) & str_detect(FISH_N, 'WLL'), 'WLL',
                       if_else(is.na(WATER) & str_detect(FISH_N, 'LML'), 'LML', WATER))) %>% 
                mutate(year =  if_else(is.na(year) & str_detect(GENID, '99_'), as.numeric(1999),
                               if_else(is.na(year) & str_detect(GENID, '00_'), as.numeric(2000),
                               if_else(is.na(year) & str_detect(GENID, '01_'), as.numeric(2001),
                               if_else(is.na(year) & str_detect(GENID, '04_'), as.numeric(2004),
                               if_else(is.na(year) & str_detect(GENID, '20_'), as.numeric(2020),
                               if_else(is.na(year) & str_detect(GENID, '23_'), as.numeric(2023),year)))))))
      
      # fish that have no FISH_N, GEN_N, snorkel - aka the pre 2002 fish
      scale_data<-read_xlsx('/workdir/smallmouth/gtseq/scale_envelope_data_1950s_on.xlsx', sheet = 'clean')  %>% 
        mutate(LENGTH = as.double(LENGTH), WEIGHT = as.double(WEIGHT), ageTrue = as.double(ageTrue)) %>% 
        filter(!is.na(GENID)) %>% 
        dplyr::select(-c(FISH_N, WATER))
      
      NO_FISHN_GENN<-filter(allGenotyped, is.na(FISH_N), is.na(GEN_N), GENID %nin% GENIDs$GENID, is.na(OLD_FISH_N)) %>% 
        left_join(dplyr::select(read_xlsx('/workdir/smallmouth/gtseq/AdkLabNotebook_gtseq.xlsx', sheet = 'samples_production_2'), GENID, WATER, year), by = 'GENID') %>% 
        mutate(year = as.double(year)) %>% 
        full_join(scale_data, by = 'GENID')
      
            
      # remove the speared fish from GEN_Ns and snorkel and nofishngennn
      GEN_Ns<-filter(GEN_Ns, GEN_N %nin% speared$GEN_N)
      GENIDs<-filter(GENIDs, GENID %nin% speared$GENID)
      NO_FISHN_GENN<-filter(NO_FISHN_GENN, GENID %nin% speared$GENID)

 phenos<-
    bind_rows(GEN_Ns, FISH_Ns, GENIDs, OLD_FISH_Ns, NO_FISHN_GENN, speared) %>% 
    mutate(birthYr = if_else(str_detect(GENID, 'SMB_22_') & str_detect(SAMPLE, "NEST_GEN"), 2022, # here, adding birth year to snorkel
                     if_else(str_detect(GENID, '2021_')   & str_detect(SAMPLE, "NEST_GEN"), 2021, 
                     if_else(str_detect(GENID, 'SMB_23_') & str_detect(SAMPLE, "NEST_GEN"), 2023, birthYr))),
           eggD = lubridate::yday(EARLIEST_DATE),
             eggDate = if_else(EARLIEST_STAGE == 'Egg', eggD,
                               if_else(EARLIEST_STAGE=='Grey',eggD-4,
                                       if_else(EARLIEST_STAGE=='Black', eggD-8, NA_real_)))) %>% 
   dplyr::select(-eggD) %>% 
   mutate(GENID_duplicate = str_replace(GENID_duplicate, '__','--'))
 
# alternative to microhaps - amplicon.py
  genos_withdups<-read_csv('/workdir/backup/smallmouth/gtseq_production_2/amp_py_output/hap_genotype_read_depth.csv') %>% 
    filter(read_depth > 15) %>% 
    left_join(dplyr::rename(ordered_amplicons, 'locus'='microhap_name'), by = 'locus')
  
  n_loc_total<-length(unique(genos_withdups$locus))
  
# Exclude duplicated individuals from genos
    exclude_duped<- genos_withdups %>% 
      group_by(GENID_duplicate) %>% 
      tally() %>%  # make a list of duplicated fish to exclude
      ungroup() %>% 
      left_join(phenos, by = 'GENID_duplicate') %>% 
      group_by(GENID) %>% 
      mutate(n_dups=n()) %>% 
      filter(n_dups>1) %>%  # first get all duplicated
      arrange(GENID, desc(n)) %>% 
      slice_tail(n=-1) %>%  # Then make a list of all but the top scoring individual - this is the list to exclude
      ungroup() 

    genos<-genos_withdups %>% 
      filter(GENID_duplicate %nin% exclude_duped$GENID_duplicate)
    
    n_inds<-length(unique(genos$GENID_duplicate))

# read in microhaplot SNP data, exlcuding duplicated individuals, contam inds, and paralogs
    microhap_snp<-
      read_csv('/workdir/smallmouth/gtseq/microhaplot/snp_report_gtseq_production_2_depth15.csv') %>% 
      filter(indiv.ID %in% mutate(genos, GENID_duplicate = str_replace(GENID_duplicate, '--', '__'))$GENID_duplicate,
             locus %nin% read_csv('/workdir/smallmouth/gtseq/results/paralogs.csv')$contig,
             ar>0.2) %>% # exclude contaminated & paralogs, and loci not in the genos (read depth)
      filter(!str_detect(snp, 'N')) %>% 
      mutate(locus=paste0(locus, '-pos', pos)) %>% # make a new name
      group_by(locus) %>% 
      mutate(allele_count_per_locus = length(unique(snp))) %>% 
      filter(allele_count_per_locus>1) %>% 
      ungroup() %>%  # removed fixed SNPs
      separate(snp, into=c('snp1','snp2'), sep = '/', remove = F) %>% 
      rowwise() %>% 
      mutate(genoty=paste0(sort(c(snp1,snp2)),collapse='/')) %>% 
      ungroup() %>% # arrange by alphabet
      dplyr::select(GENID_duplicate=indiv.ID, locus, genoty)
    
    n_inds<-length(unique(microhap_snp$GENID_duplicate))
    
    microhap_snp<-microhap_snp %>% 
      group_by(locus) %>% mutate(prop_inds_scoring = n()/n_inds) %>% 
      filter(prop_inds_scoring > 0.7) %>% 
      ungroup()

# code genotypes as 0,1,2
    mhap_AlleleIdx<-separate(microhap_snp, genoty, into = c('hap1', 'hap2'), sep = '/') %>% 
      pivot_longer(-c(locus, GENID_duplicate, prop_inds_scoring), names_to = 'gene_copy', values_to = 'allele') %>% 
      filter(!is.na(allele), allele != '', allele != 'N') %>% 
      group_by(locus, allele) %>%
      tally() %>%
      filter(!is.na(allele)) %>%
      mutate(Freq = n / sum(n)) %>%
      arrange(locus, desc(Freq)) %>%
      dplyr::select(-n) %>%
      ungroup() %>% group_by(locus) %>% mutate(n=n()) %>% filter(n == 2) %>% 
      mutate(AlleIdx = c(1,0)) %>% # statgenGWAS expects minor allele to be a 0
      ungroup() %>% 
      dplyr::select(-c(Freq,n))
    
    microhap_snp<-separate(microhap_snp, genoty, into = c('allele','allele2'), sep ='/', remove = F) %>% 
      left_join(mhap_AlleleIdx, by = c('locus','allele')) %>% 
      dplyr::rename(allele_1=allele, AlleIdx_1=AlleIdx, allele=allele2) %>% 
      left_join(mhap_AlleleIdx, by = c('locus','allele')) %>% 
      dplyr::rename(allele_2=allele, AlleIdx_2=AlleIdx) %>% 
      mutate(AlleIdx_genoty=AlleIdx_1+AlleIdx_2,
             GENID_duplicate = str_replace(GENID_duplicate, '__', '--'))

# make a genind object of the neutral markers in Little Moose
    genos_neutral<-genos %>% 
      left_join(dplyr::select(phenos, GENID_duplicate, year, WATER), by = 'GENID_duplicate') %>% 
      filter(str_detect(WATER, 'LML'),
             str_detect(locus, 'parentage')) %>%
      dplyr::select(locus, GENID_duplicate, genoty, year) %>% 
      pivot_wider(names_from=locus, values_from=genoty) %>% 
      dplyr::rename(ind=GENID_duplicate, pop=year)
    
    obj_preLD_pre_HWE<-df2genind(dplyr::select(genos_neutral, -c(ind, pop)), sep = '/', ploidy = 2, ncode = 2, ind.names = as.character(genos_neutral$ind), pop = as.character(genos_neutral$pop)) %>% 
      missingno('loci',0.3) %>% 
      missingno('geno', 0.3)
  
# set strata
    strata.df<-tibble(pops = obj_preLD_pre_HWE$pop) 
    strata(obj_preLD_pre_HWE) <- strata.df
    
# exclude loci out of HWE in over 50% of pops
    failed_hwe<-read_csv('/workdir/smallmouth/gtseq/results/loci_failing_hwe_over_50_percent_years.csv')
    obj<- obj_preLD_pre_HWE[loc = setdiff(locNames(obj_preLD_pre_HWE), failed_hwe$locus)]
    
# exclude loci that showed greater than rbarD 0.8, after removing closely related individuals
    failed_ld<-read_csv('/workdir/smallmouth/gtseq/results/loci_parentage_ld_exclude.csv')
    obj<- obj[loc = setdiff(locNames(obj), failed_ld$value)]

# Add the site info for missing fish. I just ran this for the fish which had scoring genotypes and are in the obj file above
    site_manual<-googlesheets4::read_sheet('https://docs.google.com/spreadsheets/d/1CJVikWmzlmv0qOtG2X1iLUyslgiJ-4vmgUSnjVO_NcU/edit#gid=0', sheet = 'missing_site_n_fish_joiner') %>% 
      dplyr::select(GENID, SITE_INPUT) %>% 
      filter(!is.na(SITE_INPUT)) %>% 
      mutate(SITE_INPUT = paste0('BEF.LML.', str_pad(SITE_INPUT, 3, pad = "0")))
    
    phenos<-left_join(phenos, site_manual, by = 'GENID') %>% 
      mutate(SITE_N_NEW = coalesce(SITE_N_NEW, SITE_INPUT)) %>% 
      dplyr::select(-SITE_INPUT)
    
# clean up the lat and long from the site and the snorkels, respectively. also, add habitat. needed to convert with terra package from UTM to lat/long
    site_info<-read_csv('/workdir/smallmouth/ecological/AFRP_MAIN_121923/SITES.txt')
    
    site_convert<-dplyr::select(site_info, x = E_UTM, y = N_UTM) %>% 
      as.matrix()
    
    v<-terra::vect(site_convert, crs="+proj=utm +zone=18")
    
    y <- terra::project(v, "+proj=longlat")
    
    site_info_lat_lon<-terra::geom(y)[, c("x", "y")] %>% 
      as_tibble() %>% 
      bind_cols(site_info) %>% 
      dplyr::select(SITE_N_NEW = SITE_N, long_site = x, lat_site = y, habitat_site = HAB_1) %>% 
      mutate(long_site = if_else(SITE_N_NEW == 'BEF.LML.031', -74.931601, long_site), # site 31 is in a weird place - re-locating
        lat_site = if_else(SITE_N_NEW == 'BEF.LML.031', 43.694035, lat_site))

    phenos<-left_join(phenos, site_info_lat_lon, by = 'SITE_N_NEW') %>% 
      rename(long_snorkel = LONG, lat_snorkel = LAT)
    
# adjacent site information
    adj_sites<-googlesheets4::read_sheet('https://docs.google.com/spreadsheets/d/1CJVikWmzlmv0qOtG2X1iLUyslgiJ-4vmgUSnjVO_NcU/edit#gid=0', sheet = 'adjacent_sites')
    
# read in the distance between each site in LML, both by # of sites and by meters
    dist_out<-read_csv('/workdir/smallmouth/gtseq/results/distance_between_sites_lml.csv') %>% 
      rowwise() %>% 
      mutate(site12 = paste0(sort(c(site1,site2)), collapse = '-')) %>% 
      ungroup() %>% 
      dplyr::select(-c(site1,site2))
    
# add the two adaptive genotypes into phenos
    phenos<-
      microhap_snp %>% 
      filter(locus == 'adaptive_lg19_12740897-pos201' | locus == 'adaptive_lg6_3256886-pos201') %>% 
      dplyr::select(GENID_duplicate, locus, genoty) %>% 
      mutate(locus = if_else(str_detect(locus, 'lg19'), 'chr19','chr6')) %>% 
      pivot_wider(names_from=locus, values_from = genoty) %>% 
      right_join(phenos, by = 'GENID_duplicate') %>% 
      mutate(chr19_idx = if_else(chr19 == 'A/A', 0, 
                                if_else(chr19 == 'A/C', 1, 2))) %>% 
      mutate(chr6_idx = if_else(chr6 == 'C/C', 0,
                                if_else(chr6 == 'C/T', 1, 2)))
    
# Make another column for the snorkel fish to coalesce TL
    phenos<-phenos %>% 
      mutate(TL = coalesce(ESTIMATED_TL_fish, ESTIMATED_TL_parent))
    
# make a clean site info column
    phenos<-phenos %>% 
      mutate(site = if_else(WATER == 'LML', as.integer(str_replace(SITE_N_NEW, 'BEF.LML.', '')), NA_integer_)) 

# add the synthetic nest characteristics axis
    phenos<-phenos %>% 
      left_join(read_csv('/workdir/smallmouth/gtseq/results/synth_axis.csv'), by = 'GENID_duplicate')
    
# generate estimated birth years and ages at capture
    phenos<-phenos %>% 
      filter(WATER == 'LML') %>%
      mutate(LENGTH = coalesce(LENGTH, ESTIMATED_TL_fish)) %>% # include the field-based estimates of length. sd = 50mm
      left_join(read_csv('/workdir/smallmouth/gtseq/results/lml_alk_spring.csv'), by = 'year') %>% 
      mutate(alk_age = if_else(LENGTH < max1, 1,
                               if_else(data.table::between(LENGTH, min2, max2,  NAbounds = NA), 2,
                                       if_else(data.table::between(LENGTH, min3, max3,  NAbounds = NA), 3,
                                               if_else(data.table::between(LENGTH, min4, max4,  NAbounds = NA), 4,
                                                       if_else(data.table::between(LENGTH, min5, max5,  NAbounds = NA), 5, NA_real_))))),
             age0 = if_else((str_detect(GENID, 'SMB_2023') | str_detect(GENID, '2021_') | str_detect(GENID, 'SMB_22')) & str_detect(SAMPLE, 'NEST'), 0, NA_real_),
             age3 = if_else(str_detect(SAMPLE, 'FISH'), 3, NA_real_),
             predict_age = coalesce(ageTrue, ageLengthed, alk_age, age0, age3),
             predict_age = if_else(GENID == 'GEN_SMB_LML_052919_031', 2, 
                                   if_else(GENID == 'SMB_LML_061720_RANG_001', 2,
                                   if_else(GENID == 'LML_052203_BEF_014_001', 4, predict_age))),
             predict_birthYr = year - predict_age) %>% 
        dplyr::select(GENID_duplicate, predict_birthYr, predict_age) %>% 
        right_join(phenos, by = 'GENID_duplicate')

# make a list of families from ckmr-sim
    build_fams<-read_csv('/workdir/smallmouth/gtseq/results/FS_potential.csv') %>% 
      filter(confirmed==1) %>% 
      bind_rows(filter(read_csv('/workdir/smallmouth/gtseq/results/PO_potential.csv'), confirmed==1)) %>% 
      dplyr::select(d1 = GENID_duplicate_D1_indiv, d2 = GENID_duplicate_D2_indiv)
    
    g3<-simplify(graph.data.frame(build_fams[order(build_fams[[1]]),], directed = F))

    obj_fams<-components(g3)$membership %>% 
      as_tibble(rownames = 'GENID_duplicate') %>% 
      right_join(filter(phenos, GENID_duplicate %in% indNames(obj))) %>% 
      arrange(value) %>% 
      mutate(fam_index = if_else(is.na(value), as.double(row_number()), value), # add sequential numbers
             fam_index = as.double(as.factor(fam_index)))
    
loci_selected<-c('adaptive_lg19_12740897-pos201', 'adaptive_lg6_3256886-pos201') #, 'adaptive_lg7_25601423-pos157')
```

# Quality control

## Negative controls

```{r, warning=F, message=F, error=F, echo=F}
  genos %>% 
    filter(str_detect(GENID, "CONTROL")) %>% tally()
```

## Tissue type, extraction, and storage methods

```{r, warning=F, message=F, error=F, echo=F}
# first, read in the snorkel data with GPS points as latitude and longitude. Then, rename snorkel collected tissues as egg, grey, fin, ect
  # Then read in all snorkel data, with GPS points as lat and lon
      snork<-snorkel %>% mutate(WAYPOINT = as.character(WAYPOINT), ESTIMATED_TL = as.character(ESTIMATED_TL)) %>% 
        pivot_longer(c(NEST_GEN_1, NEST_GEN_2, FISH_GEN), names_to = 'SAMPLE', values_to = 'GENID') %>% 
        filter(!is.na(GENID)) %>% 
        mutate(SAMPLE=if_else(SAMPLE=='FISH_GEN', 'fin', EARLIEST_STAGE)) %>% 
        dplyr::select(GENID, SAMPLE)

# read in the unfiltered genotypes
    genos_noFilt<-read_csv('/workdir/smallmouth/gtseq/microhaplot/reported_diploid_haplotype_gtseq_production_1.csv') %>% 
        filter(read.depth.1>30 & read.depth.2 > 30 & ar > 0.2) %>% 
        mutate(read_depth = if_else(is.na(read.depth.2), read.depth.1, (read.depth.1+read.depth.2)),
               genotyped = 1) %>% 
        group_by(locus) %>% mutate(n_inds_nonNA=n()) %>% ungroup() %>% filter(indiv.ID !='unknown') %>% 
        rename(GENID=indiv.ID) %>% 
        anti_join(read_csv('/workdir/smallmouth/gtseq/results/contaminated_inds.csv'), by = 'GENID') %>%   # exclude contaminated inds
        anti_join(read_csv('/workdir/smallmouth/gtseq/results/paralog_loci.csv')) %>% # exclude loci showing 3+ alleles, paralog in some pops
        left_join(rename(ordered_amplicons, 'locus'='microhap_name'), by = 'locus')

# read in data on all the fish I've genotyped
    allGenotyped<-read_xlsx('/workdir/smallmouth/gtseq/AdkLabNotebook_gtseq.xlsx', sheet = 'samples_production') %>% 
      filter(!str_detect(`extraction Plate`, '5'), !str_detect(`extraction Plate`, '6'), !str_detect(`extraction Plate`, '9')) %>%  # remove the plates I haven't sequenced 
      dplyr::select(GENID, GEN_N, FISH_N, `tissue source`,`tissue type`, extractionType, `extraction Plate`, extractioncolumn, `extraction Row`)

#  bring this all together
    prop_scoring_tiss_extract<-group_by(genos_noFilt, GENID) %>% 
      summarise(propLoc = n()/length(unique(genos_noFilt$locus))) %>% 
      ungroup() %>% 
      right_join(allGenotyped, by = 'GENID') %>% left_join(snork, by = 'GENID') %>% 
      mutate(propLoc = if_else(is.na(propLoc), 0, propLoc),
        tiss = if_else(!is.na(SAMPLE), paste0(`tissue source`, '-',SAMPLE), paste0(`tissue source`, '-',`tissue type`))) %>% 
      dplyr::select(GENID,tiss, extractionType, propLoc)

# plot
    group_by(prop_scoring_tiss_extract, extractionType, tiss) %>% summarise(`Proportion\nscoring\nloci` = mean(propLoc), n= n()) %>% 
      filter(!is.na(extractionType), extractionType != 'NA') %>% 
      ggplot(aes(extractionType, tiss, fill = `Proportion\nscoring\nloci`)) + geom_tile() + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + scale_fill_continuous(type = "viridis")  + geom_text(aes(label=n)) + labs(x = 'extraction type', y = 'tissue type and storage method')
#ggsave('/workdir/smallmouth/gtseq/results/extractionMethod_tissueType_success_tile.png', width = 8, height=5)

# color all plates by proportion locus success
    left_join(prop_scoring_tiss_extract, allGenotyped, by = 'GENID') %>% 
      filter(tiss == 'fresh etoh-Grey' & extractionType.x == 'bead') %>% #  | tiss == 'fresh etoh-Grey'
      ggplot(aes(extractioncolumn, `extraction Row`, fill = propLoc)) + geom_tile() + facet_wrap(~`extraction Plate`)

# some eggs and grey fry didn't do that well. why not? 
    filter(prop_scoring_tiss_extract, (tiss == 'fresh etoh-Egg' | tiss == 'fresh etoh-Grey') & extractionType == 'bead') %>% 
      mutate(loc_success = if_else(propLoc < 0.05, 'failed', 
                                   if_else(propLoc > 0.75, 'succeeded', 'moderate'))) %>% 
      write_csv('/workdir/smallmouth/gtseq/results/succeded_failed_eggs_greyFry.csv')
     
```


## Genotyping accuracy


```{r, warning=F, message=F, error=F, echo=F}

# here I want to import the non-read-depth cleaned version of genos

# Note I went through and removed an

genos_nofilt<-read_csv('/workdir/backup/smallmouth/gtseq_production_2/amp_py_output/hap_genotype_read_depth.csv') %>% 
  filter(!is.na(haplotype.1), !is.na(haplotype.2)) %>% 
  filter(GENID_duplicate %in% unique(genos_withdups$GENID_duplicate))

n_loci<-length(unique(genos_nofilt$locus))

# calculate missingness for each individual 
dups<-group_by(genos_nofilt, GENID_duplicate) %>% tally() %>% 
  separate(GENID_duplicate, into = c('run', 'GENID'), sep = '--', remove = F)

# Generate a list of all duplicated GENID's between gtseq production 1 and 2. Use this to make a handmade list of dups, including "a", "b" within gtseq p 1 and 2
filter(dups, duplicated(GENID))

# upload list, filter ones that didn't get any reads, and then make a final list to iterate over
dups_filt<-read_xlsx('/workdir/smallmouth/gtseq/results/gtseq_produciton_2_1_dups_for_genotype_accuracy.xlsx') %>% 
  mutate(row_num = row_number()) %>% 
  pivot_longer(-row_num, values_to = 'GENID_duplicate') %>% 
  left_join(dups, by = 'GENID_duplicate') %>% 
  filter(!is.na(run)) %>% 
  dplyr::select(row_num, name, GENID_duplicate) %>% 
  pivot_wider(names_from = 'name', values_from='GENID_duplicate') %>% 
  filter(!is.na(dup1) & !is.na(dup2))

  tib_out<-tibble()
  tib_out_snp<-tibble()
  
  i<-1
  rd<-10
  miss<-0.4
  
    for(rd in c(5,10,15,20)){
      
     microhap_snp_depth<-read_csv(paste0('/workdir/smallmouth/gtseq/microhaplot/snp_report_gtseq_production_2_depth', rd,'.csv')) %>% 
       mutate(locus = paste0(locus, '-pos', pos)) %>% 
       filter(!str_detect(snp, 'N')) %>% 
       separate(snp, into=c('snp1','snp2'), sep = '/', remove = F) %>% rowwise() %>% mutate(genoty=paste0(sort(c(snp1,snp2)),collapse='/')) %>% ungroup() %>% # arrange by alphabet
       mutate(indiv.ID = str_replace(indiv.ID, '__','--'))
     n_loci_snp<-length(unique(microhap_snp_depth$locus))
      
      for(miss in seq(0.1,1, 0.1)){
        
      # Filter the genos for read depth and missingness
        hm_filt_in<-genos_nofilt %>% 
          group_by(GENID_duplicate) %>% 
          mutate(prop_score = n()/n_loci) %>% 
          filter(read_depth >= rd) %>% 
          filter(prop_score > 0.99-miss) %>% 
          ungroup() %>% 
          dplyr::select(locus, genoty, GENID_duplicate) # haplotype.1, haplotype.2, 
        
      # filter the snps for read depth and missingness
        microhap_snp_depth_filt<-microhap_snp_depth %>% 
          group_by(indiv.ID) %>% mutate(prop_score = n()/n_loci_snp) %>% filter(prop_score > 0.99-miss)

  for(i in 1:nrow(dups_filt)){
 
    iia<-dups_filt[i,]$dup1
    iib<-dups_filt[i,]$dup2
    
    try({
        tib_in<-filter(hm_filt_in, GENID_duplicate == iia | GENID_duplicate == iib) %>% 
          pivot_wider(names_from = GENID_duplicate, values_from = genoty) %>% # c(haplotype.1, haplotype.2)) 
          na.omit()
        
      # make the tibble which ID's whether the genotypes are the same or not, assuming that each, if wrong, is only half-wrong
        tib_inner<-tib_in %>% 
          # mutate(same_haps = if_else(paste0(.[[2]],.[[4]]) == paste0(.[[3]],.[[5]]) | paste0(.[[4]],.[[2]]) == paste0(.[[3]],.[[5]]), 1, 0)) %>% # this is for separated haplotypes
          mutate(same = if_else(.[[2]] == .[[3]], 1, 0)) %>% 
          group_by(same) %>% 
          summarise(n=n()) %>% 
          mutate(first = iia, second = iib, ind = i, depth = rd, missingness  = miss, number_loci = nrow(tib_in))
          
        
        tib_out<-bind_rows(tib_inner, tib_out)
      
      })
    
    try({
      tib_in<-filter(microhap_snp_depth_filt, indiv.ID == iia | indiv.ID == iib) %>% 
        dplyr::select(locus, indiv.ID, genoty) %>% 
        pivot_wider(names_from=indiv.ID, values_from=genoty) %>% 
        na.omit()
      
      tib_inner<-tib_in %>% 
        mutate(same =  if_else(.[[2]] == .[[3]], 1, 0)) %>% 
        group_by(same) %>% 
        summarise(n=n()) %>% 
        mutate(first=iia, second=iib, ind=i, depth=rd, missingness=miss, number_loci=nrow(tib_in))
      
      tib_out_snp<-bind_rows(tib_inner, tib_out_snp)

    })
  }
 
      }
    }
  
# microhap results
     write_csv(tib_out, '/workdir/smallmouth/gtseq/results/genotype_accuracy.csv')
     tib_out<- read_csv('/workdir/smallmouth/gtseq/results/genotype_accuracy.csv')
     
    dplyr::select(tib_out, -c(first, second)) %>% 
      pivot_wider(names_from=same, values_from=n) %>% # calculate individual accuracy
      mutate(acc = (1+`1`/number_loci)/2) %>%  # but take the mean of this acc and 1, because usually half the genotypes are correct
      group_by(depth, missingness) %>% 
      summarise(mean_acc = mean(acc)) %>% 
      ggplot(aes(depth, mean_acc, color = as.character(missingness), group = missingness)) + geom_point() + geom_line() + facet_wrap(~missingness, nrow=1)
     ggsave('/workdir/smallmouth/gtseq/results/accuracy.png', height=2, width=10)
     
# snp results
     write_csv(tib_out_snp, '/workdir/smallmouth/gtseq/results/genotype_accuracy_snp.csv')
     tib_out_snp<- read_csv('/workdir/smallmouth/gtseq/results/genotype_accuracy_snp.csv')
     
     dplyr::select(tib_out_snp, -c(first,second)) %>% 
       pivot_wider(names_from=same, values_from=n) %>% 
       mutate(acc = (1+`1`/number_loci)/2) %>% 
       group_by(depth, missingness) %>% 
       summarise(mean_acc = mean(acc)) %>% 
       ggplot(aes(depth, mean_acc, color = as.character(missingness), group  = missingness)) + geom_point() + geom_line()

# how many individuals do we get passing filters?
     genos_withdups %>% 
       group_by(GENID_duplicate) %>% tally() %>% 
       separate(GENID_duplicate, into = c('run', 'GENID'), sep = '--', remove = F) %>% summarise(unique(GENID))
     
```



## Null alleles (both adaptive and neutral)

### popgenreport

```{r}
genos %>% 
  left_join(dplyr::select(phenos, GENID_duplicate, year)) %>% 
  dplyr::select(locus, GENID_duplicate, genoty, year) %>% 
  pivot_wider(names_from=locus, values_from=genoty) %>% 
  dplyr::rename(ind=GENID_duplicate, pop=year) %>% 
  write_csv('/workdir/smallmouth/gtseq/genos.csv')
```

```{bash}
nohup Rscript --vanilla /workdir/smallmouth/scripts/run_popgenreport_nulls.R \
/workdir/smallmouth/gtseq/genos.csv \
/workdir/smallmouth/gtseq/genos_nulls.csv \
> /workdir/smallmouth/nohups/run_popgenreport_genos.nohup &
```

```{r}
read_csv('/workdir/smallmouth/gtseq/genos_nulls.csv') %>% 
  filter(`2.5th percentile` > 0)
```

### homozygote excess using Diana's script
https://github.com/dbaetscher/nsf-rockfish-parentage/blob/master/Rmd/03-checking-homozygosity-atrovirens.Rmd

Essentially we test each allele to get the estimated frequency of homozygotes, then compare to actual frequency of homozygotes
Then, only considering alleles above 5% frequency, we identify null alleles with a zscore test
```{r}
overall<-genind2df(obj, sep = '/') %>% 
  as_tibble(rownames = 'ind') %>% 
  pivot_longer(-c(ind, pop)) %>% 
  separate(value, into = c('al1','al2'), remove = F) %>% 
  filter(!is.na(al1), !is.na(al2))

overall_af<-overall %>% 
  pivot_longer(-c(ind, pop, name, value), names_to = 'gene_copy', values_to = 'al1') %>% 
  group_by(name, al1) %>% 
  summarise(n_alleles = n()) %>% 
  group_by(name) %>% 
  mutate(af = n_alleles/sum(n_alleles)) %>% 
  ungroup() %>% 
  mutate(expected_homo = af^2,
         expected_het = 2 * af * (1 - af))

overall_zscore<-overall %>% 
  group_by(name, al1, al2, value) %>% 
  summarise(n_genos = n()) %>% 
  mutate(homoz = al1==al2) %>% 
  group_by(name) %>% 
  mutate(geno_prop = n_genos/sum(n_genos)) %>% 
  filter(homoz == T) %>% 
  left_join(overall_af, by = c('name','al1')) %>% 
  mutate(exp_sd = sqrt(expected_homo * ( 1 - expected_homo ) / sum(n_genos)),  # calculate standard deviation of expectation
         zscore = ( geno_prop - expected_homo ) / exp_sd )# calcualte the z-score of observed minus expected

overall_zscore %>% # we do have some high-zscore alleles
  ggplot(aes(zscore)) +
  geom_histogram()

overall_zscore %>% # but most of them look really good
  ggplot(aes(expected_homo, geno_prop, color = zscore)) +
  geom_point() +
  geom_abline()

filter(overall_zscore, zscore > 3.3) # all of these three alleles have low expected homozygosity rates (<5%), so let's not worry about them

overall_zscore %>% 
  filter(expected_homo > 0.05, zscore > 3.3)

```

## HWE

```{r}
# Overall, lots of loci fail HWE
    # pegas::hw.test(obj_noFams, B = 100) %>% 
    #   as_tibble(rownames = 'locus') %>% 
    #   filter(Pr.exact < hwe_alpha | `Pr(chi^2 >)` < hwe_alpha)

# let's check per population - exclude loci that fail HWE in more than 50% of years
    obj_hwe<-seppop(obj_noFams) %>% 
      lapply(pegas::hw.test, B = 0)

    obj_hwe_pval<-sapply(obj_hwe, "[", i = TRUE, j = 3)

    hwe_plot<-obj_hwe_pval %>% 
      as_tibble() %>% 
      mutate(locus = row.names(obj_hwe_pval)) %>% 
      pivot_longer(-locus, names_to = 'pop', values_to = 'hwe') %>% 
      mutate(hwe_1yes = if_else(hwe<0.05, 0, 1))
    
    hwe_plot %>% 
      filter(!is.na(hwe_1yes)) %>% 
      group_by(locus) %>% 
      summarise(sum_in_hwe = sum(hwe_1yes))  %>% 
      filter(sum_in_hwe <= nPop(obj_noFams)/2) %>% # just grab the loci that fail in over half the years
      left_join(locus_info, by = 'locus') %>% 
      write_csv('/workdir/smallmouth/gtseq/results/loci_failing_hwe_over_50_percent_years.csv')
    
          read_csv('/workdir/smallmouth/gtseq/results/loci_failing_hwe_over_50_percent_years.csv')

    
    hwe_plot %>% 
      ggplot(aes(pop, locus, fill = hwe_1yes)) +
      geom_tile() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## LD

also ran this per year - pretty similar results
```{r}
linkage_threshold<-0.8

# read in basic info about each locus: chr, position, # alleles. also, bring in the genind that doesn't hve relatedness (yank-2, max fam members = 2)
    oa<-dplyr::select(ordered_amplicons, microhap_name, chrNum, position) %>% 
      mutate(microhap_name = str_replace_all(microhap_name, '\\.', '')) 

    oa_Arich<-read_csv('/workdir/smallmouth/gtseq/results/locus_table_parentage.csv') %>% 
      dplyr::select(microhap_name = locus, allele_count=allele) %>% 
      left_join(oa, by = 'microhap_name')
    
    yank2<-obj_preLD_pre_HWE[no_fams$GENID_duplicate]
      
# calculate LD, bind to basic info
    tt<- yank2 %>% # just grab the yank-2 dataset
      pair.ia() %>% 
      as_tibble(rownames = 'pop_comparison')
    
    filter(tt, rbarD > linkage_threshold) # take a quick look at which loci are linked
    
    linkage_data<-tt %>%
      separate(pop_comparison, into = c('p1','p2'), sep = ':') %>% 
      dplyr::select(-Ia) %>% 
      mutate(row_n = row_number()) %>% 
      pivot_longer(-c(row_n, rbarD), values_to = 'microhap_name') %>% 
      left_join(oa_Arich, by = 'microhap_name')  
    
# What does our linkage decay look like (keep in mind that we have excluded POP and FSP)
    linkage_data %>% 
      pivot_wider(names_from=name, values_from=c(microhap_name, chrNum, position, allele_count)) %>% 
      filter(chrNum_p1 == chrNum_p2) %>% # only keep if they're on the same chromosome
      mutate(physical_distance = abs(position_p1-position_p2)) %>% 
      ggplot(aes(physical_distance, rbarD)) +
      geom_point() +
      geom_smooth() +
      geom_vline(xintercept = 5e06, lty = 'dashed')
    
# figure out which linked loci (>0.8) to exclude
# This was a bit complicated. First, I started with nothing in the "excluded" list (can comment out the setDiff line start the pipe)
# I visually went through and excluded loci that showed up in the most LD-pairs (n_microhap)
# Another thing to consider when making decisions is excluding loci that have fewere alleles (allele_count)
# Go through and sequentially add to this list, "excluded"
    excluded<-c('parentage_NW_0240400401_RagTag_start24698750_end24699000', 'parentage_NW_0240444591_RagTag_start14338500_end14338750', 'parentage_NW_0240444591_RagTag_start20733500_end20733750', 'parentage_NW_0240444591_RagTag_start22096000_end22096250', 'parentage_NW_0240445701_RagTag_start20857250_end20857500', 'parentage_NW_0240445701_RagTag_start9466250_end9466500')
    
    yank2[loc = setdiff(locNames(yank2), excluded)] %>% # just grab the yank-2 dataset
      missingno('loci', 0.2) %>% 
      missingno('geno', 0.2) %>% 
      pair.ia(plot = F) %>% 
      as_tibble(rownames = 'pop_comparison') %>% 
      separate(pop_comparison, into = c('p1','p2'), sep = ':') %>% 
      dplyr::select(-Ia) %>% 
      mutate(row_n = row_number()) %>% 
      pivot_longer(-c(row_n, rbarD), values_to = 'microhap_name') %>% 
      left_join(dplyr::select(oa_Arich, -c(chrNum, position)), by = 'microhap_name')  %>% 
      filter(rbarD > linkage_threshold) %>% 
      group_by(microhap_name) %>% 
      mutate(n_microhap = n()) %>% 
      pivot_wider(names_from=name, values_from=c(microhap_name, allele_count, n_microhap)) %>% 
      filter(!is.na(microhap_name_p1), !is.na(microhap_name_p2))
    
  write_csv(as_tibble(excluded), '/workdir/smallmouth/gtseq/results/loci_parentage_ld_exclude.csv')
  
  read_csv('/workdir/smallmouth/gtseq/results/loci_parentage_ld_exclude.csv')
```


## LD (just neutral)

# Figure 1

#### Figure 1a-e (all on same axis)

```{r}
# Figure 1a (CPUE S with length bins)

      # bring in the missing SITE_N's that Kurt identified. I consolidated may and june in 2000, since we aren't considering month affect
        missing_sites<-
          read_xlsx('/workdir/smallmouth/ecological/kurt_matched_naf_surveys.xlsx', sheet = 'missing_sites_2000consolidated') %>% 
            group_by(Spring_NAF_missing_sites) %>% tally() %>% 
            filter(n>1) %>% 
            mutate(missing_sites = as.character(str_pad(Spring_NAF_missing_sites, 3, pad = "0")),
                   SITE_N = paste0('BEF.LML.',missing_sites))

      # Import shoreline distances. These are also the sites we trust the most
        site_distances<-read_csv('/workdir/smallmouth/ecological/BEFsites_LengthAndHabitat_BMQ_070318_1_shoreline_distances.csv') %>% 
          filter(Water=='LML')

# Figure 1a
      figure_1a<-allFish %>%
        mutate(jDate = lubridate::yday(DATE_COL),
             ysamp = str_sub(YSAMP_N, -2)) %>% 
        filter(between(year, 1998, 2020), !is.na(effortSec), (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO'), WATER == 'LML', month<7) %>% 
        group_by(year, SITE_N) %>% 
        filter(jDate == min(jDate)) %>% # Just grab the first jDate of the SITE_N of the year
        filter(ysamp == min(ysamp)) %>% # Just grab the first sampling site of the day
        ungroup() %>% 
        filter(SITE_N %nin% missing_sites$SITE_N,
               SITE_N %in% site_distances$SITE_N) %>% 
        mutate(lenBin = if_else((LENGTH < 100 | is.na(LENGTH)), '0-100',
                          if_else(between(LENGTH, 100, 200), '100-200',
                                  if_else(LENGTH > 200, '200+', '0')))) %>% 
        group_by(year, SITE_N, lenBin) %>% 
        summarise(cpue = (n()/unique(effortSec))*60) %>% 
        ungroup() %>% 
        pivot_wider(names_from=lenBin, values_from=cpue) %>%
        mutate_all(~ifelse(is.na(.), 0, .)) %>% # fill in all NA's with zero
        pivot_longer(-c(year, SITE_N), names_to='lenBin',values_to='cpue') %>% 
        ggplot(aes(year, cpue, group=lenBin, color=lenBin)) + # , color = lenBin, lty = lenBin
        geom_smooth(span=0.15) +
        ylab('Catch / minute') + 
        scale_color_viridis_d('Length bin\n(mm)') +
        geom_vline(xintercept = 2000.5, lty = 'dotted') +
        xlim(1998,2020) +
        coord_cartesian(ylim=c(0, 4)) +
        theme_cowplot() +
        theme(axis.text.x=element_blank(),axis.title.x=element_blank()) +
        ggtitle("A")

# Figure 1b
      figure_1b<-
        allFish %>%
        filter(between(year, 1998, 2020), (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO'), !is.na(LENGTH), WATER == 'LML', SEASON=='S') %>% 
        ggplot(aes(x=LENGTH, y=as.factor(year), fill=stat(x))) + 
        ggridges::geom_density_ridges_gradient(scale=1.5, rel_min_height = 0.001) +  
        scale_fill_viridis_c(name = "LENGTH", option = "C") + 
        xlim(0,400)  + 
        labs(y='Year',x='Length (mm)') + 
        theme_cowplot() +
        coord_flip() +
        theme(legend.position="none", axis.text.x=element_blank(),axis.title.x=element_blank()) + 
        scale_y_discrete(breaks = c(2000, 2005, 2010, 2015, 2020)) + # axis.text.x = element_text(angle = 45, vjust = 1, hjust=1), 
        ggtitle("B")

# Figure 1c
      figure_1c<-allFish %>% 
        filter(!is.na(newGSI), sex == 'F', (WATER == 'LML' | WATER == 'WLL'), ageTrue == 4, year < 2021) %>% 
        mutate(Lake = if_else(WATER == 'LML', 'Little Moose', 'Woodhull'),
          yearlake = paste0(year, Lake)) %>% 
        ggplot(aes(year, newGSI, color = Lake)) + 
        geom_boxplot(aes(group = yearlake, color = Lake)) +
        geom_jitter(height=0, width=0.1, alpha = 0.5) +
        stat_smooth(method = 'lm') + 
        labs(x='Year', y='Age 4\nfemale GSI') + 
        theme_cowplot() + xlim(1998, 2020) + 
        geom_vline(xintercept = 2000.5, lty='dotted') + 
        theme(legend.position="none", axis.text.x=element_blank(),axis.title.x=element_blank()) + 
        scale_color_manual(values=c("black", "blue")) +
        ggtitle("C")

# Figure 1d 
      figure_1d<-allFish %>% 
        filter(!is.na(newGSI), sex == 'M', (WATER == 'LML' | WATER == 'WLL'), ageTrue == 3, year < 2021) %>% 
        mutate(Lake = if_else(WATER == 'LML', 'Little Moose', 'Woodhull'),
               yearlake = paste0(year, Lake)) %>% 
        ggplot(aes(year, newGSI, color = Lake)) + 
        geom_boxplot(aes(group = yearlake, color = Lake)) +
        geom_jitter(height=0, width=0.1, alpha = 0.5) +
        stat_smooth(method = 'lm') + 
        labs(x='Year', y='Age 3\nmale GSI') + 
        theme_cowplot() +  
        xlim(1998, 2020) + 
        geom_vline(xintercept = 2000.5, lty='dotted') + 
        theme(axis.text.x=element_blank(),axis.title.x=element_blank()) + 
        scale_color_manual(values=c("black", "blue")) +
        ggtitle("D")

#### Figure 1e
      figure_1e<-allFish %>% 
        filter(SEASON == 'S', GEAR=='BEF', !is.na(ageLengthed), between(year, 1998, 2017), ageLengthed<5) %>% 
        mutate(ageyear = paste0(ageLengthed, year)) %>% 
        ggplot(aes(year, LENGTH)) + 
        geom_boxplot(aes(group = ageyear, color = ageLengthed), outlier.shape=NA) +  
        geom_smooth(aes(group = ageLengthed, color = ageLengthed), span = .3, level = 0.95) +
        labs(x='Year', y = 'Length (mm)', color = 'Age') +
        theme_cowplot() +
        geom_vline(xintercept = 2000.5, lty = 'dotted') +
        #theme(legend.position="none") +
        xlim(1998, 2020) +
        ggtitle("E")
      
    plot_grid(figure_1a, figure_1b, figure_1c, figure_1d, figure_1e, ncol=1, align="v")
    ggsave('/workdir/smallmouth/chapter_3_exports/Fig_1a-1e.png', height=10, width = 6)

```

Calculate difference in pre- vs during-suppression size-at-age. mean and p-val
```{r}
# Generate dataset
    size_at_age_data<-filter(allFish, WATER == 'LML', between(ageLengthed, 0, 6), between(year, 1998, 2017), GEAR=='BEF') %>% 
      mutate(pre_post = if_else(year<2001, 'Pre','Post'),
             pre_post_age = paste0(ageLengthed, pre_post)) %>% 
      filter(!is.na(pre_post))
      
# Plot length
      ggplot(size_at_age_data, aes(ageLengthed, LENGTH, color = pre_post)) + 
        geom_boxplot(aes(group = pre_post_age)) + 
        geom_smooth(span=2, se = F) + 
        theme_cowplot() + 
        labs(x = 'Age', y = 'Length (mm)', color = 'Post- vs. pre-\nremoval effort') + 
        facet_wrap(~SEASON) 
      ggsave('/workdir/smallmouth/ecological/results/length_at_age_spring_fall.png', height=4, width=6)
      
# Statistical comparison
      pval_out<-tibble()
      for(age_in in 0:4){
        for(season in c('S','F')){
          try({
        pv_lei<-summary(lm(LENGTH ~ pre_post, data = filter(size_at_age_data, ageLengthed==age_in, SEASON == season)))
        pval_out<-bind_rows(pval_out, tibble(ageLengthed=age_in, pval_length=pv_lei$coefficients[2,4], effect_length=pv_lei$coefficients[2,1],SEASON = season))
          })
        }
      }
    pval_out
```

#### Figure 1f-g

fishR vignette on reverse modeling of annual age-specific mortality
```{r}
# First, we need to build an age-length key with no gaps. Do 5-year blocks, skipping 2001-2005 because its hard to assess. Use the tutorial at http://derekogle.com/fishR/examples/oldFishRVignettes/AgeLengthKey.pdf

year_blocks<-tibble(start = c(1970, 2005), end = c(2000, 2023))

catch_curves_out<-tibble()
for(i in 1:2){
  #i<-1
  # import data
      sm_in<-filter(allFish, WATER == 'LML', 
             month<7, 
             between(year, year_blocks[i,]$start, year_blocks[i,]$end),
             !is.na(LENGTH), LENGTH > 30) %>% 
        mutate(ageTrue = if_else(LENGTH < 100, 1, ageTrue)) # we always call fish under 100mm as 1yo
      
      sm_age<-filter(sm_in, !is.na(ageTrue))
      
      sm_len<-filter(sm_in, is.na(ageTrue)) %>% mutate(alk = as.numeric(NA))
  
  # generate AL key
      sm_age_category<-FSA::lencat(~LENGTH, data = sm_age, startcat = 30, w=10) # length category per ind
      sm_age_raw<-with(sm_age_category, table(LCat, ageTrue)) # convert to table, age = col, lencat = row
      sm_age_key <- prop.table(sm_age_raw,margin=1) # convert this into a proportion
        
  # assign age to fishes, bind to known ages, pull first 3 days of each NAF
      catches_in<-
        FSA::alkIndivAge(sm_age_key,alk~LENGTH,data=sm_len, seed = 123) %>% 
        bind_rows(sm_age) %>% 
        mutate(age_catch_curve = coalesce(ageTrue, alk)) %>% 
        filter(!is.na(age_catch_curve), (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO')) %>% 
        mutate(jDate = lubridate::yday(DATE_COL),
               ysamp = str_sub(YSAMP_N, -2)) %>% 
        group_by(year, SITE_N) %>% 
        filter(jDate == min(jDate)) %>% # Just grab the first jDate of the SITE_N of the year
        filter(ysamp == min(ysamp)) %>% # Just grab the first sampling site of the day
        ungroup() %>% 
        group_by(year, age_catch_curve) %>% 
        tally() 
      catch_curves_out<-bind_rows(catch_curves_out, catches_in)
}

# calculate the yearly instantaneous (Z) and annual (A) mortality rate
summ_out<-tibble()
confin_out<-tibble()

for(yr in unique(catch_curves_out$year)){
  
  thcc <- FSA::chapmanRobson(n~age_catch_curve,data=filter(catch_curves_out, year == yr),ages2use=1:6)
  
  summ_out<-rownames_to_column(as.data.frame(summary(thcc)), var = 'mortality') %>% 
    mutate(year = yr) %>% 
    bind_rows(summ_out)
  
  confin_out<-rownames_to_column(as.data.frame(confint(thcc)), var = 'mortality') %>% 
    mutate(year = yr) %>% 
    bind_rows(confin_out)
}

# Figure 1f
fig_1f<-mutate(catch_curves_out, Suppression = if_else(year < 2001, 'Before', 'During'),
       suppression_age = paste0(Suppression, age_catch_curve)) %>% 
  filter(age_catch_curve < 7) %>% 
  ggplot(aes(age_catch_curve, n, color = Suppression)) + 
  geom_boxplot(aes(group = suppression_age), outlier.color = NA) +
  geom_jitter(alpha=0.2, position=position_jitterdodge(jitter.width = 0.1, jitter.height = 0)) + 
  geom_smooth(span=1, se = F) + 
  theme_cowplot() + 
  labs(x = 'Age', y = 'Catch') +
  ggtitle("F")

# Figure 1g
fig_1g<-summ_out %>% 
  filter(mortality == 'S') %>% 
  mutate(Suppression = if_else(year < 2001, 'Before', 'During'), Estimate = Estimate/100) %>% 
  ggplot(aes(Suppression, Estimate, group = Suppression, color = Suppression)) + 
  geom_boxplot() + 
  geom_jitter(height = 0, width = 0.1) + 
  labs(y = 'Annual survival estimate') + 
  theme_cowplot() +
  theme(legend.position = 'none')  +
  ggtitle("G")

  plot_grid(fig_1f,fig_1g, ncol=1, align="v")
  ggsave('/workdir/smallmouth/chapter_3_exports/Fig_1f-1g.png', height=5, width = 5)
```

# Figure 2

manhattan plot
```{r eval=T}
lg_filter <- read_csv('/workdir/smallmouth/sample_lists/lg_reference_annotate.csv')
lg_filter_temp <- rename(lg_filter, LG = lg, lg = chr)
window_length <- 50*1000
minind <- 20

# Import the reference bias filtered SNP list
    refBias <- read_tsv("/workdir/smallmouth/angsd/global_snp_list_depth_ratio_filtered.txt", col_names = c("lg", "pos")) %>%
      mutate(keep=T)

# Import Fst
    fst <- read_tsv('/workdir/smallmouth/angsd/popminind20/A_D_global_snp_list_bam_list_realigned_smb_anchored_mincov_filtered_mindp39_maxdp350_minind21_minq20_popminind20.fst', 
                           col_names = c('lg', 'pos', 'alpha', 'beta', 'fst')) %>%
      left_join(lg_filter_temp, by = 'lg') %>% 
      filter(!is.na(name)) %>% 
      left_join(refBias,by=c('lg','pos')) %>%
      filter(keep==T) %>%
      dplyr::select(-keep) %>% 
      write_csv('/workdir/smallmouth/gtseq/results/fst_A_D.csv')
    
    fst_window<-fst %>% 
      mutate(pos=cut(pos, # Make the window Fst
                     breaks=seq(0,50*10^6,window_length),
                     labels=seq(window_length/2,50*10^6-window_length/2,window_length))) %>% 
      group_by(name, pos) %>%
      summarise(fst_mean=sum(alpha)/sum(beta),
                s2fst=var(fst, na.rm = T),
                n = n()) %>% 
      filter(n > 5, !is.na(name)) %>%  # Here, I can filter the windows for a minimum number of SNPs
      mutate(pos=as.numeric(as.character(pos))) %>% 
      ungroup()
      
  # Set our 99% confidence threshold
      threshold_window <- quantile(fst_window$fst_mean, 0.99, na.rm = T)
      
  # Alternatively, use Zfst
      fst_window %>% 
        ungroup() %>%
         mutate( Zfst = (fst_mean - mean(fst_mean))/sd(fst_mean),
               signifi = if_else(Zfst > 5, 0, 1)) %>%
        ggplot(aes(x=pos/10^6, y=Zfst)) +
        geom_point(aes(color = signifi), size=0.5, alpha=0.5) +
        geom_smooth(color='blue', se=F) +
        scale_x_continuous(breaks=seq(0, 50, 5)) +
        labs(x='', y = paste('ZFst ',window_length/1000,'kb window')) +
        facet_grid(.~name, scales='free_x', space='free_x') +
        theme_cowplot() +
        geom_hline(yintercept = 5, lty = 'dotted') +
        theme(panel.spacing = unit(0.1, 'lines'),
            legend.position='none',
            axis.text.x=element_blank(),
            axis.ticks.x=element_blank())
        ggsave('/workdir/smallmouth/chapter_3_exports/figure_2a.png', width = 20, height = 6, units = 'cm')
# 
#   # Plot the window Fst with 99% CI
#         fst_window %>%
#         mutate(signifi = if_else(fst_mean > threshold_window, 0, 1)) %>%
#         ggplot(aes(x=pos/10^6, y=fst_mean)) +
#         geom_point(aes(color = signifi), size=0.5, alpha=0.5) +
#         geom_smooth(color='blue', se=F) +
#         scale_x_continuous(breaks=seq(0, 50, 5)) +
#         xlab('position (Mbp)') +
#         ylab(paste('Fst ',window_length/1000,'kb window')) +
#         facet_grid(.~name, scales='free_x', space='free_x') +
#         theme_cowplot() +
#         ggtitle('Little Moose 2000 vs 2019') +
#         geom_hline(yintercept = threshold_window, lty = 'dotted') +
#         xlab('') + ylab('50kbp window Fst') +
#         theme(panel.spacing = unit(0.1, 'lines'),
#             axis.title.x=element_text(),
#             legend.position='none',
#             axis.text.x=element_blank(),
#             axis.ticks.x=element_blank(),
#             #strip.text = element_blank()
#             ) +
#           ggtitle("A")
#         ggsave('/workdir/smallmouth/chapter_3_exports/figure_3a.png', width = 23, height = 7, units = 'cm', pointsize = 20)
#         
#         
#   # Plot non-window Fst with 99% CI
#     threshold_fst <- quantile(fst$fst, 0.99, na.rm = T)
#     
#     fst %>%
#       filter(name == 6 | name == 7 | name == 19) %>% 
#       mutate(signifi = if_else(fst > threshold_fst, 0, 1)) %>%
#       ggplot(aes(x=pos/10^6, y=fst)) +
#       geom_point(aes(color = signifi), size=0.5, alpha=0.5) +
#       geom_smooth(color='blue', se=F) +
#       scale_x_continuous(breaks=seq(0, 50, 5)) +
#       xlab('position (Mbp)') +
#       ylab(paste('Fst ',window_length/1000,'kb window')) +
#       facet_grid(.~name, scales='free_x', space='free_x') +
#       theme_cowplot() +
#       ggtitle('Little Moose 2000 vs 2019') +
#       geom_hline(yintercept = threshold_fst, lty = 'dotted') +
#       xlab('') + ylab('Fst') +
#       theme(panel.spacing = unit(0.1, 'lines'),
#           axis.title.x=element_text(),
#           plot.title = element_text(size = 10),
#           legend.position='none',
#           text = element_text(size=12),
#           axis.text = element_text(size=12),
#           axis.text.x=element_blank(),
#           axis.ticks.x=element_blank())
#     
#     ggsave(filename  = paste0('/workdir/smallmouth/figures/fst_minind', minind, '_A_D_no_window.png'), width = 30, height = 8, units = 'cm', pointsize = 20)
```

Generate AF dataset
```{r}
# pull in the maf from lcwgs data
A_maf<-as_tibble(read.table(gzfile(paste0('/workdir/smallmouth/angsd/popminind20/A_global_snp_list_bam_list_realigned_smb_anchored_mincov_filtered_mindp39_maxdp350_minind21_minq20_popminind20.mafs.gz')), header = TRUE))

D_maf<-as_tibble(read.table(gzfile(paste0('/workdir/smallmouth/angsd/popminind20/D_global_snp_list_bam_list_realigned_smb_anchored_mincov_filtered_mindp39_maxdp350_minind21_minq20_popminind20.mafs.gz')), header = TRUE))

# filter(ordered_amplicons, microhap_name == 'adaptive_lg6_3256886') # position 201, plus the fasta_start
# filter(A_maf, chromo == 'NW_024040485.1_RagTag', position == 201+3256686-1) # starts at 0.16
# filter(D_maf, chromo == 'NW_024040485.1_RagTag', position == 201+3256686-1) # ends at 0.77
# 
# filter(ordered_amplicons, microhap_name == 'adaptive_lg19_12740897') # 201+12740697-1
# filter(A_maf, chromo == 'NW_024044237.1_RagTag', position == 201+12740697-1) # starts at 0.17
# filter(D_maf, chromo == 'NW_024044237.1_RagTag', position == 201+12740697-1) # ends at 0.91

lcwgs_af<-tibble(locus = c('adaptive_lg6_3256886-pos201','adaptive_lg19_12740897-pos201'), '2000' = c(0.16, 0.17), '2019' = c(0.77, 0.91)) %>% 
  pivot_longer(-locus, names_to = 'year', values_to = 'meanAF') %>% 
  mutate(type='Whole-genome', year = as.double(year))

# plot AF of putatively adaptive loci through time in LML
    LML_inds<-filter(phenos, WATER=='LML') %>% 
      dplyr::select(GENID_duplicate, year)
    
    pre_post_AF<-microhap_snp %>% 
      left_join(LML_inds, by = 'GENID_duplicate') %>% 
      filter(!is.na(year)) %>%
      dplyr::select(GENID_duplicate, locus, year, AlleIdx_1, AlleIdx_2) %>% 
      pivot_longer(-c(GENID_duplicate, locus, year), names_to = 'gene_copy', values_to = 'allele') %>% 
      group_by(locus, year) %>% 
      summarise(meanAF = mean(allele), n=n()) %>% 
      ungroup() %>%  
      filter(n>=10) %>% 
      mutate(pre_post = if_else(year < 2001, 'pre', 'post')) %>% 
      group_by(locus) %>% 
      mutate(tt=length(unique(pre_post)))  %>% 
      ungroup() %>% 
      filter(str_detect(locus, 'adaptive')) %>%
      mutate(type='Amplicon')

    # Plot them as a big wrap
      ggplot(pre_post_AF, aes(year, meanAF)) + geom_point() + geom_line() + ylim(0,1) + geom_vline(xintercept = 2000, lty='dotted') + facet_wrap(~locus)
      ggsave(paste0('/workdir/smallmouth/gtseq/results/AF_out_adaptive.png'), height=15, width=15) # 5, 10

    # filter for just the ones that line up with our LD plot through time
    filter(pre_post_AF, locus %in% read_csv('/workdir/smallmouth/gtseq/results/lg19_loci.csv')$locus) %>%
      mutate(locus = str_replace(locus, '_gwas', '')) %>%
      ggplot(aes(year, meanAF)) + 
      geom_point() + 
      geom_line() + 
      facet_wrap(~fct_rev(locus), ncol = 1) + 
      ylim(0,1) + 
      theme_cowplot() +  
      theme(strip.background = element_blank(), 
            strip.text.x = element_blank(),
            axis.text.x = element_text(angle = 45, vjust = 1, hjust=1), 
            panel.spacing = unit(0.75, 'cm')) + 
      geom_vline(xintercept = 2000.5, lty = 'dotted') + 
      labs(x='Year', y='Allele frequency')
    ggsave('/workdir/smallmouth/gtseq/results/AF_change_lg19_loci.png', height=8, width = 3)
```
  
assess linkage disequilibrium (r2)
```{r}
# calculate r2 between loci within chromosome
for(lg_in in c('lg6','lg7','lg19')){
  
  if(lg_in == "lg19"){
    plot_size<-7
  } else{
    plot_size<-4
  } 
   
  corplot_in<-microhap_snp %>% 
    filter(GENID_duplicate %in% filter(phenos, WATER=='LML')$GENID_duplicate,
           str_detect(locus, 'adaptive'),
           str_detect(locus, lg_in)) %>% 
    mutate(locus = str_replace(locus, 'gwas_', '')) %>% 
    separate(locus, into = c('xx','lg','pos'), sep = '_') %>% 
    separate(pos, into = c('pos','pos2'), sep = '-pos') %>% 
    mutate(pos = paste0(as.integer(pos)+as.integer(pos2), '-')) %>% 
    dplyr::select(GENID_duplicate, pos, AlleIdx_genoty) %>% 
    arrange(pos) %>% 
    pivot_wider(names_from = pos, values_from = AlleIdx_genoty) 
    
    cor_in<-cor(dplyr::select(corplot_in, -GENID_duplicate), use='pairwise.complete.obs')
    
    corplot<-ggcorrplot::ggcorrplot(cor_in, 
                           lab = TRUE,
                           show.legend = F,
                           lab_size = 3,
                           title = str_replace(lg_in, 'lg', 'Chromosome '))
    
    ggsave(paste0('/workdir/smallmouth/gtseq/results/correlation_snps_',lg_in,'.png'), corplot, width = plot_size, height = plot_size)
}
```
  
per locus: AF, Ho change, genotype frequency change, anovas for genotype-phenotype interactions , plots
```{r}
tib_out_sig<-tibble()
prop_mature_plot<-list() # load the proportion mature into this list
prop_genos_plot<-list() # load the genotype change through time into this list
for(loc_in in loci_selected){
  
  # Build the phenotype dataset
    phenos_dataset<-filter(microhap_snp, locus == loc_in) %>% 
      left_join(obj_fams, by = 'GENID_duplicate') %>% 
      filter(WATER == 'LML', SEASON == 'S', !is.na(ageLengthed), ageLengthed < 5) %>% 
      left_join(read_csv('/workdir/smallmouth/gtseq/results/genoty_idx_converter.csv'), by = c('locus','genoty')) 
    
  # Make a function to remove individuals in the same family
    no_dups<-function(input, seed_in){
      set.seed(seed_in)
      
      input %>% 
        group_by(fam_index) %>% 
        slice_sample(n=1)
    }
    
  # run analyses over loci
    tib_out_sex<-tibble()
    tib_out<-tibble()
    for(age_in in 1:4){
      for(sex_in in c('F','M')){
        for(i in 1:5){
        # Test if any are different using an anova
          # GSI for each sex independently
            data_in<-filter(phenos_dataset, ageLengthed == age_in, sex == sex_in, !is.na(newGSI), newGSI>0) %>% 
              no_dups(i)
            kt_gsi_sex<-lm(log(newGSI) ~ idx_genoty, # gsi for each sex
                             data = data_in)
            
            # Export effect size and r2  
              if(str_detect(loc_in, 'lg19') & age_in == 3 & sex_in == 'F' & i == 1){
                print('lg19, age3, female, gsi')
                print(summary(kt_gsi_sex))
                print(data_in %>% group_by(idx_genoty) %>% summarise(meanGsi = mean(newGSI, na.rm = T), test = 'lg19, age3, female, gsi'))
              }
            
              if(str_detect(loc_in, 'lg6') & age_in == 3 & sex_in == 'M' & i == 1){
                print('lg6, age3, male, gsi')
                print(summary(kt_gsi_sex))
                print(data_in %>% group_by(idx_genoty) %>% summarise(meanGsi = mean(newGSI, na.rm = T), test = 'lg6, age3, male, gsi'))
              }

          # length for each sex independently
            data_in<-filter(phenos_dataset,ageLengthed == age_in, sex == sex_in) %>% 
              no_dups(i)
            kt_length_sex<-lm(yearly_length_anomaly ~ idx_genoty, # yearly length anomaly for each sex
                             data = data_in)
            
            # export the effect size and r2
              if(str_detect(loc_in, 'lg6') & age_in == 3 & sex_in == 'M' & i == 1){
                print('lg6, age3, male, length')
                print(summary(kt_length_sex))
                print(data_in %>% group_by(idx_genoty) %>% summarise(meanLen = mean(LENGTH, na.rm = T), test = 'lg6, age3, male, length'))
              }
                          
          # length for both sexes combined   
            data_in<-filter(phenos_dataset, ageLengthed == age_in) %>% 
              no_dups(i)
            kt_length<-lm(yearly_length_anomaly ~ idx_genoty, # yearly length anomaly, combining sexes
                             data = data_in)
            
            # export the effect size and r2
              if(str_detect(loc_in, 'lg19') & age_in == 1 & sex_in == 'F' & i == 1){
                print('lg19, age1, both sexes, length')
                print(summary(kt_length))
                print(data_in %>% group_by(idx_genoty) %>% summarise(meanLen = mean(LENGTH, na.rm = T), test = 'lg19, age1, bothsex, length'))
              }
            
              if(str_detect(loc_in, 'lg19') & age_in == 3 & sex_in == 'F' & i == 1){
                print('lg19, age3, both sexes, length')
                print(summary(kt_length))
                print(data_in %>% group_by(idx_genoty) %>% summarise(meanLen = mean(LENGTH, na.rm = T), test = 'lg19, age3, bothsex, length'))
              }
            
          # eggDate
            data_in<-left_join(microhap_snp, obj_fams, by = 'GENID_duplicate') %>% 
              filter(locus == loc_in, WATER == 'LML', str_detect(SAMPLE, 'NEST'), !is.na(eggDate), !is.na(genoty), !is.na(year)) %>% 
              group_by(WAYPOINT) %>% 
              slice_head(n=1) %>% 
              no_dups(i)
            kt_egg<-nlme::lme(eggDate~as.factor(genoty), 
                                    random=~1|year,
                                    data = data_in)

          # consolidate the ANOVA p-values
            tib_out_sex<-bind_rows(tib_out_sex, 
                                    tibble(ageL = age_in, 
                                    sex = sex_in, 
                                    i=i,
                                    gsi_anova_bysex = anova(kt_gsi_sex)$`Pr(>F)`[1], 
                                    len_anova_bysex = anova(kt_length_sex)$`Pr(>F)`[1],
                                    len_anova_bothsex = anova(kt_length)$`Pr(>F)`[1],
                                    eggdate_anova_randomyear = anova(kt_egg)$`p-value`[2]))
        }
      }
    }
    tib_out_sig_in<-tib_out_sex %>% 
      pivot_longer(-c(ageL, sex, i)) %>% 
      filter(value<0.05) %>% 
      group_by(ageL, sex, name) %>% 
      pivot_wider(names_from = i, values_from = value) %>% 
      mutate(locus = loc_in)

    tib_out_sig<-bind_rows(tib_out_sig, tib_out_sig_in)
    
    # add full sex names
      phenos_dataset_sex<-phenos_dataset %>% 
        mutate(sex_in = if_else(sex == 'M', 'Male',
                                if_else(sex == 'F', 'Female', NA_character_))) %>% 
        filter(!is.na(sex_in)) 
      
    # make plots - for lg6, filter to just include males
      if(str_detect(loc_in, 'lg6')){
        phenos_dataset_filtered<-filter(phenos_dataset, sex == 'M')
        length_label<-'Male Length\n(mm)'
        plot_name<-'Chromosome 6'
        panel_names<-c('B','C','D')
      } else {
        phenos_dataset_filtered<-phenos_dataset
        length_label<-'Length\n(mm)'
        plot_name<-'Chromosome 19'
        panel_names<-c('E','F','G')
      }
    
    # length
      len_out<-phenos_dataset_filtered %>% 
        ggplot(aes(as.character(ageLengthed), LENGTH, color = genoty)) + 
        geom_boxplot(outlier.color = NA) + 
        labs(x='Age', y = length_label, color = 'Genotype') + 
        scale_color_viridis_d(option = 'D') + 
        geom_point(position=position_jitterdodge(jitter.width = 0.2, jitter.height = 0), 
                   aes(group = genoty), alpha=0.2) +
        theme_cowplot() +
        theme(legend.position = 'none')  +
        ggtitle(panel_names[2])

    # gsi
      gsi_out<-phenos_dataset_sex %>% 
        filter(between(ageLengthed, 2, 4)) %>% 
        ggplot(aes(as.character(ageLengthed), newGSI, color = genoty)) + 
        geom_boxplot(outlier.color = NA) + 
        labs(x='Age', y = 'Gonadal-Somatic\nIndex', color = 'Genotype') + 
        scale_color_viridis_d(option = 'D') + 
        geom_point(position=position_jitterdodge(jitter.width = 0.2, jitter.height = 0), 
                   aes(group = genoty), alpha=0.2) +
        facet_wrap(~sex_in, scales = 'free') +
        theme_cowplot() +
        theme(legend.position = 'none')  +
        ggtitle(panel_names[3])
      
      
    # Plot AF through time
      dat_in<-filter(pre_post_AF, locus == loc_in) %>%
        bind_rows(filter(lcwgs_af, locus == loc_in))
      
      af_out<-ggplot(NULL) + 
        geom_point(data=dat_in, aes(year, meanAF, color = type)) + 
        geom_line(data=filter(dat_in, year>1995 & type=='Amplicon'), aes(year, meanAF), color = 'red') + 
        geom_line(data=filter(dat_in, year<2000), aes(year, meanAF), color = 'red', lty='dashed') + 
        ylim(0,1) + 
        geom_vline(xintercept = 2000.5, lty='dotted') +
        labs(y= 'Allele\nfrequency', x = 'Year') + 
        theme_cowplot() + 
        #theme(legend.position="none") +
        xlim(1970, 2020) +
        ggtitle(panel_names[1])

    # proportion mature
      propm<-phenos_dataset_sex %>% 
        group_by(sex_in, idx_genoty, ageLengthed) %>% 
        summarise(propM = mean(mature)) %>% 
        ggplot(aes(ageLengthed, propM, color = as.character(idx_genoty))) + 
        geom_point(alpha = 0.8, size = 3) + 
        scale_color_viridis_d(option = 'D') + 
        geom_line(alpha = 0.5, size = 1.5) + 
        facet_wrap(~sex_in) +
        labs(x = 'Age', y = 'Proportion mature', color = 'Genotype') +
        theme_cowplot() +
        ggtitle(plot_name)
      prop_mature_plot[[loc_in]]<-propm
      
    # Look at proportion of genotypes before vs after removal
      propg<-left_join(microhap_snp, phenos, by = 'GENID_duplicate') %>% 
        filter(locus==loc_in, WATER == 'LML', genoty != '') %>% 
        left_join(read_csv('/workdir/smallmouth/gtseq/results/genoty_idx_converter.csv'), by = c('locus','genoty')) %>% 
        group_by(year, idx_genoty) %>% 
        tally() %>% 
        ungroup() %>% 
        group_by(year) %>% 
        mutate(sum_n=sum(n)) %>% 
        ungroup() %>% 
        filter(sum_n>=5) %>%  
        mutate(prop=n/sum_n, pre_post = if_else(year<2001, 'before', 'during')) %>%
        ggplot(aes(year, prop, color = as.character(idx_genoty))) + 
        geom_point() + 
        geom_line() + 
        scale_color_viridis_d(option = 'D') + 
        geom_vline(xintercept = 2000.5, lty = 'dotted') +
        lims(x = c(1970, 2020), y = c(0,1)) +
        ggtitle(plot_name) +
        labs(x = 'Year', y = 'Genotype proportion', color = 'Genotype') +
        theme_cowplot()
      prop_genos_plot[[loc_in]]<-propg

      # Bind AF, length, GSI for figure 3 export
      plot_grid(af_out, len_out, gsi_out, ncol=1, align="v")
      ggsave(paste0('/workdir/smallmouth/chapter_3_exports/fig3_',loc_in,'.png'), height = 7, width = 4)
}

tib_out_sig

plot_grid(plotlist = prop_mature_plot, ncol = 1)
ggsave('/workdir/smallmouth/gtseq/results/prop_mature_adaptive_loci.png', height=6, width=6)
      
plot_grid(plotlist = prop_genos_plot, ncol = 1)
ggsave('/workdir/smallmouth/gtseq/results/genotype_frequency_changes_adaptive_loci.png', height=6, width=5)

# what is the total % of age-3 GSI variation we can explain with both loci?
  data_in<-filter(microhap_snp, locus %in% loci_selected) %>% 
    left_join(obj_fams, by = 'GENID_duplicate') %>% 
    filter(WATER == 'LML', SEASON == 'S', ageLengthed==3, !is.na(newGSI)) %>% 
    left_join(read_csv('/workdir/smallmouth/gtseq/results/genoty_idx_converter.csv'), by = c('locus','genoty')) %>% 
    dplyr::select(GENID_duplicate, locus, genoty, newGSI, sex) %>% 
    mutate(locus = if_else(str_detect(locus, 'lg19'), 'lg19','lg6')) %>% 
    pivot_wider(names_from = locus, values_from = genoty)
  summary(lm(log(newGSI) ~ lg19 + lg6 + sex, data = data_in))
```

# Figure 3

## Relatedness

Setup functions
```{r, warning=F, message=F, error=F, echo=F}

long2freqs <- function(L) {

    loci <-unique(L$Locus) # First I have to set the loci to a list of unique loci, to set Pos as the level
  
    L %>%
      count(Locus, Allele) %>%
      group_by(Locus) %>%
      # mutate(Freq = n / sum(n),
      #        Chrom = str_sub(str_replace(Locus,'parentage_',''), 1,14), # I made this change to include chrom
      #        Pos =str_replace_all(str_sub(Locus, -8), c(n="",d=""))) %>% # made this change to include pos
      mutate(Freq = n / sum(n),
           Chrom = "Unk",
           Pos = as.integer(factor(Locus, levels = loci))) %>%
      ungroup() %>%
      dplyr::select(Chrom, Pos, Locus, Allele, Freq) %>%
      arrange(Pos, desc(Freq)) %>%
      mutate(AlleIdx = NA,
             LocIdx = NA) %>%
      filter(!is.na(Allele)) %>% 
      reindex_markers()
}

create_ckmr_simple <- function(C) {
    create_ckmr(
      D = C,
      kappa_matrix = kappas[c("PO", "FS", "HS", "U"), ],
      ge_mod_assumed = ge_model_TGIE, # This ( I belive) is the same one that Diana used
      ge_mod_true = ge_model_TGIE,
      ge_mod_assumed_pars_list = list(epsilon = 0.005),
      ge_mod_true_pars_list = list(epsilon = 0.005)
    )
}

Qs<-function(Q){simulate_Qij(Q, 
                           calc_relats = c("PO", "FS", "HS","U"),
                           sim_relats = c("PO", "FS", "HS", "U") )
}
```

make database
```{r, warning=F, message=F, error=F, echo=F}
library(CKMRsim)
water_ckmr<-'LML' # when running this for a new lake, will need to uncomment and run the for loop below "hwe_out<-tibble(), which calculates HWE for each locus

# Prep the genos going in into a long format
    long_genos<-genind2df(obj, sep = '/') %>% 
      as_tibble(rownames = 'GENID_duplicate') %>% 
      pivot_longer(-c(GENID_duplicate, pop), names_to = 'Locus') %>% 
      left_join(dplyr::select(phenos, GENID_duplicate, WATER)) %>% 
      filter(WATER == water_ckmr) %>% 
      dplyr::select(GENID_duplicate, Locus, value) %>% 
      separate(value, into = c('1','2'), sep = '/') %>% 
      pivot_longer(-c(GENID_duplicate, Locus)) %>% 
      rename(Indiv = GENID_duplicate, gene_copy = name, Allele = value) %>% 
      filter(!is.na(Allele), Allele != '', Allele != 'NA', Allele != 'N', !str_detect(Allele, 'NN')) 

# filter the long_genos for loci that don't show Ho deficit and for matching genotypes
    matchers_lake<-read_csv('/workdir/smallmouth/gtseq/results/matching_parentage_loci.csv') 
    
    long_genos<-filter(long_genos, Indiv %nin% matchers_lake$indiv_1)

# Run all CKMR analyses
    afreqs_ready <- long2freqs(long_genos) # generate allele frequency, index alleles
    ex1_ckmr<-create_ckmr_simple(afreqs_ready) # Generate the CKMR object and plot how well we can separate relationships
    ex1_Qs<-Qs(ex1_ckmr)
    
# Plot histogram of allele counts
    afreqs_ready %>%
        group_by(Locus) %>%
        summarise(num_haplotypes = n()) %>%
        group_by(num_haplotypes) %>%
        summarise(num_loci = n()) %>% # plot this for figure 1
        ggplot(., aes(num_haplotypes, num_loci)) +
        geom_histogram(stat = "identity") + theme_bw() + xlab("Number of Alleles") + ylab("Number of Loci")
     # ggsave(paste0('/workdir/smallmouth/gtseq/results/ckmr_haps_',water_ckmr,'.png'))

# plot Q's
      bind_rows(
            extract_logls(ex1_Qs, numer = c(PO = 1), denom = c(U = 1)),
            extract_logls(ex1_Qs, numer = c(FS = 1), denom = c(U = 1)),
            extract_logls(ex1_Qs, numer = c(HS = 1), denom = c(U = 1)),
            extract_logls(ex1_Qs, numer = c(PO = 1), denom = c(FS = 1))) %>% 
            filter(denom_wts == "U=1") %>%
            ggplot(., aes(x = logl_ratio, fill = true_relat)) +
              geom_density(alpha = 0.35) +
              facet_wrap(~ numer_wts, ncol = 1) + ggtitle('Panel power for separating full-sibs, half-sibs, and parent-offspring\n pairs from unrelated fish')
        #  ggsave(paste0('/workdir/smallmouth/gtseq/results/ckmr_power_po_fs_',water_ckmr,'.png'), height = 2.5, width = 5)

# find matchers 
    matchers<-find_close_matching_genotypes(
            LG = long_genos,
            CK = ex1_ckmr, 
            max_mismatch = 5)

        # if we have matchers, write a csv and exclude this above. the first time I run this I'll need to make a new csv
          if(length(matchers$indiv_1)>0){
            bind_rows(matchers, read_csv('/workdir/smallmouth/gtseq/results/matching_parentage_loci.csv')) %>% 
              write_csv('/workdir/smallmouth/gtseq/results/matching_parentage_loci.csv')
          }
```

get POPs and FSPs
```{r, warning=F, message=F, error=F, echo=F}
# run ckmr on each year for adu and yoy
    PO_potential<-tibble()
    FS_potential<-tibble()
    ckmr_in<- phenos %>% 
      filter(GENID_duplicate %in% long_genos$Indiv)

    for(yr in unique(ckmr_in$predict_birthYr)){
      print(yr)
    #  yr<-2015
      
      # First, grab POPs from that cohort
      try({
          yoy<-filter(ckmr_in, predict_birthYr == yr)
          
          adu<-ckmr_in %>% 
            filter((between(predict_birthYr, yr-9, yr-3)) | (year==yr & mature==1)) %>% # we have some 9yo!
            filter(year>=yr)  # they can't be used for this year if they've already been taken out of the system

          PO_potential<-pairwise_kin_logl_ratios(D1=filter(long_genos, Indiv %in% adu$GENID_duplicate),
                                                 D2=filter(long_genos, Indiv %in% yoy$GENID_duplicate),
                                                 CK=ex1_ckmr, 
                                                 numer='PO',
                                                 denom='U') %>% 
          mutate(cohort=yr) %>% 
          bind_rows(PO_potential)
      })
      
      # Next, grab FSP
      try({
        yoy<-filter(ckmr_in, predict_birthYr == yr)
        
        FS_potential<-pairwise_kin_logl_ratios(D1=filter(long_genos, Indiv %in% yoy$GENID_duplicate),
                                               D2=filter(long_genos, Indiv %in% yoy$GENID_duplicate),
                                               CK=ex1_ckmr,
                                               numer='FS',
                                               denom='U') %>% 
          mutate(cohort=yr) %>% 
          bind_rows(FS_potential)
      })
  }

# process and export PO
    cut_math<-0.1*(nrow(PO_potential)^-1)
    FPRs_PO<-mc_sample_simple(ex1_Qs, nu = "PO",de = "U",lambda_stars = seq(0,15, 0.01))
    logL_cut<-filter(FPRs_PO, FPR < cut_math) %>% slice(1)
    
    PO_potential  %>%
      mutate(pairN = row_number()) %>% 
      dplyr::select(pairN, D1_indiv, D2_indiv, logl_ratio) %>% 
      pivot_longer(-c(pairN, logl_ratio), values_to='GENID_duplicate') %>% 
      left_join(dplyr::select(phenos, GENID_duplicate, predict_birthYr, year), by = 'GENID_duplicate') %>% 
      mutate(name = str_replace(name, 'GENID_','')) %>% 
      pivot_wider(names_from=name, values_from = c(GENID_duplicate, predict_birthYr, year), names_glue = "{.value}_{name}") %>% 
      mutate(confirmed = if_else(logl_ratio>logL_cut$Lambda_star, 1, 0)) %>% 
      write_csv('/workdir/smallmouth/gtseq/results/PO_potential.csv')
    
# process and export FS
    cut_math<-0.1*(nrow(FS_potential)^-1)
    FPRs_FS<-mc_sample_simple(ex1_Qs, nu = "FS",de = "U",lambda_stars = seq(0,15, 0.01))
    logL_cut<-filter(FPRs_FS, FPR < cut_math) %>% 
      slice(1)
    
    FS_potential  %>%
      mutate(pairN = row_number()) %>% 
      dplyr::select(pairN, D1_indiv, D2_indiv, logl_ratio, cohort) %>% 
      pivot_longer(-c(pairN, logl_ratio, cohort), values_to='GENID_duplicate') %>% 
      left_join(dplyr::select(phenos, GENID_duplicate, year), by = 'GENID_duplicate') %>% 
      mutate(name = str_replace(name, 'GENID_','')) %>% 
      pivot_wider(names_from=name, values_from = c(GENID_duplicate, year), names_glue = "{.value}_{name}") %>% 
      mutate(confirmed = if_else(logl_ratio>logL_cut$Lambda_star, 1, 0)) %>% 
      write_csv('/workdir/smallmouth/gtseq/results/FS_potential.csv')
```

Consolidate export for Ben
```{r}
# Just one egg/fry from each nest, unless its the speared male, then can send two
po_include<-phenos %>%  
  mutate(waypoint_egg =if_else(str_detect(SAMPLE, 'NEST'), WAYPOINT, NA_character_)) %>% 
  filter(!duplicated(waypoint_egg) | is.na(waypoint_egg)) %>% 
  filter(!str_detect(waypoint_egg, '2022__541 or 558|NULL|a|b') | is.na(waypoint_egg)) %>% 
  filter(!duplicated(long_snorkel) | is.na(long_snorkel)) %>% 
  filter(!duplicated(lat_snorkel) | is.na(lat_snorkel))

# prep phenos dataset for gear type and sex (remove U, replace with NA)
phenos_ben<-phenos %>% 
  mutate(gear = if_else(!is.na(SAMPLE) & SAMPLE=='FISH_GEN', 'SPEAR',
                        if_else(!is.na(SAMPLE) & str_detect(SAMPLE, 'NEST'), 'EGG', GEAR)),
         sex = if_else(sex == 'U', NA_character_, sex))

read_csv('/workdir/smallmouth/gtseq/results/PO_potential.csv') %>% 
  filter(GENID_duplicate_D1_indiv %in% po_include$GENID_duplicate,
         GENID_duplicate_D2_indiv %in% po_include$GENID_duplicate) %>% 
  dplyr::select(ind_1 = GENID_duplicate_D1_indiv, 
                ind_2 = GENID_duplicate_D2_indiv, 
                birth_yr_1 = predict_birthYr_D1_indiv, 
                birth_yr_2 = predict_birthYr_D2_indiv, 
                capture_year_1 = year_D1_indiv, 
                capture_year_2 = year_D2_indiv, 
                POP = confirmed) %>% 
  left_join(dplyr::select(phenos_ben, ind_1 = GENID_duplicate, gear_1 = gear)) %>% 
  left_join(dplyr::select(phenos_ben, ind_2 = GENID_duplicate, gear_2 = gear)) %>% 
  left_join(dplyr::select(phenos_ben, ind_1 = GENID_duplicate, sex_1 = sex)) %>% 
  left_join(dplyr::select(phenos_ben, ind_2 = GENID_duplicate, sex_2 = sex)) %>% 
  write_csv('/workdir/smallmouth/gtseq/results/SMB_LML_PO.csv.gz')

```

## consolidate a bunch of pop gen metrics

Run Ar, Ho, He, HWE, relats, ect, in order to export a figure (2) of pop gen metrics through time
According to Anderson Waples 2017, I should only exclude FSP for Ne and genetic structure, not for He/Ho/Ar/Fst, ect
```{r}
missing_loci<-.05
missing_geno<-.3
min_n<-5 # decide on how many individuals per year we want
xlims<-c(1970, 2020) # the limits on the plots

# prep input data
fst_test<-
  genos %>% 
  left_join(dplyr::select(phenos, GENID_duplicate, predict_birthYr, WATER, year)) %>% 
  filter(WATER == 'LML', str_detect(locus, 'parentage')) %>% 
  mutate(predict_birthYr_guess = if_else(year == 1971, 1971, # throw some numbers in for the predicted birth year for some fishes
                                         if_else(str_detect(year, '2000|2001'), 1998,
                                                 if_else(year == 1998, 1995, NA_integer_))),
         predict_birthYr = coalesce(predict_birthYr, predict_birthYr_guess)) %>% 
  mutate(year_birth = paste0(year, '-', predict_birthYr)) %>% 
  dplyr::select(locus, GENID_duplicate, genoty, year_birth) %>% 
  pivot_wider(names_from = locus, values_from = genoty)

annual_fst_test<-
  df2genind(dplyr::select(fst_test, -c(GENID_duplicate, year_birth)), 
            sep = '/', 
            ploidy = 2, 
            ncode = 2, 
            ind.names = as.character(fst_test$GENID_duplicate), 
            pop = as.character(fst_test$year_birth),
            strata = separate(tibble(t=fst_test$year_birth),t, into = c('year','birth'), sep = '-')) %>% 
  missingno('loci', 0.75) %>% 
  missingno('geno', 0.75) %>% 
    missingno('loci', missing_loci) %>% 
  missingno('geno', missing_geno) %>% 
  setPop(~birth)

# Decide how many loci we need to capture the genetic diversity of the pop - estimate at least 20 loci or so. Use this to tune my missingno(geno)
    #genotype_curve(annual_fst_test)
    
    pop_list<-annual_fst_test@pop %>% # make the list of pops to include bsaed on the filter
      as_tibble() %>% 
      group_by(value) %>% 
      tally() %>% 
      filter(n>=min_n, value != 'NA')

    annual_fst_subset<-annual_fst_test %>% # subset the genind and re-calculate missingno
      popsub(sublist = pop_list$value) %>% 
      missingno('loci', missing_loci) %>% 
      missingno('geno', missing_geno)

# create plots
    Ho_out<-Ho(annual_fst_subset) %>% 
      as_tibble(rownames = 'year') %>% 
      rename(Ho = value) %>% 
      left_join(as_tibble(Hs(annual_fst_subset),rownames = 'year')) %>% 
      rename(He = value) %>% 
      mutate(year = as.integer(year)) %>% 
      rename(Expected = He, Observed = Ho) %>% 
      pivot_longer(-c(year), names_to = 'Heterozygosity') %>% 
      group_by(year) %>% 
      mutate(min = min(value), max = max(value)) %>% 
      ggplot() +
      geom_vline(xintercept = 2000.5, lty='dashed') +
      geom_ribbon(aes(year, value, ymin = min, ymax = max), alpha = 0.2) +
      scale_fill_manual(values = c('white','black')) +
      geom_segment(aes(x=year, y=min, xend=year, yend=max), alpha = 0.5) +
      geom_point(aes(year, value, fill = Heterozygosity), shape = 21) +
      theme_cowplot() +
      labs(x = '', y = 'Heterozygosity') +
      xlim(xlims) +
      theme(axis.title.x=element_blank(),
            axis.text.x = element_blank()) +
      ggtitle("A")

    # Fst
      obj_genepop<-annual_fst_subset %>% 
        graph4lg::genind_to_genepop() %>% 
        separate(ID, into = c('ID','drop'), sep = '_gtseq_') %>% # Need to get rid of the indivdiual labels so we can compare populations, not individuals
        dplyr::select(-drop)

      obj_pair_D<-diveRsity::diffCalc(obj_genepop, pairwise = T, bs_pairwise = T, boots = 1000, para = T, fst = T)
      
      Fst_out<-obj_pair_D$bs_pairwise %>% 
        as.data.frame() %>% 
        rename(year_comp = gst.populations) %>% 
        dplyr::select(-contains('populations')) %>% 
        pivot_longer(-year_comp) %>% 
        separate(name, into = c('Test','measure'), sep = '\\.') %>% 
        separate(year_comp, into = c('year1','year2'), sep = ' vs ') %>%
        mutate(year1 = as.integer(year1),
               year2 = as.integer(year2),
               year_diff = abs(year1-year2)) %>% 
        group_by(year2) %>% 
        filter(year1<year2) %>% 
        filter(year_diff == min(year_diff),
               year_diff<55,
               str_detect(Test, 'Fst|gst')) %>%
        pivot_wider(names_from = measure, values_from = value) %>% 
        mutate(`5% CI > 0` = if_else(lower<0, 'no','yes'),
               actual_per_year = actual / year_diff) %>% 
        ggplot(aes(year2, actual_per_year)) +
        geom_line(aes(group = Test)) +
        geom_point(aes(color = `5% CI > 0`, shape = Test), size = 3) + 
        theme_cowplot() +
        labs(y = 'Annual genetic\ndivergence') +
        xlim(xlims) +
        geom_vline(xintercept = 2000.5, lty='dashed')  +      
        theme(axis.title.x=element_blank(),
              axis.text.x = element_blank()) +
        ggtitle("D")

    # Ne
      # group fish into bins of three years, then exclude nests (will increase Ne estimate)
    fam_prune<-2# how many members of each family should we grab?  no more than 2
    
    geno_count<-annual_fst_subset %>% 
      genind2df() %>% 
      as_tibble(rownames = 'GENID_duplicate') %>% 
      pivot_longer(-GENID_duplicate) %>% 
      filter(!is.na(value)) %>% 
      group_by(GENID_duplicate) %>% 
      tally()
    
    fst_grouped<-annual_fst_test %>% 
      genind2df() %>% 
      as_tibble(rownames = 'GENID_duplicate') %>%
      mutate(year = as.integer(as.character(pop))) %>% 
      mutate(pop =if_else(between(year, 1994, 1997), 1996,
                  if_else(between(year, 1999, 2003), 2002,
                  if_else(between(year, 2004, 2006), 2005,
                  if_else(between(year, 2007, 2009), 2008,
                  if_else(between(year, 2010, 2012), 2011,
                  if_else(between(year, 2013, 2015), 2014,
                  if_else(between(year, 2016, 2018), 2017,
                  if_else(between(year, 2019, 2023), 2020, NA_integer_))))))))) %>% 
      filter(!is.na(pop)) %>% 
      left_join(dplyr::select(phenos, GENID_duplicate, SAMPLE)) %>% 
      filter(!str_detect(SAMPLE, 'NEST') | is.na(SAMPLE)) %>% 
      dplyr::select(-c(SAMPLE,year))

    tracked_out<-tibble()
    for(year_test in unique(fst_grouped$pop)){
      
      inds_in_ne<-fst_grouped %>% 
        filter(pop == year_test) %>% 
        left_join(dplyr::select(obj_fams, GENID_duplicate, fam_index)) %>% 
        pivot_longer(-c(GENID_duplicate, fam_index, pop)) %>% 
        filter(!is.na(value)) %>% 
        group_by(GENID_duplicate, fam_index) %>% 
        tally() %>% 
        group_by(fam_index) %>% 
        arrange(desc(n),.by_group = T) %>% 
        slice_sample(n=fam_prune) %>% 
        ungroup()      
      
      tracked_out<-bind_rows(tracked_out, inds_in_ne)
    }
  
  # Now with this pruned list, run LDNe
      ne_intermediate<-fst_grouped %>% 
        filter(GENID_duplicate %in% tracked_out$GENID_duplicate) %>% 
        arrange(pop) %>% 
        mutate(ind_temp = paste0('ind-',row_number()),
               pop_temp = paste0('pop-', as.integer(pop)))
      
      ne_in<-ne_intermediate %>% 
        dplyr::select(-c(GENID_duplicate, pop)) %>% 
        relocate(ind_temp, pop_temp)
      
      setwd('/workdir/smallmouth/rLDNe/')
      wd<-'/workdir/smallmouth/rLDNe/'

      gp_file<-RLDNe::write_genepop_zlr(loci = ne_in[,3:ncol(ne_in)],
                                 pops =  ne_in$pop_temp, # to look at Ne across all pops, just set this as 1
                                 ind.ids = ne_in$ind_temp,
                                 folder = wd,filename ="genepop_output_smb.txt",
                                 missingVal = NA,
                                 ncode = 2,
                                 diploid = T)
      
      param_files<- RLDNe::NeV2_LDNe_create(input_file = gp_file$Output_File,
                                     param_file = paste0(wd,"Ne_params_smb.txt"), 
                                     NE_out_file = paste0(wd,"Ne_out_smb.txt"), 
                                     matingsystem = 0, 
                                     crit_vals = 0.05)
      
      RLDNe::run_LDNe(LDNe_params = param_files$param_file)

      ne__out<-readLines('Ne_out_smbxLD.txt')
      
        
      joiner<-
       ne_intermediate %>% 
         mutate(Population = str_replace(pop_temp, 'pop-', ''),
                pop = as.integer(as.character(pop))) %>% 
         dplyr::select(ind_temp, pop, Population) 
      
      final_line<-grep('Total number of populations', ne__out)-4
      
      ne_fig<-ne__out[seq(16, final_line, 2)] %>% # need to set 40 to the last informative line
        as_tibble() %>% 
        separate(value, into = c('Population','xx'), sep = ':') %>% 
        mutate(xx = str_squish(xx)) %>%  # get rid of those rows of spaces
        separate(xx, into = as.character(1:14), sep = ' ') %>% 
        mutate(ind_temp = as.character(`1`), n = as.double(`2`), Ne = as.double(`8`), low = as.double(`11`), high = as.double(`12`)) %>% 
        mutate(Population = str_squish(Population)) %>%  # get rid of those rows of spaces
        left_join(joiner, by = 'ind_temp') %>% 
        filter(Ne>0) %>% 
        ggplot(aes(pop, Ne)) + 
        geom_point() + 
        geom_line() + 
        geom_ribbon(aes(ymin = low, ymax = high), alpha = 0.2) + 
        #scale_y_log10() + 
        theme_cowplot() + 
        labs(x='', y = 'Effective population\nsize') + 
        geom_vline(xintercept = 2000.5, lty='dashed') +
        xlim(xlims)  +
        theme(axis.title.x=element_blank(),
              axis.text.x = element_blank()) +
        ggtitle("B")

      
# Bring in relatedness within cohort, excluding egg samples. just freee-swimming BEF fish
   fs_in<-read_csv('/workdir/smallmouth/gtseq/results/FS_potential.csv') %>% 
     rename(D1 = GENID_duplicate_D1_indiv, D2 = GENID_duplicate_D2_indiv) %>% 
     filter(D1 %nin% filter(phenos, str_detect(SAMPLE, 'NEST'))$GENID_duplicate & 
            D2 %nin% filter(phenos, str_detect(SAMPLE, 'NEST'))$GENID_duplicate)
  
   sampled_n<-15
   n_boot<-1000
   fams_rare_out<-tibble()
   for(year_in in unique(fs_in$cohort)){
     fs_loop<-fs_in %>% 
      filter(cohort == year_in)
     
      build_fams<-fs_loop %>% 
        filter(confirmed == 1) %>% 
        dplyr::select(D1, D2)
      
      g3<-simplify(graph.data.frame(build_fams[order(build_fams[[1]]),], directed = F))
  
      fam_matrix<-
        components(g3)$membership %>% 
        as_tibble(rownames = 'GENID_duplicate') %>% 
        right_join(tibble(GENID_duplicate = unique(fs_loop$D1))) %>% 
        arrange(value) %>% 
        mutate(fam_index = if_else(is.na(value), as.double(row_number()), value), # add sequential numbers
               fam_index = as.double(as.factor(fam_index))) 
     
     if(nrow(fam_matrix)>sampled_n){
       for(boot in 1:n_boot){
        boot_in<-fam_matrix %>% 
           slice_sample(n=sampled_n, replace = F) %>% 
           filter(!duplicated(fam_index))
        fams_rare_out<-bind_rows(fams_rare_out,
                                 tibble(year = year_in,
                                        boots = boot,
                                        n_fams = nrow(boot_in),
                                        n_total = nrow(fam_matrix)))
       }
     }
   }

      # Make a summarised dataset 
      final_dat<-
        fams_rare_out %>% 
        mutate(n_sibs = sampled_n-n_fams,
          percent_sibs = n_sibs/sampled_n) %>% 
        group_by(year) %>% 
        summarise(mn = mean(percent_sibs), 
                  sd_f = sd(percent_sibs), 
                  n_total = unique(n_total)) %>% 
        mutate(se_f = sd_f / sqrt(n_total),
               lower_ci = mn - qt(1 - (0.05 / 2), n_total - 1) * se_f, # calculate 95% upper and lower confidence interval
               upper_ci = mn + qt(1 - (0.05 / 2), n_total - 1) * se_f) 

      # Check if the number of samples in a year impacts the mean or CI. It doesn't change the mean or 95% CI
      summary(lm(mn~n_total, data = final_dat)) # mn, upper_ci, lower_ci
      ggplot(final_dat, aes(mn, n_total)) + geom_point() + geom_smooth(method = 'lm')

      # Plot with 95% CI
      fs_cohort<-ggplot(final_dat, aes(year, mn)) + 
        geom_point() + 
        geom_line() + 
        geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), alpha = 0.2) + 
        theme_cowplot() + 
        labs(x='Year', y='Full-sibling\nproportion in cohort') + 
        xlim(xlims) + 
        geom_vline(xintercept = 2000.5, lty='dashed') +
        ggtitle("E")

# include overall CPUE
    cp_year<-read_csv('/workdir/smallmouth/gtseq/results/cpue_overall.csv') %>% 
      ggplot(aes(year, cpue)) +
      geom_vline(xintercept = 2000.5, lty = 'dashed') +
      geom_smooth(span = .1) +
      xlim(xlims) +
      theme_cowplot() +
      labs(x = '', y = 'Catch / minute') +
      theme(axis.title.x=element_blank(),
            axis.text.x = element_blank()) +
      ggtitle("C")

# Generate final plot
    plot_grid(
      plot_grid(
        Ho_out + theme(legend.position = "none")
        , ne_fig
        , cp_year
        , Fst_out + theme(legend.position = 'none')
        , fs_cohort
        , ncol = 1
        , align = "v")
      , plot_grid(
        get_legend(Ho_out)
        , ggplot() + theme(panel.background = element_blank())
        , ggplot() + theme(panel.background = element_blank())
        , get_legend(Fst_out)
        , ggplot() + theme(panel.background = element_blank())
        , ncol =1)
      , rel_widths = c(10,3)
      )
    
    ggsave('/workdir/smallmouth/chapter_3_exports/fig3.png', height=12, width = 8)
    
# Sanity check (to go in the supplement) - do we see systematic bias in # of scoring loci?
    annual_fst_test %>% 
      genind2df() %>% 
      as_tibble(rownames = 'ind') %>% 
      pivot_longer(-c(ind, pop)) %>% 
      filter(!is.na(value))  %>% 
      group_by(ind, pop) %>% 
      summarise(prop_loci = n()/32) %>% 
      mutate(year = as.integer(as.character(pop))) %>% 
      ggplot(aes(year, prop_loci)) +
      geom_count() +
      theme_cowplot() +
      labs(x = 'Year', y = 'Proportion of scoring loci\nper individual')
    ggsave('/workdir/smallmouth/gtseq/results/prop_scoring_loci_perInd.png', height = 4, width = 7)
```



# Supplement

## Biomass kilo/hour in the spring

```{r}
# Figure 1f: biomass
      # Estimate weight for all LML fish to look at biomass cpue
      AF_biomass<-allFish %>% 
        filter(!is.na(LENGTH), !is.na(WEIGHT), WATER=='LML', year>1994, (GEAR_CODE=='NAF' | GEAR_CODE == 'NBO'), between(month,5,6))
      
      AF_LML<-allFish %>% 
        filter(!is.na(LENGTH), WATER=='LML', year>1994, GEAR=='BEF', (GEAR_CODE=='NAF' | GEAR_CODE == 'NBO'), between(month,5,6))
      
      # Tested R2 with and without year as a fixed variable - 0.98 with year, 0.97 without
          # library(ggpmisc) # for putting R2 on graph
          
          # LWdata_logModel <- lm(WEIGHT ~ LENGTH^3 + as.character(year), data = AF_biomass) 
          LWdata_logModel <- lm(log(WEIGHT) ~ log(LENGTH) + as.character(year), data = AF_biomass) 
          
          summary(LWdata_logModel)
          
          AF_LML_weightPred<-
            predict(LWdata_logModel, newdata=AF_LML, interval = "confidence") %>% 
            as_tibble() %>% 
            bind_cols(AF_LML) %>% 
            mutate(weightPred=exp(fit))
          
      # Plot the fit
          ggplot(AF_LML_weightPred, aes(WEIGHT, weightPred)) +
            geom_point() +
            geom_abline()

      # Plot the biomass per u e
        AF_biomass<- AF_LML_weightPred %>%
          mutate(jDate = lubridate::yday(DATE_COL),
               ysamp = str_sub(YSAMP_N, -2)) %>% 
          filter(between(year, 1998, 2020), !is.na(effortSec), (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO'), WATER == 'LML', month<7) %>% 
          group_by(year, SITE_N) %>% 
          filter(jDate == min(jDate)) %>% # Just grab the first jDate of the SITE_N of the year
          filter(ysamp == min(ysamp)) %>% # Just grab the first sampling site of the day
          ungroup() %>% 
          filter(SITE_N %nin% missing_sites$SITE_N,
                 SITE_N %in% site_distances$Site) %>% 
          group_by(year, SITE_N) %>% 
          summarise(cpue_kph = (sum(weightPred)/1000)/(unique(effortSec)/360)) %>% 
          ungroup()
        
    # average before vs after biomass
        bio_summ<-AF_biomass %>% 
          group_by(year) %>% 
          summarise(mean_kph = mean(cpue_kph)) %>% 
          mutate(cpue_gpm = (mean_kph*1000)/60) %>% 
          ungroup() %>% 
          mutate(before_after = if_else(year<2001, 'bef', 'aft')) %>% 
          group_by(before_after) %>% 
          summarise(mean_gpm = mean(cpue_gpm, na.rm = T))
        
    # Biomass decreased by...
        1-bio_summ$mean_gpm[1]/bio_summ$mean_gpm[2]

    #Plot the kilo/hour
      AF_biomass %>% 
        mutate(cpue_gpm = (cpue_kph*1000)/60) %>% 
        ggplot(aes(year, cpue_gpm)) +
        #geom_point() +
        geom_smooth(span=0.1) +
        labs(y = 'Grams / minute', x = 'Year') + 
        geom_vline(xintercept = 2000.5, lty = 'dotted') +
        geom_segment(aes(x = 1998, xend = 2000.5, y = bio_summ$mean_gpm[2], yend = bio_summ$mean_gpm[2])) +
        geom_segment(aes(x = 2000.5, xend = 2020, y = bio_summ$mean_gpm[1], yend = bio_summ$mean_gpm[1])) +
          theme_cowplot()
      ggsave('/workdir/smallmouth/chapter_3_exports/supplement_biomass.png', height=4, width=6)

```

## CPUE by size-class, most robust (seasonal window, first pass, shoreline lengths)

```{r}
  allFish %>%
  mutate(jDate = lubridate::yday(DATE_COL),
         ysamp = str_sub(YSAMP_N, -2)) %>% 
  filter(between(year, 1998, 2020), !is.na(effortSec), (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO'), WATER == 'LML', month<7) %>% 
  group_by(year, SITE_N) %>% 
  filter(jDate == min(jDate)) %>% # Just grab the first jDate of the SITE_N of the year
  filter(ysamp == min(ysamp)) %>% # Just grab the first sampling site of the day
  ungroup() %>% 
  filter(between(jDate, 134, 145)) %>% 
  mutate(lenBin = if_else((LENGTH < 100 | is.na(LENGTH)), '0-100',
                          if_else(between(LENGTH, 100, 200), '100-200',
                                  if_else(LENGTH > 200, '200+', '0')))) %>% 
  group_by(year, effortSec, SITE_N, lenBin) %>% # lenBin
  tally() %>% 
  ungroup() %>% 
  mutate(cpue = (n/effortSec)*60) %>%  # fish per minute 
  dplyr::select(year, SITE_N, lenBin, cpue) %>% 
  pivot_wider(names_from=lenBin, values_from=cpue) %>% 
  mutate_all(~ifelse(is.na(.), 0, .)) %>% # fill in all NA's with zero
  pivot_longer(-c(year, SITE_N), names_to='lenBin',values_to='cpue') %>% 
  group_by(SITE_N) %>% 
  filter(min(year) == 2000) %>% 
  ggplot(aes(year, cpue, group = lenBin, color = lenBin)) +
  geom_point() + 
  geom_line() + 
  facet_wrap(~SITE_N, scales = 'free')  + 
  theme_cowplot() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  geom_vline(xintercept = 2000.5, lty = 'dashed') +
  labs(y = 'Catch per minute of electrofishing', x = 'Year', color = 'Length\nbin\n(mm)') +
  scale_color_viridis_d()
ggsave('/workdir/smallmouth/chapter_3_exports/conservative_filter_cpue.png', height = 10, width = 10)

```

## Seasaonal shift in sampling effort

```{r}
naf_dates<-allFish %>%
  filter(WATER == 'LML', GEAR_CODE == 'NAF') %>% 
  group_by(DATE_COL, SITE_N_NEW) %>% tally() %>% ungroup() %>% 
  group_by(DATE_COL) %>% tally() %>% 
  mutate(jDate = lubridate::yday(DATE_COL),
         year = lubridate::year(DATE_COL)) %>% 
  filter(between(jDate, 100, 200))

# plot
naf_dates %>% 
  ggplot(aes(year, jDate, color = n)) + geom_point() + 
  geom_jitter(height=0, width=0.2) +
  theme_cowplot() +
  scale_color_viridis_c() +
  geom_hline(yintercept = 134, lty = 'dashed') +
  geom_hline(yintercept = 145, lty = 'dashed') +
  labs(x = 'Year', y = 'Julian date', color = 'number\nof\nsites\nsampled')

# get minimum dates
naf_dates %>% 
  group_by(year) %>% summarise(min_julian = min(jDate))

```

## How many adults do we remove each year? CPUE of adults by shoreline length

```{r}
# adult catch through time
    adults_allYears<-allFish %>% 
      filter(WATER == 'LML', (LENGTH > 225 | mature == 1), GEAR == 'BEF', year > 1999) %>% 
      group_by(year) %>% 
      tally()
    
    ggplot(adults_allYears, aes(year, n)) + geom_point() + geom_line()
    
    filter(adults_allYears, year == 2000) # number of adults in 2000
    
    filter(adults_allYears, year > 2000) %>% 
      summarise(mean_n = mean(n), sd_n = sd(n))  # number of adults after 2000
      
# CPUE of adults by shoreline length

  # Plot
    allFish %>%
    filter(!is.na(effortSec), (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO'), WATER == 'LML', month<7, between(year,1998, 2020)) %>% 
    left_join(rename(site_distances, 'SITE_N' = 'Site'), by = 'SITE_N') %>% 
    mutate(adults = if_else(LENGTH < 225 | is.na(LENGTH), 0, 1)) %>% # account for days with 0 adults
    filter(!is.na(SITE_N), !is.na(Shape_Length)) %>% 
    group_by(year, SITE_N, DATE_COL, Shape_Length) %>%
    summarise(n_adults = sum(adults),
              effortSec = unique(effortSec)) %>% # Number of fish over 225 caught on each date, site, and year
    ungroup() %>% 
    group_by(year, SITE_N) %>% 
    mutate(day_index=as.numeric(factor(as.character(DATE_COL)))) %>% # Just grab the first day
    ungroup() %>% 
    filter(day_index==1) %>% # Just grab the first NAF days of each site of each year
    filter(SITE_N %nin% missing_sites$SITE_N, # exclude the sites that were not well-covered
           SITE_N != 'BEF.LML.001') %>% 
    mutate(cpue = (n_adults/effortSec)*60) %>%   #  effortSec OR Shape_Length
    ggplot(aes(year, cpue)) + # , color = lenBin, lty = lenBin
    geom_boxplot(aes(group = year)) +
    geom_smooth(span=0.15) +
    #scale_y_continuous(trans='log10') +
    geom_vline(xintercept = 2000.5, lty = 'dotted') +
    theme_cowplot() +
    labs(x='', y = 'Adult catch / minute')
ggsave('/workdir/smallmouth/figures/lml_cpue_adults_shoreline.png',height=4, width=6) # 2, 4 for main paper

allFish %>% 
  filter(GEAR == 'BEF' , year == 1998, WATER == 'LML') %>% 
  group_by(YSAMP_N, SITE_N, monthDay, effortSec, GEAR_CODE) %>% tally()

allFish %>% 
  group_by(SITE_N) %>% tally()

```

## CPUE without length bins

```{r}
library(lubridate)

lubridate::yday
# Generate the dataset
  cpue_AF<-allFish %>%
    mutate(jDate = lubridate::yday(DATE_COL),
         ysamp = str_sub(YSAMP_N, -2)) %>% 
    filter(between(year, 1998, 2020), !is.na(effortSec), (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO'), WATER == 'LML', month<7) %>% 
    group_by(year, SITE_N) %>% 
    filter(jDate == min(jDate)) %>% # Just grab the first jDate of the SITE_N of the year
    filter(ysamp == min(ysamp)) %>% # Just grab the first sampling site of the day
    ungroup() %>% 
    filter(SITE_N %nin% missing_sites$SITE_N,
           SITE_N %in% site_distances$Site) %>% 
    group_by(year, SITE_N) %>% 
    summarise(cpue = (n()/unique(effortSec))*60) %>% 
    ungroup() %>% 
    write_csv('/workdir/smallmouth/gtseq/results/cpue_overall.csv')

# average before vs after biomass
    cpue_summ<-cpue_AF %>% 
      group_by(year) %>% 
      summarise(mean_kph = mean(cpue)) %>% 
      ungroup() %>% 
      mutate(before_after = if_else(year<2001, 'bef', 'aft')) %>% 
      group_by(before_after) %>% 
      summarise(mean_kph = mean(mean_kph, na.rm = T))
    
# CPUE increased by...
    cpue_summ$mean_kph[1]/cpue_summ$mean_kph[2]-1
    
#Plot the cpue/hr
  cpue_AF %>% 
    ggplot(aes(year, cpue)) +
    #geom_point() +
    geom_smooth(span=0.1) +
    labs(y = 'Fish / minute', x = 'Year') + 
    geom_vline(xintercept = 2000.5, lty = 'dotted') +
    geom_segment(aes(x = 1998, xend = 2000.5, y = cpue_summ$mean_kph[2], yend = cpue_summ$mean_kph[2])) +
    geom_segment(aes(x = 2000.5, xend = 2020, y = cpue_summ$mean_kph[1], yend = cpue_summ$mean_kph[1])) +
      theme_cowplot()
  ggsave('/workdir/smallmouth/chapter_3_exports/supplement_cpue.png', height=4, width=6)
```


## Effort through suppression years

```{r}
# first bring in Ben's site distances
site_distances<-read_csv('/workdir/smallmouth/ecological/BEFsites_LengthAndHabitat_BMQ_070318_1_shoreline_distances.csv') %>% 
  filter(Water=='LML') %>% 
  dplyr::select(Site=SITE_N, Shape_Length)

# total BEF effort (days) across years
effort_BEF_years<-filter(allFish, WATER == 'LML', GEAR == 'BEF', between(year, 2000, 2020)) %>% 
  group_by(year, month, day) %>% 
  tally() %>% 
  ungroup() %>% 
  group_by(year) %>% 
  summarise(removal_electrofishing_days_nights = n())

# total BEF effort (hours) across years. There are quite a few missing values for effort, so just running with unique YSAMP_N's
filter(allFish, WATER == 'LML', GEAR == 'BEF', between(year, 2000, 2020)) %>% 
  group_by(year, YSAMP_N) %>% 
  summarise(effort = sum(effortSec), 
            n_bass = n()) %>% 
  filter(is.na(effort)) %>% 
  write_csv('/workdir/smallmouth/gtseq/results/no_effort.csv')

# total removal days all years - plot both days and fish removed
coeff <- 300 # the transformation to bring the second axis into line with the first

filter(allFish, WATER == 'LML', GEAR == 'BEF', between(year,2000,2022)) %>% 
  group_by(year, month, day) %>% 
  tally() %>% 
  ungroup() %>% 
  group_by(year) %>% 
  summarise(Days_electrofished = n(),
            fish_captured = sum(n)) %>% 
  ggplot(aes(year)) +
  geom_point(aes(y=Days_electrofished), color = 'blue') +
  geom_point(aes(y=fish_captured/coeff), , color = 'green') +
  geom_line(aes(y = Days_electrofished), color = 'blue') +
  geom_line(aes(y = fish_captured/coeff), color = 'green') +
  scale_y_continuous(
    name = "Days of electrofishing (blue)",
    sec.axis = sec_axis(~.*coeff, name="Total bass removed (green)")
  ) +
  theme_cowplot() +
  lims(x = c(1998, 2020)) +
  geom_vline(xintercept = 2000.5, lty = 'dashed')

# Use Kurt's missing sites. Note - I consolidated 2000 across May and June
missing_sites_all_years<-read_xlsx('/workdir/smallmouth/ecological/kurt_matched_naf_surveys.xlsx', sheet = 'missing_sites_2000consolidated') %>% 
   mutate(Site = paste0('BEF.LML.',as.character(str_pad(Spring_NAF_missing_sites, 3, pad = "0"))),
          keep = 0) %>% 
  dplyr::select(year, Site, keep)

# Total number of fish removed each year
fish_removed<-allFish %>% 
  filter(WATER == 'LML', GEAR == 'BEF', between(year, 2000, 2022)) %>% 
  group_by(year) %>% 
  summarise(n_fish = n())

# average number of fish removed yearly
summarise(fish_removed, mean(n_fish), sd(n_fish))

# How many days were there of electrofishing surveys in '98 and '99?
allFish %>% 
  filter(WATER == 'LML', GEAR == 'BEF', between(year, 1998, 1999)) %>% 
  group_by(year, month, day) %>% 
  tally() %>% 
  ungroup() %>% 
  group_by(year) %>% 
  tally()

# Make a table of total sites (number, percent) and distance of shoreline shocked (meters, percent)
tibble(year = rep(1998:2020, each=32), Site = rep(site_distances$Site[1:32], 23)) %>% 
  left_join(missing_sites_all_years, by = c('year', 'Site')) %>% 
  left_join(site_distances, by = 'Site') %>% 
  mutate(keep = if_else(is.na(keep), 1, 0)) %>% 
  group_by(year, keep) %>% 
  summarise(total_sites = n(),shoreline_shocked_km = round(sum(Shape_Length),-1)/1000) %>% 
  filter(keep == 1) %>% 
  mutate(site_proportion = round(total_sites/32,2),
         shoreline_shocked_proportion = round(shoreline_shocked_km/11.54,2)) %>% 
  left_join(effort_BEF_years, by = 'year') %>% 
  left_join(fish_removed, by = 'year') %>% 
  dplyr::select(year, total_sites, site_proportion, shoreline_shocked_km, shoreline_shocked_proportion, removal_electrofishing_days_nights, n_fish) %>% 
  write_csv('/workdir/smallmouth/ecological/total_sites_missing_shoreline_missing.csv')

```

## LD through removal for lg19
```{r}
lg_19_loci<-read_csv('/workdir/smallmouth/gtseq/results/lg19_loci.csv')
lg_in<-'lg19'
yrs<-tibble(start = c(1950, 2009, 2016), end = c(2008, 2015, 2023))
  for(yr_in in 1:nrow(yrs)){
    yr_start <-yrs[yr_in,]$start
    yr_end <-yrs[yr_in,]$end

  # first, convert NA's to 0 and add 1 to other genotyp values. change locus name to position. set position
    adapt_gdat_prep<-microhap_snp %>% filter(str_detect(locus, lg_in), str_detect(locus, 'adaptive'), locus %in% lg_19_loci$locus) %>% # This isjust for the interesting loci on lg19
      left_join(phenos, by = 'GENID_duplicate') %>% 
      filter(WATER == 'LML', between(year, yr_start, yr_end)) %>% 
      separate(locus, into = c('locus','pos1'), sep = '-pos') %>% 
      separate(locus, into = c('xx','pos2'), sep =paste0(lg_in,'_')) %>% 
      mutate(pos = round((as.double(pos1)+as.double(pos2))/1e6),1) %>% 
      dplyr::select(Ind=GENID_duplicate, pos, AlleIdx_genoty) %>% 
      arrange(pos)
    
    adapt_gdat<- pivot_wider(adapt_gdat_prep, names_from='pos', values_from=AlleIdx_genoty) %>% 
      dplyr::select(-Ind) %>% 
      as.matrix()

    corplot<-as_tibble(adapt_gdat)
    colnames(corplot) <- paste0(colnames(corplot),' Mbp')
    cor_year<-cor(corplot, method = 'spearman', use='pairwise.complete.obs')
    ggcorrplot ::ggcorrplot(corr = cor_year,lab_size = 3, title = paste0(yr_start, '-',yr_end,' Little Moose ',lg_in)) #  lab = T
    ggsave(paste0("/workdir/smallmouth/gtseq/results/corrplot-LML-",lg_in,"-start",yr_start,"-end",yr_end,".png"), height = 4, width = 4)

 # }
}
```

## PMRN in Little Moose across the years
```{r}
year_sep<-3 # how many years to bin by?

L50_out<-tibble()
quantiles<-c(0.25, 0.5, 0.75) # pick which quantiles we want to extract
for(sex_in in c('M', 'F')){
  for(ageLengthed_in in 2:5){
    for(year_in in seq(2000, 2023, year_sep)){
    glm_in<-allFish %>% 
      filter(WATER == 'LML', 
             !is.na(mature), 
             sex == sex_in, 
             ageLengthed == ageLengthed_in, 
             between(year, year_in, year_in+(year_sep-1)))
    try({
      L50 <- tibble(value = as.double(MASS::dose.p(glm(mature ~ LENGTH, 
                                                     family = binomial, 
                                                     data = glm_in),
                                                 p=quantiles)),
                    bin = quantiles,
                    sex=if_else(sex_in=='M', 'Male','Female'), 
                    ageLengthed=ageLengthed_in,
                    year  = as.character(year_in),
                    n = nrow(glm_in),
                    n_mat = nrow(filter(glm_in, mature==1)),
                    n_not_mat = nrow(filter(glm_in, mature==0)))
      L50_out<-bind_rows(L50_out, L50)
    })
    }
  }
}

L50_out %>% 
  filter(n_mat>1, n_not_mat>1) %>% 
  pivot_wider(names_from = bin, values_from = value) %>% 
  ggplot(aes(ageLengthed, color = year, fill = year)) + 
  geom_ribbon(aes(y = `0.5`, ymin = `0.25`, ymax = `0.75`), color = 'lightgrey', alpha = 0.5, position = position_dodge(width = 0.4)) +
  #geom_point(aes(y = `0.5`)) +
    geom_pointrange(aes(y = `0.5`, ymin = `0.25`, ymax = `0.75`), position = position_dodge(width = 0.4)) +

  geom_line(aes(y = `0.5`), position = position_dodge(width = 0.4)) + 
  facet_wrap(~sex, ncol = 1, scales = 'free_y') +
  theme_cowplot() +
  scale_x_continuous(breaks= 2:4) +
  labs(x = 'Age', y = 'Total length (mm)', fill = 'Year', color = 'Year') +
  scale_color_viridis_d('year') +
  scale_fill_viridis_d('year')
ggsave('/workdir/smallmouth/gtseq/results/pmrn_plot.png', height = 4, width = 6)
```

## Compare neutral to adaptive AF change through the suppression

Take the first SNP per microhap
```{r}
# decide on how many individuals per year we want
    min_n<-5

# Build dataset
    fst_test<-
      microhap_snp %>% 
      left_join(dplyr::select(phenos, GENID_duplicate, WATER, year)) %>% 
      filter(WATER == 'LML', (str_detect(locus, 'parentage') | locus %in% loci_selected)) %>% # don't grab the lg7 or sex
      separate(locus, into = c('loc1','pos'), sep = 'pos', remove = F) %>% # grab the first SNP in each locus
      group_by(loc1) %>% 
      filter(pos == min(pos)) %>% 
      ungroup() %>% 
      mutate(loc_type = if_else(str_detect(locus, 'parentage'), 'parent-',
                                if_else(str_detect(locus, 'lg19'), 'lg19-', 'lg6-')),
             locus = paste0(loc_type,as.integer(as.factor(locus))),
             year = if_else(between(year, 1995, 2000), 1998, year)) %>% # rename loci to work in genind
      dplyr::select(locus, GENID_duplicate, genoty, year)
    
# Calculate annual allele frequency change per locus
    af_out<-tibble()
    for(loc_in in unique(fst_test$locus)){
      af_temp<-filter(fst_test, locus == loc_in) %>% 
        group_by(year) %>% 
        mutate(n = n()) %>% 
        filter(n>=min_n) %>% 
        ungroup() %>% 
        dplyr::select(locus, GENID_duplicate, genoty, year) %>% 
        pivot_wider(names_from = locus, values_from = genoty) %>% 
        filter(!is.na(.[[3]])) %>% 
        separate(loc_in, into = c('a','b')) %>% 
        pivot_longer(-c(GENID_duplicate, year))
      
      af_in<-af_temp %>% 
        mutate(alidx = if_else(value == unique(af_temp$value)[1], 1, 0)) %>% 
        group_by(year) %>% 
        summarise(af = mean(alidx)) %>% 
        ungroup() %>% 
        arrange(year) %>% 
        mutate(yeardiff = year - lag(year),
               af_diff = abs(af - lag(af)) / yeardiff,
               loc = loc_in) %>% 
        filter(between(yeardiff, 1, 5))
      
      af_out<-bind_rows(af_out, af_in)
    }
  
    af_out<-af_out %>% 
      mutate(loc_name = if_else(str_detect(loc, 'parent'), ' Neutral', 
                                if_else(str_detect(loc, '19'), 'Chromsome 19','Chromosome 6')),
             neut_af = if_else(loc_name == ' Neutral', af_diff, NA)) 

# individually test each of the years to see if putatively adaptive loci are part of the distribution (sqrt makes it normal)
    pv_out<-tibble()
    for(year_grp in unique(af_out$year)){

      dist_in<-af_out %>% 
        filter(year == year_grp)
    
      # calculate quantiles 
        chr_19_quantile<-ecdf(filter(dist_in, loc_name == ' Neutral')$af_diff)(filter(dist_in, loc_name == 'Chromsome 19')$af_diff)
        chr_6_quantile<-ecdf(filter(dist_in, loc_name == ' Neutral')$af_diff)(filter(dist_in, loc_name == 'Chromosome 6')$af_diff)

      # run p-value test
        pnrom_in<-dist_in %>% 
        group_by(loc_name) %>% 
        summarise(mn = mean(sqrt(af_diff)),
                  sd = sd(sqrt(af_diff)))

        chr_19_pv<-1-pnorm(pnrom_in$mn[3],pnrom_in$mn[1],pnrom_in$sd[1])
        chr_6_pv<-1-pnorm(pnrom_in$mn[2],pnrom_in$mn[1],pnrom_in$sd[1])
        
      # Compile results
        pv_out<-bind_rows(pv_out, tibble(yr = year_grp, q19 = chr_19_quantile, q6 = chr_6_quantile, p19 = chr_19_pv, p6 = chr_6_pv))
    }
    
# Plot the results
    sigs<-pv_out %>% 
      mutate(sig = if_else(p19 < 0.01 | p6 < 0.01, '***',
                           if_else(p19 < 0.05 | p6 < 0.05, '**',
                                   if_else(p19 < 0.1 | p6 < 0.1, '*', ''))))
    
    n_year<-af_out %>% 
      group_by(year) %>% 
      tally()
    
    af_out %>% 
      ggplot() +
      geom_jitter(aes(as.factor(year), neut_af), height = 0, width = 0.1, alpha = 0.1, color = "#1B9E77") +
      geom_boxplot(aes(as.factor(year), af_diff, color = loc_name), outlier.shape = NA) +
      geom_text(data = n_year, aes(x = as.factor(year), y = -0.02, label = n), size = 4) +
      geom_text(data = sigs, aes(x = as.factor(yr), y = -0.05, label = sig), size = 5) +
      theme_cowplot() +
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
      #scale_color_viridis_d(option = 17) +
      scale_color_brewer(palette = 'Dark2') +
      labs(x = 'Capture year', y = 'Annual allele frequency change', color = '')
    ggsave('/workdir/smallmouth/chapter_3_exports/neutral_adaptive_af.png', height = 5, width = 8)

    # RColorBrewer::brewer.pal(n = 3, name = "Dark2")
    
# For the text, get the quantiles of years that exceed the normal distribution
    pv_out %>% 
      filter(p19<0.1 | p6 < 0.1)
```

# Misc paper stats

How many fish are removed each year?
```{r}
allFish %>% 
  filter(WATER == 'LML', GEAR == 'BEF', between(year, 2000, 2020)) %>% 
  group_by(year) %>% 
  tally() %>% 
  ggplot(aes(year, n)) +
  geom_point() +
  geom_line() +
  labs(x = 'year', y = 'bass removed per year') +
  theme_cowplot()
```

Are there consistent biases in fresh : frozen weights or legnths? 1998/9 bass were measured fresh
```{r}
# import 2020 geomorph study where we fresh-measured bass
fresh<-googlesheets4::read_sheet('https://docs.google.com/spreadsheets/d/1kdiVUv7DzwEGC3s5GRjFOWlEk8_OgW498DUjcFCKQ60/edit#gid=2100724345', sheet = 'Data') %>% 
  left_join(allFish, by = 'FISH_N') %>% 
  mutate(weight_fresh_frozen = Weight_g-WEIGHT,
         length_fresh_frozen = Length_mm-LENGTH)

# Weight
  
  fresh %>% 
    ggplot(aes(Weight_g, weight_fresh_frozen)) +
    geom_point() +
    geom_smooth(method = 'lm')
  
  summary(lm(WEIGHT ~ Weight_g, data = fresh))
  
# Length
  fresh %>% 
    left_join(allFish, by = 'FISH_N') %>% 
    ggplot(aes(Length_mm, length_fresh_frozen)) +
    geom_point() +
    geom_smooth(method = 'lm')

  summary(lm(LENGTH ~ Length_mm, data = fresh))

allFish %>% 
  filter(str_detect(FISH_N, '060920'))
```

how many fish in the gtseq panel?
```{r}
genos %>% # genos for final filtered numbers, phenos for input number of individual
  group_by(GENID_duplicate) %>% 
  summarise(n=n()) %>% 
  left_join(phenos, by = 'GENID_duplicate') %>% 
  filter(WATER == 'LML') %>% 
  group_by(year) %>% 
  summarise(prop_loci = mean(n)/94,
            n = n()) %>% 
  ggplot(aes(year, n)) +
  geom_vline(xintercept = 2000.5, lty = 'dashed') +
  geom_label(aes(label = n, fill = prop_loci), size = 2) +
  labs(x='year', y = 'number of fish\ngenotyped (GTseq)', fill = 'proportion\nloci\nsuccessful') 
  ggsave('/workdir/smallmouth/chapter_3_exports/n_per_year_lml.png', height = 3, width = 8)
```

table with sample size for each of our analyses
```{r}
allFish %>% 
  filter(WATER == 'LML', month < 7) %>% 
  dplyr::select(LENGTH, WEIGHT, ageTrue, newGSI, sex) %>% 
  map(~sum(!is.na(.)))

filter(phenos, GENID_duplicate %in% genos$GENID_duplicate) %>% 
  filter(WATER == 'LML', month < 7) %>% 
  dplyr::select(LENGTH, WEIGHT, ageTrue, newGSI, sex) %>% 
  map(~sum(!is.na(.)))
```

What is the allele frequency change in background regions vs three adaptive peaks?
```{r}
fst_adaptive<-read_csv('/workdir/smallmouth/gtseq/results/fst_window_A_D.csv') %>% 
  mutate(adaptive = if_else((name==19 & between(pos, 1.05e07, 2.8e07) | (name==6 & between(pos, 0.2e07, 0.5e07) | (name==7 & between(pos, 2.3e7, 2.6e7)))), 1, 0))

fst_adaptive %>% 
  group_by(adaptive) %>% 
  summarise(median_af = median(fst_mean),
            sd_af = sd(fst_mean))

fst_adaptive %>% 
  filter(fst_mean>0.2)
  ggplot(aes(pos, fst_mean, color = adaptive)) +
  geom_point() +
  facet_wrap(~name)
```

Does genotype frequency change for lg6 and 19 loci as fish age? Maybe. Hard to tell
```{r}
microhap_snp %>% 
  filter(locus %in% loci_selected) %>% 
  left_join(phenos, by = 'GENID_duplicate') %>% 
  filter(WATER == 'LML', str_detect(GEAR, 'BEF|RANG'), SEASON == 'S') %>% 
  group_by(year, ageLengthed, locus) %>% 
  summarise(mean_geno = mean(AlleIdx_genoty)/2,
            n = n()) %>% 
  filter(n>4) %>% 
  ggplot(aes(ageLengthed, mean_geno)) +
  geom_point() +
  geom_smooth(method = 'lm') +
  facet_wrap(~locus)
ggsave('/workdir/smallmouth/gtseq/results/genoty_freq_by_age.png', height = 15, width = 15)
```

Coverage and proportion of reference covered for lcwgs and amplicon
```{r}
# lcwgs pre-filter
read_csv("/workdir/smallmouth/sample_lists/full_read_count.csv") %>% 
  mutate(raw_depth=raw_bases/829000000) %>% 
  filter(str_detect(population, 'Little')) %>% 
  summarise(min(raw_depth), max(raw_depth))

# lcwgs post-filter
read_tsv("/workdir/smallmouth/sample_lists/bam_list_realigned_smb_anchored_mincov_filtered_depth_per_position_per_sample_summary.tsv") %>% 
  filter(str_detect(str_sub(sample_seq_id, 1,1), 'A|D')) %>% 
  summarise(maxdp = max(mean_depth),
            mindp = min(mean_depth),
            mmaxref = max(proportion_of_reference_covered),
            minref = min(proportion_of_reference_covered))

# amplicon
genos %>% 
  summarise(max(read_depth),
            min(read_depth),
            mean(read_depth),
            sd(read_depth))
```

# Submit sequences to NCBI

I've taken all the raw lcwgs files and added them to lcwgs_smb/all_raw
```{bash}
cd /workdir/backup/smallmouth/lcwgs_smb
ftp ftp-private.ncbi.nlm.nih.gov
# username: subftp
# pass: SniappegEtnurak3
cd uploads/zarriliam_gmail.com_GvUkLsf4
mkdir lcwgs_submission
cd lcwgs_submission
put ... # it would seem that I need to upload them individually. in the future, I should gzip all into a single file then upload that
```
# To do

# Scratch pad

Look at the genotypes of bass we've confirmed as parents, do they show different genotype frequency from the rest of the population?
```{r}
read_csv('/workdir/smallmouth/gtseq/results/PO_potential.csv') %>% 
  filter(confirmed == 1) %>% 
  dplyr::select(GENID_duplicate = GENID_duplicate_D1_indiv, year = year_D1_indiv, confirmed) %>% 
  right_join(microhap_snp) %>% 
  filter(locus %in% loci_selected) %>% 
  left_join(read_csv('/workdir/smallmouth/gtseq/results/genoty_idx_converter.csv'), by = c('locus','genoty')) %>% 
  group_by(confirmed, locus, idx_genoty) %>% 
  tally() %>% 
  group_by(confirmed, locus) %>% 
  mutate(prop = n / sum(n)) %>% 
  ggplot(aes(x = as.character(confirmed), y = prop, fill = idx_genoty)) +
  geom_bar(stat = 'identity') +
  facet_wrap(~locus, scales = 'free')
  
```

## Age at maturity for different lakes

Not enough power. We need to age a bunch more otoliths from many lakes
```{r}
allFish %>% 
  mutate(mature = if_else(is.na(mature) & ageLengthed == 1, 0, mature)) %>% 
  filter(year>2012, !is.na(mature), !is.na(sex), !is.na(ageLengthed), ageLengthed < 6) %>% 
  group_by(WATER, sex, ageLengthed, mature) %>% 
  tally() %>% 
  group_by(WATER, sex, ageLengthed) %>% 
  mutate(sum_n = sum(n),
         prop = n / sum_n)  %>% 
  filter(mature == 1, 
         sum_n > 1) %>% 
  ggplot(aes(ageLengthed, prop, color = WATER)) +
  geom_point() +
  geom_line() +
  facet_wrap(~sex)
```