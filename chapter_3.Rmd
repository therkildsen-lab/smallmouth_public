# import R libraries, data from the AFRP database, and genotypes
```{r}
library(tidyverse)
library(poppr)
library(readxl)
library(cowplot)
library(igraph)
library(hierfstat)
library(CKMRsim)
library(statgenGWAS)
library(lubridate)

basedir<-'/workdir/smallmouth/'

# import homemade functions
source(paste0(basedir,
              '/markdowns/functions_copy.R'))

# import data
load(paste0(basedir,
            'chapter_3_exports/smallmouth_adaptation_data.rda.gz'))

```

# Wrangle data for Rdata file
```{r, eval=F, include=F}
ordered_amplicons<-read_csv(paste0(basedir,
                                   'gtseq/all_regions_primers_ordered.csv'))
                            
# import allFish
allFish<- read_csv(paste0(basedir,
                          'ecological/allFish.csv.gz'))

# import snorkel data from 2021 and 2022
snorkel<-googlesheets4::read_sheet('https://docs.google.com/spreadsheets/d/1CJVikWmzlmv0qOtG2X1iLUyslgiJ-4vmgUSnjVO_NcU/edit#gid=0', 
                                   sheet = 'Sheet1')

# First, read in all the fish I've genotyped
allGenotyped_1<-read_xlsx('/workdir/smallmouth/gtseq/AdkLabNotebook_gtseq.xlsx', 
                          sheet = 'samples_production_1') %>% 
  filter(!str_detect(extraction_plate, 
                     '5|6|9')) %>%  # remove the plates I haven't sequenced 
  dplyr::select(GENID, 
                GEN_N, 
                FISH_N, 
                tissue_source,
                tissue_type, 
                extraction_type, 
                extraction_plate, 
                extraction_column, 
                extraction_row) %>% 
  mutate(GENID_duplicate = paste0('gtseq_production_1--', 
                                  GENID))

allGenotyped<-read_xlsx('/workdir/smallmouth/gtseq/AdkLabNotebook_gtseq.xlsx', 
                        sheet = 'samples_production_2') %>% 
  dplyr::select(GENID, 
                GEN_N, 
                FISH_N, 
                OLD_FISH_N, 
                tissue_source,
                tissue_type, 
                extraction_type, 
                extraction_plate, 
                extraction_column, 
                extraction_row) %>% 
  mutate(GENID_duplicate = paste0('gtseq_production_2--', 
                                  GENID)) %>% 
  bind_rows(allGenotyped_1) %>% 
  separate(GENID, 
           into = c('GENID','duplicate'), 
           sep = '-')

# Then read in all snorkel data, with GPS points as lat and lon
snorkel_genid<-snorkel %>% 
  mutate(WAYPOINT = paste0(year, 
                           '__', 
                           as.character(WAYPOINT)), # some duplicates in waypoint, so adding year to it
         ESTIMATED_TL = as.double(as.character(ESTIMATED_TL)), 
         TRANSECT = as.character(TRANSECT),
         NEST_WIDTH = as.double(as.character(NEST_WIDTH)),
         NEST_DEPTH = as.double(as.character(NEST_DEPTH))) %>% 
  pivot_longer(c(NEST_GEN_1, 
                 NEST_GEN_2, 
                 FISH_GEN), 
               names_to = 'SAMPLE', 
               values_to = 'GENID') %>% 
  filter(!is.na(GENID)) %>% 
  dplyr::select(-c(NEST_DESTROYED, 
                   SUCCESSFUL, 
                   NOTES)) %>% 
  mutate(ESTIMATED_TL_parent = if_else(str_detect(SAMPLE, 
                                                  'NEST'), 
                                       as.double(ESTIMATED_TL), 
                                       NA_real_), # set the estimated TL to be paret or adult
         ESTIMATED_TL_fish = if_else(str_detect(SAMPLE, 
                                                'FISH'), 
                                     as.double(ESTIMATED_TL), 
                                     NA_real_)) %>% 
  dplyr::select(-ESTIMATED_TL)

# Splitting this up into several different categories depending on where data is stored

# fish collected via snorkling (only have GENID's) - will have to deal with duplicates
GENIDs<-filter(allGenotyped, 
               str_detect(GENID_duplicate, 
                          "SMB_22_|2021_|SMB_2023")) %>%
  left_join(snorkel_genid, by = 'GENID') 

# fish with GEN_N's, filling in missing WATER and year 
GEN_Ns<-filter(allGenotyped, 
               (GEN_N != 'NA' & is.na(FISH_N)), 
               GENID %nin% GENIDs$GENID) %>% # , !duplicated(GEN_N)
  dplyr::select(-FISH_N) %>% 
  left_join(allFish, by = 'GEN_N') %>% 
  mutate(WATER = if_else(is.na(WATER) & str_detect(GEN_N, 
                                                   'WLL'), 
                         'WLL',
                         if_else(is.na(WATER) & str_detect(GEN_N, 
                                                           'TBL'), 
                                 'TBL',
                                 if_else(is.na(WATER) & str_detect(GEN_N, 
                                                                   'SBL'), 
                                         'SBL',
                                         if_else(is.na(WATER) & str_detect(GEN_N, 
                                                                           'SDL'), 
                                                 'SDL',
                                                 if_else(is.na(WATER) & str_detect(GENID, 
                                                                                   'LML'), 
                                                         'LML', 
                                                         WATER)))))) %>% 
  mutate(year =  if_else(is.na(year) & str_detect(GENID, '22_'),
                         as.numeric(2022),
                         if_else(is.na(year) & str_detect(GENID, '19_'),
                                 as.numeric(2019),
                                 if_else(is.na(year) & (str_detect(GENID, '_F') | str_detect(GENID, '_E')), 
                                         as.numeric(2019), 
                                         if_else(is.na(year) & str_detect(GEN_N, 
                                                                          '19.'), 
                                                 as.numeric(2019), year)))))

# The special speared fish joiner  
speared<-googlesheets4::read_sheet('https://docs.google.com/spreadsheets/d/1CJVikWmzlmv0qOtG2X1iLUyslgiJ-4vmgUSnjVO_NcU/edit#gid=0', 
                                   sheet = 'speared_fish_joiner') %>% 
  dplyr::select(GENID, GENID, GEN_N) %>% 
  left_join(dplyr::select(GENIDs, 
                          GENID, 
                          duplicate, 
                          tissue_source, 
                          tissue_type, 
                          extraction_type, 
                          GENID_duplicate, 
                          year, 
                          WATER, 
                          WAYPOINT, 
                          LONG, 
                          LAT, 
                          EARLIEST_DATE, 
                          SAMPLE, 
                          ESTIMATED_TL_parent, 
                          ESTIMATED_TL_fish, 
                          NEST_WIDTH, 
                          NEST_DEPTH, 
                          EARLIEST_STAGE), 
            by = 'GENID') %>% 
  left_join(dplyr::select(GEN_Ns, 
                          GEN_N, 
                          FISH_N, 
                          GEAR, 
                          LENGTH, 
                          WEIGHT, 
                          GONAD_WEIGHT, 
                          newGSI, 
                          sex, 
                          ageLengthed, 
                          birthYr, 
                          yearly_length_anomaly), 
            by = 'GEN_N')

# put in OLD_FISH_N's
OLD_FISH_Ns<-filter(allGenotyped, 
                    !is.na(OLD_FISH_N)) %>% 
  dplyr::select(-FISH_N) %>% 
  filter(OLD_FISH_N != 'LML.061603.BEF.001.001') %>% # This one links with 2 FISH_N's
  left_join(read_csv('/workdir/smallmouth/ecological/AFRP_MAIN_121923/FISH_N.txt'), 
            by = 'OLD_FISH_N') %>% 
  dplyr::select(-c(OLD_FISH_N, 
                   RECALC_FISH_N, 
                   MEASUREMENT_DATA, 
                   GEN_N)) %>% 
  left_join(allFish, 
            by = 'FISH_N')

# fish with only FISH_N's (no genN's)
FISH_Ns<-filter(allGenotyped, FISH_N != 'NA') %>% # , !duplicated(FISH_N)
  dplyr::select(-GEN_N) %>% 
  left_join(allFish, by = 'FISH_N') %>% 
  left_join(read_csv('/workdir/smallmouth/ecological/results/FISH_N_empty.csv'), by = 'FISH_N') %>% 
  mutate(WATER = if_else(is.na(WATER) & str_detect(FISH_N, 
                                                   'WLL'), 
                         'WLL',
                         if_else(is.na(WATER) & str_detect(FISH_N, 
                                                           'LML'), 
                                 'LML', 
                                 WATER))) %>% 
  mutate(year =  if_else(is.na(year) & str_detect(GENID, 
                                                  '99_'), 
                         as.numeric(1999),
                         if_else(is.na(year) & str_detect(GENID, 
                                                          '00_'), 
                                 as.numeric(2000),
                                 if_else(is.na(year) & str_detect(GENID, 
                                                                  '01_'), 
                                         as.numeric(2001),
                                         if_else(is.na(year) & str_detect(GENID, 
                                                                          '04_'), 
                                                 as.numeric(2004),
                                                 if_else(is.na(year) & str_detect(GENID, 
                                                                                  '20_'), 
                                                         as.numeric(2020),
                                                         if_else(is.na(year) & str_detect(GENID, 
                                                                                          '23_'), 
                                                                 as.numeric(2023),
                                                                 year)))))))

# fish that have no FISH_N, GEN_N, snorkel - aka the pre 2002 fish
scale_data<-read_xlsx('/workdir/smallmouth/gtseq/scale_envelope_data_1950s_on.xlsx', sheet = 'clean')  %>% 
  mutate(LENGTH = as.double(LENGTH), 
         WEIGHT = as.double(WEIGHT), 
         ageTrue = as.double(ageTrue)) %>% 
  filter(!is.na(GENID)) %>% 
  dplyr::select(-c(FISH_N, WATER))

NO_FISHN_GENN<-filter(allGenotyped, is.na(FISH_N), 
                      is.na(GEN_N), 
                      GENID %nin% GENIDs$GENID, 
                      is.na(OLD_FISH_N)) %>% 
  left_join(dplyr::select(read_xlsx('/workdir/smallmouth/gtseq/AdkLabNotebook_gtseq.xlsx', 
                                    sheet = 'samples_production_2'), 
                          GENID, 
                          WATER, 
                          year), 
            by = 'GENID') %>% 
  mutate(year = as.double(year)) %>% 
  full_join(scale_data, by = 'GENID')

# remove the speared fish from GEN_Ns and snorkel and nofishngennn
GEN_Ns<-filter(GEN_Ns, GEN_N %nin% speared$GEN_N)
GENIDs<-filter(GENIDs, GENID %nin% speared$GENID)
NO_FISHN_GENN<-filter(NO_FISHN_GENN, 
                      GENID %nin% speared$GENID)

phenos<-
  bind_rows(GEN_Ns, 
            FISH_Ns, 
            GENIDs, 
            OLD_FISH_Ns, 
            NO_FISHN_GENN, 
            speared) %>% 
  mutate(birthYr = if_else(str_detect(GENID, 'SMB_22_') & str_detect(SAMPLE, 
                                                                     "NEST_GEN"), 
                           2022, # here, adding birth year to snorkel
                           if_else(str_detect(GENID, 
                                              '2021_') & str_detect(SAMPLE, 
                                                                    "NEST_GEN"), 
                                   2021, 
                                   if_else(str_detect(GENID, 
                                                      'SMB_23_') & str_detect(SAMPLE, "NEST_GEN"), 
                                           2023, 
                                           birthYr))),
         eggD = lubridate::yday(EARLIEST_DATE),
         eggDate = if_else(EARLIEST_STAGE == 'Egg', 
                           eggD,
                           if_else(EARLIEST_STAGE=='Grey',
                                   eggD-4,
                                   if_else(EARLIEST_STAGE=='Black', 
                                           eggD-8, NA_real_)))) %>% 
  dplyr::select(-eggD) %>% 
  mutate(GENID_duplicate = str_replace(GENID_duplicate, 
                                       '__',
                                       '--'))

# alternative to microhaps - amplicon.py
genos_withdups<-read_csv('/workdir/backup/smallmouth/gtseq_production_2/amp_py_output/hap_genotype_read_depth.csv') %>% 
  filter(read_depth > 15) %>% 
  left_join(dplyr::rename(ordered_amplicons, 
                          'locus'='microhap_name'), 
            by = 'locus')

# Exclude duplicated individuals from genos
exclude_duped<- genos_withdups %>% 
  group_by(GENID_duplicate) %>% 
  tally() %>%  # make a list of duplicated fish to exclude
  ungroup() %>% 
  left_join(phenos, by = 'GENID_duplicate') %>% 
  group_by(GENID) %>% 
  mutate(n_dups=n()) %>% 
  filter(n_dups>1) %>%  # first get all duplicated
  arrange(GENID, desc(n)) %>% 
  slice_tail(n=-1) %>%  # Then make a list of all but the top scoring individual - this is the list to exclude
  ungroup() 

genos<-genos_withdups %>% 
  filter(GENID_duplicate %nin% exclude_duped$GENID_duplicate)

n_inds<-length(unique(genos$GENID_duplicate))

# read in microhaplot SNP data, exlcuding duplicated individuals, contam inds, and paralogs
microhap_snp<-
  read_csv('/workdir/smallmouth/gtseq/microhaplot/snp_report_gtseq_production_2_depth15.csv') %>% 
  filter(indiv.ID %in% mutate(genos, 
                              GENID_duplicate = str_replace(GENID_duplicate, 
                                                            '--', 
                                                            '__'))$GENID_duplicate,
         locus %nin% read_csv('/workdir/smallmouth/gtseq/results/paralogs.csv')$contig,
         ar>0.2) %>% # exclude contaminated & paralogs, and loci not in the genos (read depth)
  filter(!str_detect(snp, 'N')) %>% 
  mutate(locus=paste0(locus, 
                      '-pos', 
                      pos)) %>% # make a new name
  group_by(locus) %>% 
  mutate(allele_count_per_locus = length(unique(snp))) %>% 
  filter(allele_count_per_locus>1) %>% 
  ungroup() %>%  # removed fixed SNPs
  separate(snp, 
           into=c('snp1',
                  'snp2'), 
           sep = '/', 
           remove = F) %>% 
  rowwise() %>% 
  mutate(genoty=paste0(sort(c(snp1,
                              snp2)),
                       collapse='/')) %>% 
  ungroup() %>% # arrange by alphabet
  dplyr::select(GENID_duplicate=indiv.ID, 
                locus, 
                genoty)

# exclude loci that have more than 30% of individuals missing
n_inds<-length(unique(microhap_snp$GENID_duplicate))

microhap_snp<-microhap_snp %>% 
  group_by(locus) %>% 
  mutate(prop_inds_scoring = n()/n_inds) %>% 
  filter(prop_inds_scoring > 0.7) %>% 
  ungroup()

# code genotypes as 0,1,2
mhap_AlleleIdx<-separate(microhap_snp, 
                         genoty, 
                         into = c('hap1', 
                                  'hap2'), 
                         sep = '/') %>% 
  pivot_longer(-c(locus, 
                  GENID_duplicate, 
                  prop_inds_scoring), 
               names_to = 'gene_copy', 
               values_to = 'allele') %>% 
  filter(!is.na(allele), 
         allele != '', 
         allele != 'N') %>% 
  group_by(locus, 
           allele) %>%
  tally() %>%
  filter(!is.na(allele)) %>%
  mutate(Freq = n / sum(n)) %>%
  arrange(locus, 
          desc(Freq)) %>%
  dplyr::select(-n) %>%
  ungroup() %>% 
  group_by(locus) %>% 
  mutate(n=n()) %>% 
  filter(n == 2) %>% 
  mutate(AlleIdx = c(1,
                     0)) %>%
  ungroup() %>% 
  dplyr::select(-c(Freq,
                   n))

microhap_snp<-separate(microhap_snp, 
                       genoty, 
                       into = c('allele','allele2'), 
                       sep ='/', 
                       remove = F) %>% 
  left_join(mhap_AlleleIdx, 
            by = c('locus','allele')) %>% 
  dplyr::rename(allele_1=allele, 
                AlleIdx_1=AlleIdx, 
                allele=allele2) %>% 
  left_join(mhap_AlleleIdx, 
            by = c('locus',
                   'allele')) %>% 
  dplyr::rename(allele_2=allele, 
                AlleIdx_2=AlleIdx) %>% 
  mutate(AlleIdx_genoty=AlleIdx_1+AlleIdx_2,
         GENID_duplicate = str_replace(GENID_duplicate, 
                                       '__', 
                                       '--'))

# make a genind object of the neutral markers in Little Moose
genos_neutral<-genos %>% 
  left_join(dplyr::select(phenos, 
                          GENID_duplicate, 
                          year, 
                          WATER), 
            by = 'GENID_duplicate') %>% 
  filter(str_detect(WATER, 
                    'LML'),
         str_detect(locus, 
                    'parentage')) %>%
  dplyr::select(locus, 
                GENID_duplicate, 
                genoty, 
                year) %>% 
  pivot_wider(names_from=locus, 
              values_from=genoty) %>% 
  dplyr::rename(ind=GENID_duplicate, 
                pop=year)

obj_preLD_pre_HWE<-df2genind(dplyr::select(genos_neutral, 
                                           -c(ind, 
                                              pop)), 
                             sep = '/', 
                             ploidy = 2, 
                             ncode = 2, 
                             ind.names = as.character(genos_neutral$ind), 
                             pop = as.character(genos_neutral$pop)) %>% 
  missingno('loci',
            0.3) %>% 
  missingno('geno', 
            0.3)

# set strata
strata.df<-tibble(pops = obj_preLD_pre_HWE$pop) 
strata(obj_preLD_pre_HWE) <- strata.df

# exclude loci out of HWE in over 50% of pops
failed_hwe<-read_csv('/workdir/smallmouth/chapter_3_exports/loci_failing_hwe_over_50_percent_years.csv')
obj<- obj_preLD_pre_HWE[loc = setdiff(locNames(obj_preLD_pre_HWE), 
                                      failed_hwe$locus)]

# exclude loci that showed greater than rbarD 0.8, after removing closely related individuals
failed_ld<-read_csv('/workdir/smallmouth/chapter_3_exports/loci_parentage_ld_exclude.csv')
obj<- obj[loc = setdiff(locNames(obj), 
                        failed_ld$value)]

# Add the site info for missing fish. I just ran this for the fish which had scoring genotypes and are in the obj file above
site_manual<-googlesheets4::read_sheet('https://docs.google.com/spreadsheets/d/1CJVikWmzlmv0qOtG2X1iLUyslgiJ-4vmgUSnjVO_NcU/edit#gid=0', 
                                       sheet = 'missing_site_n_fish_joiner') %>% 
  dplyr::select(GENID, SITE_INPUT) %>% 
  filter(!is.na(SITE_INPUT)) %>% 
  mutate(SITE_INPUT = paste0('BEF.LML.', 
                             str_pad(SITE_INPUT, 
                                     3, 
                                     pad = "0")))

phenos<-left_join(phenos, 
                  site_manual, 
                  by = 'GENID') %>% 
  mutate(SITE_N_NEW = coalesce(SITE_N_NEW, 
                               SITE_INPUT)) %>% 
  dplyr::select(-SITE_INPUT)

# clean up the lat and long from the site and the snorkels, respectively. also, add habitat. needed to convert with terra package from UTM to lat/long
site_info<-read_csv('/workdir/smallmouth/ecological/AFRP_MAIN_121923/SITES.txt')

site_convert<-dplyr::select(site_info, 
                            x = E_UTM, 
                            y = N_UTM) %>% 
  as.matrix()

v<-terra::vect(site_convert, 
               crs="+proj=utm +zone=18")

y <- terra::project(v, 
                    "+proj=longlat")

site_info_lat_lon<-terra::geom(y)[, c("x", "y")] %>% 
  as_tibble() %>% 
  bind_cols(site_info) %>% 
  dplyr::select(SITE_N_NEW = SITE_N, 
                long_site = x, 
                lat_site = y, 
                habitat_site = HAB_1) %>% 
  mutate(long_site = if_else(SITE_N_NEW == 'BEF.LML.031', 
                             -74.931601, 
                             long_site), # site 31 is in a weird place - re-locating
         lat_site = if_else(SITE_N_NEW == 'BEF.LML.031', 
                            43.694035, 
                            lat_site))

phenos<-left_join(phenos, 
                  site_info_lat_lon, 
                  by = 'SITE_N_NEW') %>% 
  dplyr::rename(long_snorkel = LONG, 
                lat_snorkel = LAT)

# Make another column for the snorkel fish to coalesce TL
phenos<-phenos %>% 
  mutate(TL = coalesce(ESTIMATED_TL_fish, 
                       ESTIMATED_TL_parent))

# make a clean site info column
phenos<-phenos %>% 
  mutate(site = if_else(WATER == 'LML', 
                        as.integer(str_replace(SITE_N_NEW, 
                                               'BEF.LML.', 
                                               '')), 
                        NA_integer_)) 

# add the synthetic nest characteristics axis
phenos<-phenos %>% 
  left_join(read_csv('/workdir/smallmouth/chapter_3_exports/synth_axis.csv'), 
            by = 'GENID_duplicate')

# generate estimated birth years and ages at capture
phenos<-phenos %>% 
  filter(WATER == 'LML') %>%
  mutate(LENGTH = coalesce(LENGTH, 
                           ESTIMATED_TL_fish)) %>% # include the field-based estimates of length. sd = 50mm
  left_join(read_csv('/workdir/smallmouth/chapter_3_exports/lml_alk_spring.csv'), by = 'year') %>% 
  mutate(alk_age = if_else(LENGTH < max1, 1,
                           if_else(data.table::between(LENGTH, 
                                                       min2, 
                                                       max2,  
                                                       NAbounds = NA), 
                                   2,
                                   if_else(data.table::between(LENGTH, 
                                                               min3, 
                                                               max3,  
                                                               NAbounds = NA), 
                                           3,
                                           if_else(data.table::between(LENGTH, 
                                                                       min4, 
                                                                       max4,  
                                                                       NAbounds = NA), 
                                                   4,
                                                   if_else(data.table::between(LENGTH, 
                                                                               min5, 
                                                                               max5,  
                                                                               NAbounds = NA), 
                                                           5, 
                                                           NA_real_))))),
         age0 = if_else((str_detect(GENID, 
                                    'SMB_2023') | str_detect(GENID, 
                                                             '2021_') | str_detect(GENID, 
                                                                                   'SMB_22')) & str_detect(SAMPLE,
                                                                                                           'NEST'),
                        0,
                        NA_real_),
         age3 = if_else(str_detect(SAMPLE, 
                                   'FISH'), 
                        3, 
                        NA_real_),
         predict_age = coalesce(ageTrue, 
                                ageLengthed, 
                                alk_age, 
                                age0, 
                                age3),
         predict_age = if_else(GENID == 'GEN_SMB_LML_052919_031', 
                               2, 
                               if_else(GENID == 'SMB_LML_061720_RANG_001', 
                                       2,
                                       if_else(GENID == 'LML_052203_BEF_014_001', 
                                               4, 
                                               predict_age))),
         predict_birthYr = year - predict_age) %>% 
  dplyr::select(GENID_duplicate, 
                predict_birthYr, 
                predict_age) %>% 
  right_join(phenos, 
             by = 'GENID_duplicate')

# make a list of families from ckmr-sim
FS_potential<-read_csv('/workdir/smallmouth/chapter_3_exports/FS_potential.csv')

build_fams<- FS_potential %>% 
  filter(confirmed==1) %>% 
  bind_rows(filter(read_csv('/workdir/smallmouth/chapter_3_exports/PO_potential.csv'), 
                   confirmed==1)) %>% 
  dplyr::select(d1 = GENID_duplicate_D1_indiv, 
                d2 = GENID_duplicate_D2_indiv)

g3<-simplify(graph.data.frame(build_fams[order(build_fams[[1]]),], 
                              directed = F))

obj_fams<-components(g3)$membership %>% 
  as_tibble(rownames = 'GENID_duplicate') %>% 
  right_join(filter(phenos, GENID_duplicate %in% indNames(obj))) %>% 
  arrange(value) %>% 
  mutate(fam_index = if_else(is.na(value), 
                             as.double(row_number()), 
                             value), # add sequential numbers
         fam_index = as.double(as.factor(fam_index)))

# add residual GSI standard deviationsbased on year, corrected for sex and age
# get gsi anomaly
gsi_in<-phenos %>%
  filter(!is.na(newGSI),
         WATER == 'LML',
         SEASON == 'S',
         !is.na(sex),
         sex != 'U',
         between(predict_age,
                 1,
                 5))

gsi_out<-tibble()
for(sex_in in c('M','F')){
  for(age_in in 1:5){
    data_in<-filter(gsi_in,
                    sex == sex_in,
                    predict_age==age_in)
    
    mod_in<-lm(newGSI~year,
               data = data_in)
    
    gsi_out<-data_in %>%
      bind_cols(tibble(gsi_resid=rstandard(mod_in))) %>%
      bind_rows(gsi_out)
  }
}

phenos<-phenos %>%
  left_join(dplyr::select(gsi_out,
                          GENID_duplicate,
                          gsi_resid))

# pull in the maf from lcwgs data
A_maf<-as_tibble(read.table(gzfile(paste0('/workdir/smallmouth/angsd/popminind20/A_global_snp_list_bam_list_realigned_smb_anchored_mincov_filtered_mindp39_maxdp350_minind21_minq20_popminind20.mafs.gz')), header = TRUE)) %>% 
  right_join(dplyr::select(ordered_amplicons,
                           microhap_name,
                           chromo=chr,
                           position),
             by = c('chromo', 
                    'position'))

D_maf<-as_tibble(read.table(gzfile(paste0('/workdir/smallmouth/angsd/popminind20/D_global_snp_list_bam_list_realigned_smb_anchored_mincov_filtered_mindp39_maxdp350_minind21_minq20_popminind20.mafs.gz')), header = TRUE)) %>% 
  right_join(dplyr::select(ordered_amplicons,
                           microhap_name,
                           chromo=chr,
                           position),
             by = c('chromo', 
                    'position'))

# bring in the missing SITE_N's that Kurt identified. I consolidated may and june in 2000, since we aren't considering month affect
missing_sites<-
  read_xlsx('/workdir/smallmouth/ecological/kurt_matched_naf_surveys.xlsx', 
            sheet = 'missing_sites_2000consolidated') %>% 
  group_by(Spring_NAF_missing_sites) %>% 
  tally() %>% 
  filter(n>1) %>% 
  mutate(missing_sites = as.character(str_pad(Spring_NAF_missing_sites, 
                                              3, 
                                              pad = "0")),
         SITE_N = paste0('BEF.LML.',
                         missing_sites))

# Import shoreline distances. These are also the sites we trust the most
site_distances<-read_csv('/workdir/smallmouth/ecological/BEFsites_LengthAndHabitat_BMQ_070318_1_shoreline_distances.csv') %>% 
  filter(Water=='LML')

# LG names
lg_filter <- read_csv('/workdir/smallmouth/sample_lists/lg_reference_annotate.csv') %>% 
  dplyr::rename(LG=lg,
                lg=chr)

# Import the reference bias filtered SNP list
refBias <- read_tsv("/workdir/smallmouth/angsd/global_snp_list_depth_ratio_filtered.txt", col_names = c("lg", "pos")) %>%
  mutate(keep=T,
         lg_pos = paste0(lg, '-', pos))

# Import Fst and exclude refBias
fst <- read_tsv('/workdir/smallmouth/angsd/popminind20/A_D_global_snp_list_bam_list_realigned_smb_anchored_mincov_filtered_mindp39_maxdp350_minind21_minq20_popminind20.fst', 
                col_names = c('lg', 'pos', 'alpha', 'beta', 'fst')) %>%
  left_join(lg_filter, by = 'lg') %>% 
  filter(!is.na(name)) %>% 
  left_join(refBias,by=c('lg','pos')) %>%
  filter(keep==T) %>%
  dplyr::select(-keep)

# import 2020 geomorph study where we fresh-measured bass
fresh <-
  googlesheets4::read_sheet(
    'https://docs.google.com/spreadsheets/d/1kdiVUv7DzwEGC3s5GRjFOWlEk8_OgW498DUjcFCKQ60/edit#gid=2100724345',
    sheet = 'Data'
  ) %>%
  left_join(allFish, by = 'FISH_N') %>%
  mutate(weight_fresh_frozen = Weight_g - WEIGHT,
         length_fresh_frozen = Length_mm - LENGTH)

# filter exported data down to just Little Moose and Woodhull
allFish<-allFish %>% 
  filter(WATER == 'LML' | WATER == 'WLL')

phenos<-phenos %>% 
  filter(WATER == 'LML' | WATER == 'WLL')

save(ordered_amplicons,
     allFish,
     snorkel,
     allGenotyped,
     phenos,
     genos_withdups,
     genos,
     microhap_snp,
     obj_preLD_pre_HWE,
     obj,
     obj_fams,
     A_maf,
     D_maf,
     missing_sites,
     site_distances,
     fst,
     fresh,
     file=paste0(basedir,
                 'chapter_3_exports/smallmouth_adaptation_data.rda'))

R.utils::gzip(paste0(basedir,
                          'chapter_3_exports/smallmouth_adaptation_data.rda'))

```

# Quality control

## Tissue type, extraction, and storage methods

```{r, warning=F, message=F, error=F, echo=F, eval=F}
# first, read in the snorkel data with GPS points as latitude and longitude. Then, rename snorkel collected tissues as egg, grey, fin, ect
# Then read in all snorkel data, with GPS points as lat and lon
snork<-snorkel %>% 
  mutate(WAYPOINT = as.character(WAYPOINT), 
         ESTIMATED_TL = as.character(ESTIMATED_TL)) %>% 
  pivot_longer(c(NEST_GEN_1, 
                 NEST_GEN_2, 
                 FISH_GEN), 
               names_to = 'SAMPLE', 
               values_to = 'GENID') %>% 
  filter(!is.na(GENID)) %>% 
  mutate(SAMPLE=if_else(SAMPLE=='FISH_GEN', 
                        'fin', 
                        EARLIEST_STAGE)) %>% 
  dplyr::select(GENID, 
                SAMPLE)

# read in the unfiltered genotypes
genos_noFilt<-read_csv('/workdir/smallmouth/gtseq/microhaplot/reported_diploid_haplotype_gtseq_production_1.csv') %>% 
  filter(read.depth.1>30 & read.depth.2 > 30 & ar > 0.2) %>% 
  mutate(read_depth = if_else(is.na(read.depth.2), 
                              read.depth.1, 
                              (read.depth.1+read.depth.2)),
         genotyped = 1) %>% 
  group_by(locus) %>% 
  mutate(n_inds_nonNA=n()) %>% 
  ungroup() %>% 
  filter(indiv.ID !='unknown') %>% 
  rename(GENID=indiv.ID) %>% 
  anti_join(read_csv('/workdir/smallmouth/chapter_3_exports/contaminated_inds.csv'), 
            by = 'GENID') %>%   # exclude contaminated inds
  anti_join(read_csv('/workdir/smallmouth/chapter_3_exports/paralog_loci.csv')) %>% # exclude loci showing 3+ alleles, paralog in some pops
  left_join(rename(ordered_amplicons, 
                   'locus'='microhap_name'), 
            by = 'locus')

# read in data on all the fish I've genotyped
allGenotyped<-read_xlsx('/workdir/smallmouth/gtseq/AdkLabNotebook_gtseq.xlsx', sheet = 'samples_production') %>% 
  filter(!str_detect(`extraction Plate`, '5'), 
         !str_detect(`extraction Plate`, '6'), 
         !str_detect(`extraction Plate`, '9')) %>%  # remove the plates I haven't sequenced 
  dplyr::select(GENID, 
                GEN_N, 
                FISH_N, 
                `tissue source`,
                `tissue type`, 
                extractionType, 
                `extraction Plate`, 
                extractioncolumn, 
                `extraction Row`)

#  bring this all together
prop_scoring_tiss_extract<-group_by(genos_noFilt, GENID) %>% 
  summarise(propLoc = n()/length(unique(genos_noFilt$locus))) %>% 
  ungroup() %>% 
  right_join(allGenotyped, by = 'GENID') %>% 
  left_join(snork, by = 'GENID') %>% 
  mutate(propLoc = if_else(is.na(propLoc), 
                           0, 
                           propLoc),
         tiss = if_else(!is.na(SAMPLE), 
                        paste0(`tissue source`, 
                               '-',SAMPLE), 
                        paste0(`tissue source`, 
                               '-',`tissue type`))) %>% 
  dplyr::select(GENID,
                tiss, 
                extractionType, 
                propLoc)

# plot
group_by(prop_scoring_tiss_extract, 
         extractionType, tiss) %>% 
  summarise(`Proportion\nscoring\nloci` = mean(propLoc), 
            n= n()) %>% 
  filter(!is.na(extractionType), 
         extractionType != 'NA') %>% 
  ggplot(aes(extractionType, 
             tiss, 
             fill = `Proportion\nscoring\nloci`)) + 
  geom_tile() + 
  theme(axis.text.x = element_text(angle = 45, 
                                   vjust = 1, 
                                   hjust=1)) + 
  scale_fill_continuous(type = "viridis")  + 
  geom_text(aes(label=n)) + 
  labs(x = 'extraction type', 
       y = 'tissue type and storage method')
#ggsave('/workdir/smallmouth/chapter_3_exports/extractionMethod_tissueType_success_tile.png', width = 8, height=5)

# color all plates by proportion locus success
left_join(prop_scoring_tiss_extract, 
          allGenotyped, 
          by = 'GENID') %>% 
  filter(tiss == 'fresh etoh-Grey' & extractionType.x == 'bead') %>% #  tiss == 'fresh etoh-Grey'
  ggplot(aes(extractioncolumn, 
             `extraction Row`, 
             fill = propLoc)) + 
  geom_tile() + 
  facet_wrap(~`extraction Plate`)

# some eggs and grey fry didn't do that well. why not? 
filter(prop_scoring_tiss_extract, 
       (tiss == 'fresh etoh-Egg' | tiss == 'fresh etoh-Grey') & extractionType == 'bead') %>% 
  mutate(loc_success = if_else(propLoc < 0.05, 
                               'failed', 
                               if_else(propLoc > 0.75, 
                                       'succeeded', 
                                       'moderate'))) %>% 
  write_csv('/workdir/smallmouth/chapter_3_exports/succeded_failed_eggs_greyFry.csv')

```


## Genotyping accuracy
```{r, warning=F, message=F, error=F, echo=F, eval=F}

# here I want to import the non-read-depth cleaned version of genos

# Note I went through and removed an

genos_nofilt<-read_csv('/workdir/backup/smallmouth/gtseq_production_2/amp_py_output/hap_genotype_read_depth.csv') %>% 
  filter(!is.na(haplotype.1), !is.na(haplotype.2)) %>% 
  filter(GENID_duplicate %in% unique(genos_withdups$GENID_duplicate))

n_loci<-length(unique(genos_nofilt$locus))

# calculate missingness for each individual 
dups<-group_by(genos_nofilt, GENID_duplicate) %>% tally() %>% 
  separate(GENID_duplicate, into = c('run', 'GENID'), sep = '--', remove = F)

# Generate a list of all duplicated GENID's between gtseq production 1 and 2. Use this to make a handmade list of dups, including "a", "b" within gtseq p 1 and 2
filter(dups, duplicated(GENID))

# upload list, filter ones that didn't get any reads, and then make a final list to iterate over
dups_filt<-read_xlsx('/workdir/smallmouth/chapter_3_exports/gtseq_produciton_2_1_dups_for_genotype_accuracy.xlsx') %>% 
  mutate(row_num = row_number()) %>% 
  pivot_longer(-row_num, values_to = 'GENID_duplicate') %>% 
  left_join(dups, by = 'GENID_duplicate') %>% 
  filter(!is.na(run)) %>% 
  dplyr::select(row_num, name, GENID_duplicate) %>% 
  pivot_wider(names_from = 'name', values_from='GENID_duplicate') %>% 
  filter(!is.na(dup1) & !is.na(dup2))

# how many individuals?
dups_filt %>% 
  pivot_longer(-row_num) %>% 
  separate(value, into = c('gt','ind'), sep = '--') %>% 
  arrange(ind)

tib_out<-tibble()
tib_out_snp<-tibble()

for(rd in c(5,10,15,20)){
  
  microhap_snp_depth<-read_csv(paste0('/workdir/smallmouth/gtseq/microhaplot/snp_report_gtseq_production_2_depth', rd,'.csv')) %>% 
    mutate(locus = paste0(locus, '-pos', pos)) %>% 
    filter(!str_detect(snp, 'N')) %>% 
    separate(snp, into=c('snp1','snp2'), sep = '/', remove = F) %>% rowwise() %>% mutate(genoty=paste0(sort(c(snp1,snp2)),collapse='/')) %>% ungroup() %>% # arrange by alphabet
    mutate(indiv.ID = str_replace(indiv.ID, '__','--'))
  n_loci_snp<-length(unique(microhap_snp_depth$locus))
  
  for(miss in seq(0.1,1, 0.1)){
    
    # Filter the genos for read depth and missingness
    hm_filt_in<-genos_nofilt %>% 
      group_by(GENID_duplicate) %>% 
      mutate(prop_score = n()/n_loci) %>% 
      filter(read_depth >= rd) %>% 
      filter(prop_score > 0.99-miss) %>% 
      ungroup() %>% 
      dplyr::select(locus, genoty, GENID_duplicate) # haplotype.1, haplotype.2, 
    
    # filter the snps for read depth and missingness
    microhap_snp_depth_filt<-microhap_snp_depth %>% 
      group_by(indiv.ID) %>% mutate(prop_score = n()/n_loci_snp) %>% filter(prop_score > 0.99-miss)
    
    for(i in 1:nrow(dups_filt)){
      
      iia<-dups_filt[i,]$dup1
      iib<-dups_filt[i,]$dup2
      
      try({
        tib_in<-filter(hm_filt_in, GENID_duplicate == iia | GENID_duplicate == iib) %>% 
          pivot_wider(names_from = GENID_duplicate, values_from = genoty) %>% # c(haplotype.1, haplotype.2)) 
          na.omit()
        
        # make the tibble which ID's whether the genotypes are the same or not, assuming that each, if wrong, is only half-wrong
        tib_inner<-tib_in %>% 
          # mutate(same_haps = if_else(paste0(.[[2]],.[[4]]) == paste0(.[[3]],.[[5]]) | paste0(.[[4]],.[[2]]) == paste0(.[[3]],.[[5]]), 1, 0)) %>% # this is for separated haplotypes
          mutate(same = if_else(.[[2]] == .[[3]], 1, 0)) %>% 
          group_by(same) %>% 
          summarise(n=n()) %>% 
          mutate(first = iia, second = iib, ind = i, depth = rd, missingness  = miss, number_loci = nrow(tib_in))
        
        
        tib_out<-bind_rows(tib_inner, tib_out)
        
      })
      
      try({
        tib_in<-filter(microhap_snp_depth_filt, indiv.ID == iia | indiv.ID == iib) %>% 
          dplyr::select(locus, indiv.ID, genoty) %>% 
          pivot_wider(names_from=indiv.ID, values_from=genoty) %>% 
          na.omit()
        
        tib_inner<-tib_in %>% 
          mutate(same =  if_else(.[[2]] == .[[3]], 1, 0)) %>% 
          group_by(same) %>% 
          summarise(n=n()) %>% 
          mutate(first=iia, second=iib, ind=i, depth=rd, missingness=miss, number_loci=nrow(tib_in))
        
        tib_out_snp<-bind_rows(tib_inner, tib_out_snp)
        
      })
    }
    
  }
}

# microhap results
write_csv(tib_out, '/workdir/smallmouth/chapter_3_exports/genotype_accuracy.csv')
tib_out<- read_csv('/workdir/smallmouth/chapter_3_exports/genotype_accuracy.csv')

dplyr::select(tib_out, -c(first, second)) %>% 
  pivot_wider(names_from=same, values_from=n) %>% # calculate individual accuracy
  mutate(acc = (1+`1`/number_loci)/2) %>%  # but take the mean of this acc and 1, because usually half the genotypes are correct
  group_by(depth, missingness) %>% 
  summarise(mean_acc = mean(acc)) %>% 
  ggplot(aes(depth, mean_acc, color = as.character(missingness), group = missingness)) + geom_point() + geom_line() + facet_wrap(~missingness, nrow=1)
ggsave('/workdir/smallmouth/chapter_3_exports/accuracy.png', height=2, width=10)

# snp results
write_csv(tib_out_snp, '/workdir/smallmouth/chapter_3_exports/genotype_accuracy_snp.csv')
tib_out_snp<- read_csv('/workdir/smallmouth/chapter_3_exports/genotype_accuracy_snp.csv')

dplyr::select(tib_out_snp, -c(first,second)) %>% 
  pivot_wider(names_from=same, values_from=n) %>% 
  mutate(acc = (1+`1`/number_loci)/2) %>% 
  group_by(depth, missingness) %>% 
  summarise(mean_acc = mean(acc)) %>% 
  ggplot(aes(depth, mean_acc, color = as.character(missingness), group  = missingness)) + geom_point() + geom_line()

# how many individuals do we get passing filters?
genos_withdups %>% 
  group_by(GENID_duplicate) %>% tally() %>% 
  separate(GENID_duplicate, into = c('run', 'GENID'), sep = '--', remove = F) %>% summarise(unique(GENID))

```

## Null alleles (both adaptive and neutral)

### popgenreport

```{r}
genos %>% 
  left_join(dplyr::select(phenos, GENID_duplicate, year)) %>% 
  dplyr::select(locus, GENID_duplicate, genoty, year) %>% 
  pivot_wider(names_from=locus, values_from=genoty) %>% 
  dplyr::rename(ind=GENID_duplicate, pop=year) %>% 
  write_csv('/workdir/smallmouth/gtseq/genos.csv')
```

```{bash}
nohup Rscript --vanilla /workdir/smallmouth/scripts/run_popgenreport_nulls.R \
/workdir/smallmouth/gtseq/genos.csv \
/workdir/smallmouth/gtseq/genos_nulls.csv \
> /workdir/smallmouth/nohups/run_popgenreport_genos.nohup &
```

```{r}
read_csv('/workdir/smallmouth/gtseq/genos_nulls.csv') %>% 
  filter(`2.5th percentile` > 0)
```

### homozygote excess using Diana's script
https://github.com/dbaetscher/nsf-rockfish-parentage/blob/master/Rmd/03-checking-homozygosity-atrovirens.Rmd

Essentially we test each allele to get the estimated frequency of homozygotes, then compare to actual frequency of homozygotes
Then, only considering alleles above 5% frequency, we identify null alleles with a zscore test
```{r}
overall<-genind2df(obj, sep = '/') %>% 
  as_tibble(rownames = 'ind') %>% 
  pivot_longer(-c(ind, pop)) %>% 
  separate(value, into = c('al1','al2'), remove = F) %>% 
  filter(!is.na(al1), !is.na(al2))

overall_af<-overall %>% 
  pivot_longer(-c(ind, pop, name, value), names_to = 'gene_copy', values_to = 'al1') %>% 
  group_by(name, al1) %>% 
  summarise(n_alleles = n()) %>% 
  group_by(name) %>% 
  mutate(af = n_alleles/sum(n_alleles)) %>% 
  ungroup() %>% 
  mutate(expected_homo = af^2,
         expected_het = 2 * af * (1 - af))

overall_zscore<-overall %>% 
  group_by(name, al1, al2, value) %>% 
  summarise(n_genos = n()) %>% 
  mutate(homoz = al1==al2) %>% 
  group_by(name) %>% 
  mutate(geno_prop = n_genos/sum(n_genos)) %>% 
  filter(homoz == T) %>% 
  left_join(overall_af, by = c('name','al1')) %>% 
  mutate(exp_sd = sqrt(expected_homo * ( 1 - expected_homo ) / sum(n_genos)),  # calculate standard deviation of expectation
         zscore = ( geno_prop - expected_homo ) / exp_sd )# calcualte the z-score of observed minus expected

overall_zscore %>% # we do have some high-zscore alleles
  ggplot(aes(zscore)) +
  geom_histogram()

overall_zscore %>% # but most of them look really good
  ggplot(aes(expected_homo, geno_prop, color = zscore)) +
  geom_point() +
  geom_abline()

filter(overall_zscore, zscore > 3.3) # all of these three alleles have low expected homozygosity rates (<5%), so let's not worry about them

overall_zscore %>% 
  filter(expected_homo > 0.05, zscore > 3.3)

```

## HWE

```{r}
# Overall, lots of loci fail HWE
# pegas::hw.test(obj_noFams, B = 100) %>% 
#   as_tibble(rownames = 'locus') %>% 
#   filter(Pr.exact < hwe_alpha | `Pr(chi^2 >)` < hwe_alpha)

# let's check per population - exclude loci that fail HWE in more than 50% of years
obj_hwe<-seppop(obj) %>% 
  lapply(pegas::hw.test, B = 0)

obj_hwe_pval<-sapply(obj_hwe, "[", i = TRUE, j = 3)

hwe_plot<-obj_hwe_pval %>% 
  as_tibble() %>% 
  mutate(locus = row.names(obj_hwe_pval)) %>% 
  pivot_longer(-locus, names_to = 'pop', values_to = 'hwe') %>% 
  mutate(hwe_1yes = if_else(hwe<0.05, 0, 1))

hwe_plot %>% 
  filter(!is.na(hwe_1yes)) %>% 
  group_by(locus) %>% 
  summarise(sum_in_hwe = sum(hwe_1yes))  %>% 
  filter(sum_in_hwe <= nPop(obj)/2) %>% # just grab the loci that fail in over half the years
  #left_join(locus_info, by = 'locus') %>% 
  write_csv('/workdir/smallmouth/chapter_3_exports/loci_failing_hwe_over_50_percent_years.csv')

hwe_plot %>% 
  ggplot(aes(pop, locus, fill = hwe_1yes)) +
  geom_tile() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## LD

also ran this per year - pretty similar results
```{r, eval=F}
linkage_threshold<-0.8

# read in basic info about each locus: chr, position, # alleles. also, bring in the genind that doesn't hve relatedness (yank-2, max fam members = 2)
oa<-dplyr::select(ordered_amplicons, microhap_name, chrNum, position) %>% 
  mutate(microhap_name = str_replace_all(microhap_name, '\\.', '')) 

oa_Arich<-read_csv('/workdir/smallmouth/chapter_3_exports/locus_table_parentage.csv') %>% 
  dplyr::select(microhap_name = locus, allele_count=allele) %>% 
  left_join(oa, by = 'microhap_name')

yank2<-obj_preLD_pre_HWE[no_fams$GENID_duplicate]

# calculate LD, bind to basic info
tt<- yank2 %>% # just grab the yank-2 dataset
  pair.ia() %>% 
  as_tibble(rownames = 'pop_comparison')

filter(tt, rbarD > linkage_threshold) # take a quick look at which loci are linked

linkage_data<-tt %>%
  separate(pop_comparison, into = c('p1','p2'), sep = ':') %>% 
  dplyr::select(-Ia) %>% 
  mutate(row_n = row_number()) %>% 
  pivot_longer(-c(row_n, rbarD), values_to = 'microhap_name') %>% 
  left_join(oa_Arich, by = 'microhap_name')  

# What does our linkage decay look like (keep in mind that we have excluded POP and FSP)
linkage_data %>% 
  pivot_wider(names_from=name, values_from=c(microhap_name, chrNum, position, allele_count)) %>% 
  filter(chrNum_p1 == chrNum_p2) %>% # only keep if they're on the same chromosome
  mutate(physical_distance = abs(position_p1-position_p2)) %>% 
  ggplot(aes(physical_distance, rbarD)) +
  geom_point() +
  geom_smooth() +
  geom_vline(xintercept = 5e06, lty = 'dashed')

# figure out which linked loci (>0.8) to exclude
# This was a bit complicated. First, I started with nothing in the "excluded" list (can comment out the setDiff line start the pipe)
# I visually went through and excluded loci that showed up in the most LD-pairs (n_microhap)
# Another thing to consider when making decisions is excluding loci that have fewere alleles (allele_count)
# Go through and sequentially add to this list, "excluded"
excluded<-c('parentage_NW_0240400401_RagTag_start24698750_end24699000', 'parentage_NW_0240444591_RagTag_start14338500_end14338750', 'parentage_NW_0240444591_RagTag_start20733500_end20733750', 'parentage_NW_0240444591_RagTag_start22096000_end22096250', 'parentage_NW_0240445701_RagTag_start20857250_end20857500', 'parentage_NW_0240445701_RagTag_start9466250_end9466500')

yank2[loc = setdiff(locNames(yank2), excluded)] %>% # just grab the yank-2 dataset
  missingno('loci', 0.2) %>% 
  missingno('geno', 0.2) %>% 
  pair.ia(plot = F) %>% 
  as_tibble(rownames = 'pop_comparison') %>% 
  separate(pop_comparison, into = c('p1','p2'), sep = ':') %>% 
  dplyr::select(-Ia) %>% 
  mutate(row_n = row_number()) %>% 
  pivot_longer(-c(row_n, rbarD), values_to = 'microhap_name') %>% 
  left_join(dplyr::select(oa_Arich, -c(chrNum, position)), by = 'microhap_name')  %>% 
  filter(rbarD > linkage_threshold) %>% 
  group_by(microhap_name) %>% 
  mutate(n_microhap = n()) %>% 
  pivot_wider(names_from=name, values_from=c(microhap_name, allele_count, n_microhap)) %>% 
  filter(!is.na(microhap_name_p1), !is.na(microhap_name_p2))

write_csv(as_tibble(excluded), '/workdir/smallmouth/chapter_3_exports/loci_parentage_ld_exclude.csv')

read_csv('/workdir/smallmouth/chapter_3_exports/loci_parentage_ld_exclude.csv')
```


## LD (just neutral)

# Figure 1

Figure 1a-e
```{r}
# Figure 1a (CPUE S with length bins)

# cpue
fig_cpue<-allFish %>%
  mutate(jDate = lubridate::yday(DATE_COL),
         ysamp = str_sub(YSAMP_N, 
                         -2)) %>% 
  filter(between(year, 
                 1998, 
                 2020), 
         !is.na(effortSec), 
         (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO'), 
         WATER == 'LML', 
         month<7) %>% 
  group_by(year, 
           SITE_N) %>% 
  filter(jDate == min(jDate)) %>% # Just grab the first jDate of the SITE_N of the year
  filter(ysamp == min(ysamp)) %>% # Just grab the first sampling site of the day
  ungroup() %>% 
  filter(SITE_N %nin% missing_sites$SITE_N,
         SITE_N %in% site_distances$SITE_N) %>% 
  mutate(lenBin = if_else((LENGTH < 100 | is.na(LENGTH)), 
                          '0-100',
                          if_else(between(LENGTH, 
                                          100, 
                                          200), 
                                  '100-200',
                                  if_else(LENGTH > 200, 
                                          '200+', 
                                          '0')))) %>% 
  group_by(year, 
           SITE_N, 
           lenBin) %>% 
  summarise(cpue = (n()/unique(effortSec))*60) %>% 
  ungroup() %>% 
  pivot_wider(names_from=lenBin, 
              values_from=cpue) %>%
  mutate_all(~ifelse(is.na(.), 
                     0, 
                     .)) %>% # fill in all NA's with zero
  pivot_longer(-c(year, 
                  SITE_N), 
               names_to='lenBin',
               values_to='cpue') %>% 
  ggplot(aes(year, 
             cpue, 
             group=lenBin, 
             color=lenBin)) + # , color = lenBin, lty = lenBin
  geom_smooth(span=0.15) +
  ylab('Catch / minute') + 
  scale_color_viridis_d('Length bin\n(mm)') +
  geom_vline(xintercept = 2000.5, 
             lty = 'dashed') +
  xlim(1998,2020) +
  coord_cartesian(ylim=c(0, 
                         4)) +
  theme_cowplot()

# length histos
fig_length<-
  allFish %>%
  filter(between(year, 
                 1998, 
                 2020), 
         (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO'), 
         !is.na(LENGTH), 
         WATER == 'LML', 
         SEASON=='S') %>% 
  ggplot(aes(x=LENGTH, 
             y=as.factor(year), 
             fill=stat(x))) + 
  ggridges::geom_density_ridges_gradient(scale=1.5, 
                                         rel_min_height = 0.001) +  
  scale_fill_viridis_c(name = "LENGTH", 
                       option = "C") + 
  xlim(0,400)  + 
  labs(y='Year',
       x='Length (mm)') + 
  theme_cowplot() +
  coord_flip() +
  scale_y_discrete(breaks = c(2000, 
                              2005, 
                              2010, 
                              2015, 
                              2020))

# female gsi age-4
fig_female_gsi_data<-allFish %>% 
  filter(!is.na(newGSI), 
         sex == 'F', 
         (WATER == 'LML' | WATER == 'WLL'), 
         ageTrue == 4, 
         year < 2021) %>% 
  mutate(Lake = if_else(WATER == 'LML', 
                        'Suppression', 
                        'Reference'),
         Lake = factor(Lake, 
                       levels = c('Suppression',
                                  'Reference')),
         yearlake = paste0(year, 
                           Lake))

fig_female_gsi<-fig_female_gsi_data %>% 
  ggplot(aes(year, 
             newGSI, 
             color = Lake)) + 
  geom_boxplot(aes(group = yearlake, 
                   color = Lake)) +
  geom_jitter(height=0, 
              width=0.1, 
              alpha = 0.5) +
  stat_smooth(method = 'lm') + 
  labs(x='Year', 
       y='Age 4\nfemale GSI') + 
  theme_cowplot() + 
  xlim(1998, 
       2020) + 
  geom_vline(xintercept = 2000.5, 
             lty='dashed') + 
  scale_color_manual(values=c("black", 
                              "blue"))

summary(lm(newGSI ~ year, 
           data = filter(fig_female_gsi_data, 
                         Lake == 'Suppression')))

# male gsi age-3
fig_male_gsi_data<-allFish %>% 
  filter(!is.na(newGSI), 
         sex == 'M', 
         (WATER == 'LML' | WATER == 'WLL'), 
         ageTrue == 3, 
         year < 2021) %>% 
  mutate(Lake = if_else(WATER == 'LML', 
                        'Suppression', 
                        'Reference'),
         Lake = factor(Lake, 
                       levels = c('Suppression',
                                  'Reference')),
         yearlake = paste0(year, 
                           Lake)) 

fig_male_gsi<-fig_male_gsi_data %>% 
  ggplot(aes(year, 
             newGSI, 
             color = Lake)) + 
  geom_boxplot(aes(group = yearlake, 
                   color = Lake)) +
  geom_jitter(height=0, 
              width=0.1, 
              alpha = 0.5) +
  stat_smooth(method = 'lm') + 
  labs(x='Year', 
       y='Age 3\nmale GSI') + 
  theme_cowplot() +  
  xlim(1998, 
       2020) + 
  geom_vline(xintercept = 2000.5, 
             lty='dashed') + 
  scale_color_manual(values=c("black", 
                              "blue"))

summary(lm(newGSI ~ year,
           data = filter(fig_male_gsi_data, 
                         Lake == 'Suppression')))

#### length at age
fig_length_age <- allFish %>%
  filter(
    SEASON == 'S',
    GEAR == 'BEF',!is.na(ageLengthed),
    between(year,
            1998,
            2017),
    ageLengthed < 5) %>%
  mutate(ageyear = paste0(ageLengthed, 
                          year)) %>%
  ggplot(aes(year, 
             LENGTH)) +
  geom_boxplot(aes(group = ageyear, 
                   color = ageLengthed), 
               outlier.shape = NA) +
  geom_smooth(aes(group = ageLengthed, 
                  color = ageLengthed),
              span = .3,
              level = 0.95) +
  labs(x = 'Year',
       y = 'Length (mm)', 
       color = 'Age') +
  theme_cowplot() +
  geom_vline(xintercept = 2000.5, 
             lty = 'dashed') +
  xlim(1998, 2020)

```

fishR vignette on reverse modeling of annual age-specific mortality
```{r}
# First, we need to build an age-length key with no gaps. Do 5-year blocks, skipping 2001-2005 because its hard to assess. Use the tutorial at http://derekogle.com/fishR/examples/oldFishRVignettes/AgeLengthKey.pdf

year_blocks<-tibble(start = c(1970, 
                              2005), 
                    end = c(2000, 
                            2023))

catch_curves_out<-tibble()
for(i in 1:2){
  # import data
  sm_in<-filter(allFish, 
                WATER == 'LML', 
                month<7, 
                between(year, 
                        year_blocks[i,]$start, 
                        year_blocks[i,]$end),
                !is.na(LENGTH), 
                LENGTH > 30) %>% 
    mutate(ageTrue = if_else(LENGTH < 100, 
                             1, 
                             ageTrue)) # we always call fish under 100mm as 1yo
  
  sm_age<-filter(sm_in, 
                 !is.na(ageTrue))
  
  sm_len<-filter(sm_in, 
                 is.na(ageTrue)) %>% 
    mutate(alk = as.numeric(NA))
  
  # generate AL key
  sm_age_category<-FSA::lencat(~LENGTH, 
                               data = sm_age, 
                               startcat = 30, 
                               w=10) # length category per ind
  sm_age_raw<-with(sm_age_category, 
                   table(LCat, 
                         ageTrue)) # convert to table, age = col, lencat = row
  sm_age_key <- prop.table(sm_age_raw,
                           margin=1) # convert this into a proportion
  
  # assign age to fishes, bind to known ages, pull first 3 days of each NAF
  catches_in<-
    FSA::alkIndivAge(sm_age_key,
                     alk~LENGTH,
                     data=sm_len, 
                     seed = 123) %>% 
    bind_rows(sm_age) %>% 
    mutate(age_catch_curve = coalesce(ageTrue, 
                                      alk)) %>% 
    filter(!is.na(age_catch_curve), 
           (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO')) %>% 
    mutate(jDate = lubridate::yday(DATE_COL),
           ysamp = str_sub(YSAMP_N, -2)) %>% 
    group_by(year, 
             SITE_N) %>% 
    filter(jDate == min(jDate)) %>% # Just grab the first jDate of the SITE_N of the year
    filter(ysamp == min(ysamp)) %>% # Just grab the first sampling site of the day
    ungroup() %>% 
    group_by(year, 
             age_catch_curve) %>% 
    tally() 
  catch_curves_out<-bind_rows(catch_curves_out, 
                              catches_in)
}

# calculate the yearly instantaneous (Z) and annual (A) mortality rate
summ_out<-tibble()
confin_out<-tibble()

for(yr in unique(catch_curves_out$year)){
  
  thcc <- FSA::chapmanRobson(n~age_catch_curve,
                             data=filter(catch_curves_out, 
                                         year == yr),
                             ages2use=1:6)
  
  summ_out<-rownames_to_column(as.data.frame(summary(thcc)), 
                               var = 'mortality') %>% 
    mutate(year = yr) %>% 
    bind_rows(summ_out)
  
  confin_out<-rownames_to_column(as.data.frame(confint(thcc)), 
                                 var = 'mortality') %>% 
    mutate(year = yr) %>% 
    bind_rows(confin_out)
}

# Figure 1f
fig_catch_age<-mutate(catch_curves_out, 
                      Years = if_else(year < 2001, 
                                      '1998-2000', 
                                      '2001-2020'),
                      suppression_age = paste0(Years, 
                                               age_catch_curve)) %>% 
  filter(age_catch_curve < 7) %>% 
  ggplot(aes(age_catch_curve, 
             n, 
             color = Years)) + 
  geom_boxplot(aes(group = suppression_age), 
               outlier.color = NA) +
  geom_jitter(alpha=0.2, 
              position=position_jitterdodge(jitter.width = 0.1, 
                                            jitter.height = 0)) + 
  geom_smooth(span=1, 
              se = F) + 
  theme_cowplot() + 
  labs(x = 'Age', 
       y = 'Catch')

# Figure 1g
fig_survival_data<-summ_out %>% 
  filter(mortality == 'S',
         year < 2021) %>% 
  mutate(Years = if_else(year < 2001, 
                         '1998-2000', 
                         '2001-2020'), 
         Estimate = Estimate/100) 

fig_survival<-fig_survival_data %>% 
  ggplot(aes(Years, 
             Estimate, 
             group = Years, 
             color = Years)) + 
  geom_boxplot() + 
  geom_jitter(height = 0, 
              width = 0.1) + 
  labs(y = 'Annual survival estimate') + 
  theme_cowplot()

calc_diff<-fig_survival_data %>% 
  group_by(Years) %>% 
  summarise(survival = mean(Estimate)) %>% 
  mutate(mortality = 1-survival)

paste0('Survival was reduced by ',
       round(1-calc_diff$survival[2]/calc_diff$survival[1], 
             2)*100, 
       '%')

calc_diff$mortality[2] / calc_diff$mortality[1]
```


Plot fig 1
```{r}
height_out<-10
width_out<-7

plot_grid(
  plot_grid(fig_cpue +
              theme(axis.text.x=element_blank(),
                    axis.title.x = element_blank()) +
              ggtitle('a')
            , fig_length +
              theme(legend.position='none') +
              theme(axis.text.x=element_blank(),
                    axis.title.x = element_blank()) +
              ggtitle('b')
            , fig_female_gsi +
              theme(axis.text.x=element_blank(),
                    axis.title.x = element_blank()) +
              ggtitle('c')
            , fig_male_gsi +
              theme(legend.position='none') +
              ggtitle('d')
            , ncol=1
            , align="v"
  )
  , plot_grid(fig_length_age +
                ggtitle('e')
              , fig_catch_age +
                ggtitle('f')
              , fig_survival +
                theme(legend.position='none') +
                ggtitle('g')
              , ncol = 1
              , align = 'v'
  )
)
ggsave(paste0(basedir,
              '/chapter_3_exports/Fig_1.pdf'), 
       height=10, 
       width = 10)

```

Calculate difference in pre- vs during-suppression size-at-age. mean and p-val
```{r}
# Generate dataset
size_at_age_data<-filter(allFish, WATER == 'LML', between(ageLengthed, 0, 6), between(year, 1998, 2017), GEAR=='BEF') %>% 
  mutate(pre_post = if_else(year<2001, 'Pre','Post'),
         pre_post_age = paste0(ageLengthed, pre_post)) %>% 
  filter(!is.na(pre_post))

# Plot length
ggplot(size_at_age_data, aes(ageLengthed, LENGTH, color = pre_post)) + 
  geom_boxplot(aes(group = pre_post_age)) + 
  geom_smooth(span=2, se = F) + 
  theme_cowplot() + 
  labs(x = 'Age', y = 'Length (mm)', color = 'Post- vs. pre-\nremoval effort') + 
  facet_wrap(~SEASON) 
ggsave(paste0(basedir,
              'ecological/results/length_at_age_spring_fall.png'), height=4, width=6)

# Statistical comparison
pval_out<-tibble()
for(age_in in 0:4){
  for(season in c('S','F')){
    try({
      pv_lei<-summary(lm(LENGTH ~ pre_post, data = filter(size_at_age_data, ageLengthed==age_in, SEASON == season)))
      pval_out<-bind_rows(pval_out, 
                          tibble(ageLengthed=age_in, 
                                 pval_length=pv_lei$coefficients[2,4], 
                                 effect_length=pv_lei$coefficients[2,1],
                                 SEASON = season))
    })
  }
}

pval_out

# Random effect
rand<-nlme::lme(LENGTH ~ pre_post,
          random = ~1|ageLengthed,
          data = filter(size_at_age_data, 
                        SEASON == 'S', 
                        between(ageLengthed, 1, 4)))
summary(rand)
MuMIn::r.squaredGLMM(rand)

```

# Figure 3
## statgenGWAS to get PVE

```{r}
# set up list of all genotype calls
markers<-microhap_snp %>% 
  filter(GENID_duplicate %in% filter(phenos, # grab LML bass
                                     WATER == 'LML')$GENID_duplicate,
         !is.na(AlleIdx_genoty), 
         AlleIdx_genoty != '', 
         AlleIdx_genoty != 'N') %>% 
  group_by(GENID_duplicate) %>% 
  mutate(n=n()) %>% 
  filter(n>184*.7) %>% # remove low-scoring individuals
  ungroup() %>% 
  dplyr::select(genotype=GENID_duplicate, 
                locus, 
                AlleIdx_genoty) %>% 
  pivot_wider(names_from = locus, 
              values_from = AlleIdx_genoty) %>% 
  replace(is.na(.), 1)  # replace missing genotypes with heterozygote

# make the map of physical locations of all differentiated SNPs
markers_map<-tibble(loci = colnames(markers)) %>% 
  filter(str_detect(loci, 'adaptive')) %>% 
  mutate(locus = str_replace(loci, 
                             'adaptive_', 
                             ''),
         locus = str_replace(locus, 
                             'gwas_', 
                             ''))  %>% 
  separate(locus, 
           into = c('chr', 
                    'pos'), 
           sep = '_') %>% 
  mutate(chr = str_replace(chr, 
                           'lg', 
                           ''),
         chr = as.integer(chr)) %>% 
  separate(pos, 
           into = c('pos_temp1',
                    'pos_temp2'), 
           sep = '-pos') %>% 
  mutate(pos = as.integer(pos_temp1)) %>% 
  dplyr::select(-contains('pos_temp')) %>% 
  arrange(chr,
          pos) %>% 
  column_to_rownames('loci')

# include phenotype data
phenotype_data<-left_join(dplyr::select(markers,
                                        GENID_duplicate=genotype), 
                          phenos) %>% 
  dplyr::select(genotype = GENID_duplicate,
                predict_age,
                sex,
                yearly_length_anomaly,
                gsi_resid,
                GONAD_WEIGHT,
                mature,
                SEASON) %>% 
  mutate(sex = if_else(sex == 'F',
                       0,
                       1)) # all phenotypes need to be nuemeric

# make a function to run statgenGWAS. This is set up to have the user select, within function, whether to use LOD or FDR
run_gwas<-function(phenotype_data_filt_in, 
                   traits, 
                   gwas_markers, 
                   gwas_map, 
                   covars=NULL){ # covars are NULL if not specified
  
  # debug
  # phenotype_data_filt_in<- phenotype_data %>% filter(predict_age == 1, SEASON=='S')
  # traits<-c('yearly_length_anomaly','newGSI')
  # gwas_markers<-markers
  # gwas_map<-markers_map
  # covars<-NULL
  
  # grab the traits of interest
  phenos_in<-phenotype_data_filt_in %>% 
    dplyr::select(genotype,
                  traits)
  
  # filter marker data to just the individuals of interest
  markers_in<-phenos_in %>% 
    dplyr::select(genotype) %>% 
    left_join(gwas_markers) %>% 
    column_to_rownames('genotype')
  
  # split out the "neutral" and "adaptive" snp lists
  markers_adaptive<-dplyr::select(markers_in, # adaptive genotype calls
                                  contains('adaptive'))
  
  markers_neutral<-dplyr::select(markers_in, # neutral genotype calls for kinship
                                 contains('parentage'))
  
  
  # use the "neutral" SNPs to make a kinship matrix
  kin_matrix<-kinship(as.matrix(markers_neutral))
  
  # specify covars, if they are included as an argument
  if(!is.null(covars)) {
    covars <- phenotype_data_filt_in %>% 
      column_to_rownames('genotype') %>% 
      dplyr::select(covars)
  }
  
  # create gData object
  gData_in<-createGData(geno = as.data.frame(markers_adaptive),
                        map = as.data.frame(gwas_map),
                        pheno = as.data.frame(phenos_in),
                        kin = kin_matrix, 
                        covar = covars)
  
  # remove duplicated SNPs
  set.seed(123)
  gData_in_noDups<-codeMarkers(gData_in, 
                               impute = FALSE, 
                               verbose = TRUE) 
  
  # run GWAS on desired traits. statgenGWAS throws an error if there are no significant SNPs, so catch those here
  tryCatch({
    GWASDrops <- runSingleTraitGwas(gData = gData_in_noDups,
                                    # thrType = 'fixed', LODThr = -log10(0.05/5), # 5 fixed regions, so lower LOD score 
                                    thrType = 'fdr', 
                                    pThr = 0.05, # p-value for sig SNP
                                    rho = 0.5, # correlation for cluster
                                    alpha = 0.05, # p-value following cluster number correction
                                    covar = colnames(covars))# include covariates, if specified. NA values will be dropped)
    
    if(is.null(GWASDrops$signSnp$`as.data.frame(phenos_in)`)){
      tibble(trait = 'no effect')
    } else{
      GWASDrops$signSnp$`as.data.frame(phenos_in)`
    }
  },
  error = function(e) tibble(trait = 'no effect')
  )
}

# run age- and sex-specific tests
gwas_pval_out<-tibble()
for(age_in in c(1:5)){
  # yearly length anomaly with male, female, or unknown sex
  gwas_pval_out<-phenotype_data %>% 
    filter(predict_age == age_in,
           SEASON=='S') %>% 
    run_gwas(traits = 'yearly_length_anomaly',
             gwas_markers = markers, 
             gwas_map = markers_map) %>% 
    mutate(age=age_in,
           sex=NA) %>% 
    bind_rows(gwas_pval_out)
  
  # yearly length anomaly or newGSI with sex as a random effect
  gwas_pval_out<-phenotype_data %>% 
    filter(predict_age == age_in,
           SEASON=='S') %>% 
    run_gwas(traits = c('yearly_length_anomaly',
                        'gsi_resid'),
             #'GONAD_WEIGHT'),
             gwas_markers = markers, 
             gwas_map = markers_map,
             covars = 'sex') %>% 
    mutate(age=age_in,
           sex=10) %>% 
    bind_rows(gwas_pval_out)
  
  # yearly length anomaly or newGSI with just males or just females older than age 1
  #if(age_in>1){  
  for(sex_in in c(0,1)){
    gwas_pval_out<-phenotype_data %>% 
      filter(predict_age == age_in,
             SEASON=='S',
             sex==sex_in) %>% 
      run_gwas(traits = c('yearly_length_anomaly',
                          'gsi_resid'),#,
               #'GONAD_WEIGHT'),
               gwas_markers = markers, 
               gwas_map = markers_map) %>% 
      mutate(age=age_in,
             sex=sex_in) %>% 
      bind_rows(gwas_pval_out)
    #}
  }
}

# run for early- vs late-maturing bass
mature_lookup<-tibble(predict_age = c(2,2,3,3,3), # make a lookup table
                      sex = c(1,1,1,0,0),
                      mature = c(0,1,0,0,1),
                      early_late = c(0,1,0,0,1)) # late=0, early=1

mature_lookup<-tibble(predict_age = c(2,2,3,3), # make a lookup table
                      sex = c(1,1,0,0),
                      mature = c(0,1,0,1),
                      early_late = c(0,1,0,1)) # late=0, early=1

early_late<-phenotype_data %>% 
  left_join(mature_lookup, 
            by = c('predict_age', 
                   'sex',
                   'mature')) %>% 
  filter(!is.na(early_late)) 

early_late_gwas<-run_gwas(early_late,
         traits = 'early_late',
         gwas_markers = markers,
         gwas_map = markers_map)

# export table of GWAS hits
gwas_pval_out %>% 
  bind_rows(early_late_gwas) %>% 
  filter(trait != 'no effect') %>% 
  write_csv(paste0(basedir,
                   'chapter_3_exports/gwas_rough.csv')) %>% 
  mutate(effect = if_else(str_detect(pos, 
                                     "28398082|25601423"), 
                          -effect, 
                          effect)) %>% # correct for maf
  dplyr::select(trait, 
                age, 
                sex, 
                chromosome=chr, 
                position=pos, 
                pValue, 
                effect_size=effect, 
                effect_standard_error=effectSe, 
                proportion_variance_explained=propSnpVar) %>% 
  arrange(age, 
          trait, 
          sex) %>% 
  mutate(across(where(is.numeric), ~ round(.x, 3)),
         position=format(position,
                         scientific=T,
                         digits=2)) %>% 
  write_csv(paste0(basedir,
                   'chapter_3_exports/gwas_table.csv'))
```

## plot genotype - phenotype interactions 

```{r}
gwas_hits <-
  read_csv(paste0(basedir,
                  'chapter_3_exports/gwas_rough.csv')) %>%
  mutate(sex = if_else(sex == 0,
                       'F',
                       'M'),
         trait = if_else(trait == 'gsi_resid',
                         'GONAD_WEIGHT',
                         'LENGTH'))

phenos_in <- microhap_snp %>%
  filter(locus %in% gwas_hits$snp) %>%
  left_join(phenos) %>% 
  filter(SEASON == 'S')

figs_out<-list()
for (i in 1:3) { # don't run this for the lg7, which has a different pheno relationship
# i<-1
  gwas_row <- gwas_hits[i,]
  
  if (is.na(gwas_row$sex)) {
    data_in<-phenos_in %>%
      filter(predict_age == gwas_row$age,
             locus == gwas_row$snp)
  } else{
    data_in<-phenos_in %>%
      filter(predict_age == gwas_row$age,
             sex == gwas_row$sex,
             locus == gwas_row$snp)
  }
  
  if(str_detect(gwas_row$snp, '28398082|25601423')){
    data_in<-data_in %>% 
      mutate(AlleIdx_genoty = abs(AlleIdx_genoty-2)) # flip to polarize
  }
  
  figs_out[[i]]<-data_in %>% 
    no_relats('GENID_duplicate', # eclude closely related bass
              build_fams, 
              1, 
              123) %>% 
    ggplot(aes(as.character(AlleIdx_genoty), 
               !!sym(gwas_row$trait))) +
    geom_boxplot() +
    geom_jitter(height = 0,
                width = 0.1,
                alpha = 0.3) +
    labs(x = paste0(gwas_row$chr,
                    '-',
                    gwas_row$pos),
         y = paste0('Age-',
                    gwas_row$age,
                    ' ',
                    gwas_row$sex,
                    ' ',
                    gwas_row$trait))
}

# the binary early/late maturation figure
#figs_out[[4]]<-
  early_late %>% 
  left_join(markers) %>% 
  group_by(snp=`adaptive_lg7_25601423-pos201`, 
           early_late, 
           sex) %>% 
  tally() %>% 
  group_by(snp, 
           sex) %>% 
  mutate(prop_early = n/sum(n),
         sex = if_else(sex == 0, 
                       'female', 
                       'male'),
         snp = abs(snp-2)) %>% # flip to polarize
  filter(early_late == 1) %>% 
  ggplot(aes(snp, 
             prop_early, 
             color = sex, 
             group = sex)) +
  geom_jitter(aes(size = n)) +
  geom_line() +
  labs(x = 'Chromosome 7 SNP genotype',
       y = 'Proportion bass maturing early')
  
  
figs_out[[4]]<-early_late %>% 
  left_join(markers) %>% 
  mutate(age_sex = if_else(predict_age == 2,
                           '\nAge-2\nmale\n',
                           '\nAge-3\nfemale\n'),
         snp = abs(`adaptive_lg7_25601423-pos201`-2)) %>% 
  ggplot(aes(snp, 
             mature, 
             color = age_sex)) +
  geom_jitter(height = 0.1,
              width=0.1,
              alpha = 0.5) +
  geom_smooth(method='lm') +
  scale_y_continuous(breaks = c(0,
                                1))
```

## check polarization of significant lcwgs SNPs and amplicon SNPs
- We use -majorMinor 3 and a -sites reference to the global SNP list
- The global snp list was generated as an output, mafs.gz, then cut to just have the first 4 columns (chr, pos, maj, min)
- this has been preserved in our population-specific maf files, where the minor allele is 0 and major is 1
```{r}
# organize microhap SNP so that the major and minor alleles are listed
microhap_min<-microhap_snp %>% 
  filter(locus %in% gwas_hits$snp,
         AlleIdx_1 == 1) %>% # just grab the minor allele
  distinct(snp=locus,
           mhap_min=allele_1) 

gwas_hits %>% 
  left_join(dplyr::select(A_maf,
                          pos=position,
                          knownEM_2000=knownEM,
                          lcwgs_minor=minor)) %>% 
  left_join(microhap_min)

# based on this - flip lg19 127 lcwgs locus, then flip mhaps lg19 28398082 & lg7 25601423 28398082|25601423
```

## plot figure 3

```{r}
plot_grid(
    figs_out[[3]] +
      labs(x = 'Genotype\n(Chromosome 19, position 1.3E7)',
           y = 'Age-1 bass length (mm)') +
      ggtitle('a') +
      theme_cowplot(),
    figs_out[[2]] +
      labs(x = 'Genotype\n(Chromosome 19, position 2.8E7)',
           y = 'Age-3 male bass gonad weight (g)') +
      ggtitle('b') +
      theme_cowplot(),
    figs_out[[1]] +
      labs(x = 'Genotype\n(Chromosome 6, position 1.6E6)',
           y = 'Age-3 male bass length (mm)') +
      ggtitle('c') +
      theme_cowplot(),
    figs_out[[4]] +
      labs(x = 'Genotype\n(Chromosome 7, position 2.5E7)',
           y = 'Mature',
           color = '') +
      scale_x_continuous(breaks = c(0,
                                    1,
                                    2)) +
      ggtitle('d')  +
      theme_cowplot()
)
 
ggsave(paste0(basedir,
              '/chapter_3_exports/figure_3.pdf'),
       height=10,
       width=10)
```

# Figure 2 

manhattan plot of Zfst
```{r eval=T}
# plot windowed Fst
window_length <- 50*1000
minind <- 20

fst_window<-fst %>% 
  mutate(pos=cut(pos, # Make the window Fst
                 breaks=seq(0,
                            50*10^6,
                            window_length),
                 labels=seq(window_length/2,
                            50*10^6-window_length/2,
                            window_length))) %>% 
  group_by(name, pos) %>%
  summarise(fst_mean=sum(alpha)/sum(beta),
            n = n()) %>% 
  filter(n > 5, # grab windows with more than 5 SNPs
         !is.na(name)) %>% # only windows on chromosomes
  mutate(pos=as.numeric(as.character(pos))) %>% 
  ungroup()

# Plot Zfst
lcwgs_fst<-fst_window %>% 
  ungroup() %>%
  mutate( Zfst = (fst_mean - mean(fst_mean))/sd(fst_mean),
          signifi = if_else(Zfst > 5, 
                            0, 
                            1)) %>%
  ggplot(aes(x=pos/10^6, 
             y=Zfst)) +
  geom_point(aes(color = signifi), 
             size=0.5, 
             alpha=0.5) +
  geom_smooth(color='blue', 
              se=F) +
  scale_x_continuous(breaks=seq(0, 
                                50, 
                                5)) +
  labs(x='', 
       y = paste('ZFst\n',
                 window_length/1000,
                 'kb window')) +
  facet_grid(.~name, 
             scales='free_x', 
             space='free_x') +
  theme_cowplot() +
  geom_hline(yintercept = 5, 
             lty = 'dotted') +
  theme(panel.spacing = unit(0.1, 
                             'lines'),
        legend.position='none',
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

rareify individuals to generate allele frequency plot of SNPs identified in GWAS
```{r}
min_n_yearly <- 5
years_binned<-3
n_boot<-100

# bin loci into year groups
dat_in <- microhap_snp %>%
  left_join(dplyr::select(filter(phenos, WATER=='LML'),
              GENID_duplicate,
              year), 
            by = 'GENID_duplicate') %>%
  filter(!is.na(year)) %>%
  filter(str_detect(locus, "adaptive")) %>%
  mutate(year_bin = cut(year,  # bin into every 3 years, starting with 1995
                        breaks = seq(1970,
                                     2025,
                                     years_binned),
                        include.lowest = F)) %>%
  separate(locus, into = c('locus',
                           'xx'),
           sep = '-pos') %>%  # grab loci that ended up in statgengwas
  mutate(locus = str_replace_all(locus,
                                 'adaptive_|lg|gwas_',
                                 '')) %>%
  separate(locus, into = c('lg',
                           'pos')) %>%    # grab loci that ended up in statgengwas
  filter(pos %in% read_csv(paste0(basedir,
                                  'chapter_3_exports/gwas_rough.csv'))$pos) %>%
  mutate(locus = as.numeric(paste0(lg,
                                   '.',
                                   pos))) %>%
  dplyr::select(GENID_duplicate,
                locus,
                year_bin,
                AlleIdx_1, 
                AlleIdx_2)

dat_out<-tibble()
for(iter in 1:n_boot){
  set.seed(iter)
  dat_out<-dat_in %>% 
    group_by(locus, year_bin) %>% 
    filter(n() >= min_n_yearly) %>% 
    slice_sample(n=min_n_yearly,
                 replace = T) %>% 
    pivot_longer(-c(GENID_duplicate, 
                    locus, 
                    year_bin)) %>% 
    summarise(af = mean(value)) %>% 
    ungroup() %>% 
    mutate(iter = iter) %>% 
    bind_rows(dat_out)
}

# also pull the low-coverage SNP results to plot on this as well

# low-coverage allele frequency change
af_change<-read_csv(paste0(basedir,
                           'chapter_3_exports/gwas_rough.csv')) %>% 
  separate(snp,
           into=c('microhap_name','posx'),
           sep='-pos') %>% 
  left_join(dplyr::select(ordered_amplicons,
                          microhap_name,
                          chromo=chr)) %>% 
  dplyr::rename(position=pos) %>% 
  left_join(A_maf, 
            by = c('chromo', 
                   'position')) %>%
  dplyr::select(chromo, 
                chr,
                position, 
                af_2000 = 
                  knownEM, 
                n_2000 = nInd,
                major_2000 = major) %>%
  left_join(D_maf, 
            by = c('chromo', 
                   'position')) %>%
  dplyr::select(chromo,
                chr,
                position,
                af_2000,
                n_2000,
                major_2000,
                af_2019 = knownEM,
                n_2019 = nInd,
                major_2019=major) %>% 
  mutate(af_2000 = if_else(position==12740897, # polarize lg19
                           round(1-af_2000,
                                 2),
                           round(af_2000,
                                 2)),
         af_2019 = if_else(position==12740897,
                           round(1-af_2019,
                                 2),
                           round(af_2019,
                                 2)),
         snp = paste0('LG', 
                      chr,
                      ', pos=',
                      position),
         lg = paste0('Chromosome ',
                     chr))

af_change_joiner<-af_change %>% 
  dplyr::select(lg, contains('af')) %>% 
  pivot_longer(-lg,
               values_to='q50') %>% 
  mutate(year = as.integer(str_sub(name, 
                                   4,
                                   7)))

# combine microhap AF with lcWGS SNP point estimates
dat_plot<-dat_out %>% 
  group_by(locus, year_bin) %>% 
  summarise(q50 = quantile(af,
                           probs = 0.5)) %>% 
  separate(locus, 
           into = c('lg',
                    'pos')) %>% 
  mutate(q50 = if_else(str_detect(pos,
                                  "28398082|25601423"), # polarize
                       1-q50,
                       q50),
         year = as.numeric(str_sub(year_bin, 
                                   2, 
                                   5))+1, # we didnt' include lowest cutpoint
         lg = paste0('Chromosome ', 
                     lg)) 

# iterate over each locus to plot
af_figs<-list()
for(lg_in in unique(dat_plot$lg)){
  figs_in<-dat_plot %>% 
    filter(lg == lg_in) %>% 
    bind_rows(filter(af_change_joiner,
                     lg==lg_in)) %>% 
    mutate(Type = if_else(!is.na(name),
                          'Whole-genome',
                          'Amplicon'))
  
  af_figs[[lg_in]]<-figs_in %>% 
    ggplot(aes(year, 
               q50,
               color = Type,
               group = pos)) +
    geom_vline(xintercept = 2000.5,
               lty='dashed') +
    geom_point(size = 2) +
    geom_line(data = filter(figs_in,
                            Type != 'Whole-genome')) + # don't do the lines for whole-genome
    theme_cowplot() +
    lims(y = c(0,
               1),
         x = c(1970,
               2020)) +
    labs(x = '',
         y = paste0(lg_in,
                    '\nallele frequency'),
         color = '')  +
    theme(axis.title.x=element_blank(),
          axis.text.x = element_blank())
}
```

prep relatedness database
```{r, warning=F, message=F, error=F, echo=F}
water_ckmr<-'LML' # when running this for a new lake, will need to uncomment and run the for loop below "hwe_out<-tibble(), which calculates HWE for each locus

# Prep the genos going in into a long format
long_genos<-genind2df(obj, 
                      sep = '/') %>% 
  as_tibble(rownames = 'GENID_duplicate') %>% 
  pivot_longer(-c(GENID_duplicate, 
                  pop), 
               names_to = 'Locus') %>% 
  left_join(dplyr::select(phenos, 
                          GENID_duplicate, 
                          WATER)) %>% 
  filter(WATER == water_ckmr) %>% 
  dplyr::select(GENID_duplicate, 
                Locus, 
                value) %>% 
  separate(value, 
           into = c('1',
                    '2'), 
           sep = '/') %>% 
  pivot_longer(-c(GENID_duplicate, 
                  Locus)) %>% 
  dplyr::rename(Indiv = GENID_duplicate, 
         gene_copy = name, 
         Allele = value) %>% 
  filter(!is.na(Allele), 
         Allele != '', 
         Allele != 'NA', 
         Allele != 'N', 
         !str_detect(Allele, 
                     'NN')) 

# filter the long_genos for loci that don't show Ho deficit and for matching genotypes
matchers_lake<-read_csv(paste0(basedir,
                               'gtseq/results/matching_parentage_loci.csv'))

long_genos<-filter(long_genos, 
                   Indiv %nin% matchers_lake$indiv_1)

# Run all CKMR analyses
afreqs_ready <- long2freqs(long_genos) # generate allele frequency, index alleles
ex1_ckmr<-create_ckmr_mhap(afreqs_ready,
                           0.008)
ex1_Qs<-Qs(ex1_ckmr)

# Get allele counts 
afreqs_ready %>%
  group_by(Locus) %>%
  summarise(num_haplotypes = n()) %>% 
  group_by(num_haplotypes) %>% 
  tally()

# plot Q's
bind_rows(
  extract_logls(ex1_Qs, 
                numer = c(PO = 1), 
                denom = c(U = 1)),
  extract_logls(ex1_Qs, 
                numer = c(FS = 1), 
                denom = c(U = 1)),
  extract_logls(ex1_Qs, 
                numer = c(HS = 1), 
                denom = c(U = 1)),
  extract_logls(ex1_Qs, 
                numer = c(PO = 1), 
                denom = c(FS = 1))) %>% 
  filter(denom_wts == "U=1") %>%
  ggplot(aes(x = logl_ratio, 
             fill = true_relat)) +
  geom_density(alpha = 0.35) +
  facet_wrap(~ numer_wts, 
             ncol = 1) + 
  ggtitle('Panel power for separating full-sibs, half-sibs, and parent-offspring\n pairs from unrelated fish')

# find matchers 
matchers<-find_close_matching_genotypes(
  LG = long_genos,
  CK = ex1_ckmr, 
  max_mismatch = 5)

# if we have matchers, write a csv and exclude this above. the first time I run this I'll need to make a new csv
if(length(matchers$indiv_1)>0){
  bind_rows(matchers, 
            read_csv(paste0(basedir,
                               'gtseq/results/matching_parentage_loci.csv'))) %>% 
    write_csv(paste0(basedir,
                               'gtseq/results/matching_parentage_loci.csv'))
}
```

get POPs and FSPs
```{r, warning=F, message=F, error=F, echo=F}
# run ckmr on each year for adu and yoy
PO_potential<-tibble()
FS_potential<-tibble()
ckmr_in<- phenos %>% 
  filter(GENID_duplicate %in% long_genos$Indiv)

for(yr in unique(ckmr_in$predict_birthYr)){
  print(yr)
  #  yr<-2015
  
  # First, grab POPs from that cohort
  try({
    yoy<-filter(ckmr_in, predict_birthYr == yr)
    
    adu<-ckmr_in %>% 
      filter((between(predict_birthYr, yr-9, yr-3)) | (year==yr & mature==1)) %>% # we have some 9yo!
      filter(year>=yr)  # they can't be used for this year if they've already been taken out of the system
    
    PO_potential<-pairwise_kin_logl_ratios(D1=filter(long_genos, Indiv %in% adu$GENID_duplicate),
                                           D2=filter(long_genos, Indiv %in% yoy$GENID_duplicate),
                                           CK=ex1_ckmr, 
                                           numer='PO',
                                           denom='U') %>% 
      mutate(cohort=yr) %>% 
      bind_rows(PO_potential)
  })
  
  # Next, grab FSP
  try({
    yoy<-filter(ckmr_in, predict_birthYr == yr)
    
    FS_potential<-pairwise_kin_logl_ratios(D1=filter(long_genos, Indiv %in% yoy$GENID_duplicate),
                                           D2=filter(long_genos, Indiv %in% yoy$GENID_duplicate),
                                           CK=ex1_ckmr,
                                           numer='FS',
                                           denom='U') %>% 
      mutate(cohort=yr) %>% 
      bind_rows(FS_potential)
  })
}

# process and export PO
cut_math<-0.1*(nrow(PO_potential)^-1)
FPRs_PO<-mc_sample_simple(ex1_Qs, nu = "PO",de = "U",lambda_stars = seq(0,15, 0.01))
logL_cut<-filter(FPRs_PO, FPR < cut_math) %>% slice_head(n=1)

PO_potential  %>%
  mutate(pairN = row_number()) %>% 
  dplyr::select(pairN, D1_indiv, D2_indiv, logl_ratio) %>% 
  pivot_longer(-c(pairN, logl_ratio), values_to='GENID_duplicate') %>% 
  left_join(dplyr::select(phenos, GENID_duplicate, predict_birthYr, year), by = 'GENID_duplicate') %>% 
  mutate(name = str_replace(name, 'GENID_','')) %>% 
  pivot_wider(names_from=name, values_from = c(GENID_duplicate, predict_birthYr, year), names_glue = "{.value}_{name}") %>% 
  mutate(confirmed = if_else(logl_ratio>logL_cut$Lambda_star, 1, 0)) %>% 
  write_csv(paste0(basedir,
                   'chapter_3_exports/PO_potential.csv'))

# process and export FS
cut_math<-0.1*(nrow(FS_potential)^-1)
FPRs_FS<-mc_sample_simple(ex1_Qs, nu = "FS",de = "U",lambda_stars = seq(0,15, 0.01))
logL_cut<-filter(FPRs_FS, FPR < cut_math) %>% 
  slice_head(n=1)

FS_potential  %>%
  mutate(pairN = row_number()) %>% 
  dplyr::select(pairN, D1_indiv, D2_indiv, logl_ratio, cohort) %>% 
  pivot_longer(-c(pairN, logl_ratio, cohort), values_to='GENID_duplicate') %>% 
  left_join(dplyr::select(phenos, GENID_duplicate, year), by = 'GENID_duplicate') %>% 
  mutate(name = str_replace(name, 'GENID_','')) %>% 
  pivot_wider(names_from=name, values_from = c(GENID_duplicate, year), names_glue = "{.value}_{name}") %>% 
  mutate(confirmed = if_else(logl_ratio>logL_cut$Lambda_star, 1, 0)) %>% 
  write_csv(paste0(basedir,
                   'chapter_3_exports/FS_potential.csv'))
```

genetic drift, heterozygosity, relatedness, Ne
```{r}
missing_loci<-.05
missing_geno<-.3
min_n<-5 # decide on how many individuals per year we want
xlims<-c(1970, 2020) # the limits on the plots

# prep input data
fst_test<-
  genos %>% 
  left_join(dplyr::select(phenos, 
                          GENID_duplicate, 
                          predict_birthYr, 
                          WATER, 
                          year)) %>% 
  filter(WATER == 'LML', 
         str_detect(locus, 
                    'parentage')) %>% 
  mutate(predict_birthYr_guess = if_else(year == 1971, 
                                         1971,
                                         if_else(str_detect(year, 
                                                            '2000|2001'),
                                                 1998,
                                                 if_else(year == 1998, 
                                                         1995,
                                                         NA_integer_))),
         predict_birthYr = coalesce(predict_birthYr, 
                                    predict_birthYr_guess)) %>% 
  mutate(year_birth = paste0(year, 
                             '-', 
                             predict_birthYr)) %>% 
  dplyr::select(locus, 
                GENID_duplicate, 
                genoty, 
                year_birth) %>% 
  pivot_wider(names_from = locus, 
              values_from = genoty)

annual_fst_test<-
  df2genind(dplyr::select(fst_test, 
                          -c(GENID_duplicate, 
                             year_birth)), 
            sep = '/', 
            ploidy = 2, 
            ncode = 2, 
            ind.names = as.character(fst_test$GENID_duplicate), 
            pop = as.character(fst_test$year_birth),
            strata = separate(tibble(t=fst_test$year_birth),
                              t, 
                              into = c('year',
                                       'birth'), 
                              sep = '-')) %>% 
  missingno('loci', 
            0.75) %>% 
  missingno('geno', 
            0.75) %>% 
  missingno('loci', 
            missing_loci) %>% 
  missingno('geno', 
            missing_geno) %>% 
  setPop(~birth)

# Decide how many loci we need to capture the genetic diversity of the pop - estimate at least 20 loci or so. Use this to tune my missingno(geno)
#genotype_curve(annual_fst_test)

pop_list<-annual_fst_test@pop %>% # make the list of pops to include bsaed on the filter
  as_tibble() %>% 
  group_by(value) %>% 
  tally() %>% 
  filter(n>=min_n, 
         value != 'NA')

annual_fst_subset<-annual_fst_test %>% # subset the genind and re-calculate missingno
  popsub(sublist = pop_list$value) %>% 
  missingno('loci', 
            missing_loci) %>% 
  missingno('geno', 
            missing_geno)

# create plots
Ho_out<-Ho(annual_fst_subset) %>% 
  as_tibble(rownames = 'year') %>% 
  dplyr::rename(Ho = value) %>% 
  left_join(as_tibble(Hs(annual_fst_subset),
                      rownames = 'year')) %>% 
  dplyr::rename(He = value) %>% 
  mutate(year = as.integer(year)) %>% 
  dplyr::rename(Expected = He, 
         Observed = Ho) %>% 
  pivot_longer(-c(year), 
               names_to = 'Heterozygosity') %>% 
  group_by(year) %>% 
  mutate(min = min(value), 
         max = max(value)) %>% 
  ggplot() +
  geom_vline(xintercept = 2000.5, 
             lty='dashed') +
  geom_ribbon(aes(year,
                  value, 
                  ymin = min, 
                  ymax = max), 
              alpha = 0.2) +
  scale_fill_manual(values = c('white',
                               'black')) +
  geom_segment(aes(x=year, 
                   y=min, 
                   xend=year, 
                   yend=max), 
               alpha = 0.5) +
  geom_point(aes(year, 
                 value, 
                 fill = Heterozygosity), 
             shape = 21) +
  theme_cowplot() +
  labs(x = '', 
       y = 'Heterozygosity') +
  xlim(xlims) +
  theme(axis.title.x=element_blank(),
        axis.text.x = element_blank())

# Fst
obj_genepop<-annual_fst_subset %>% 
  graph4lg::genind_to_genepop() %>% 
  separate(ID, 
           into = c('ID',
                    'drop'), 
           sep = '_gtseq_') %>% # Need to get rid of the indivdiual labels so we can compare populations, not individuals
  dplyr::select(-drop)

obj_pair_D<-diveRsity::diffCalc(obj_genepop, 
                                pairwise = T, 
                                bs_pairwise = T, 
                                boots = 1000, 
                                para = T, 
                                fst = T)

Fst_out<-obj_pair_D$bs_pairwise %>%
  as.data.frame() %>%
  dplyr::rename(year_comp = gst.populations) %>%
  dplyr::select(-contains('populations')) %>%
  pivot_longer(-year_comp) %>%
  separate(name, into = c('Test',
                          'measure'), 
           sep = '\\.') %>%
  separate(year_comp, 
           into = c('year1',
                    'year2'), 
           sep = ' vs ') %>%
  mutate(year1 = as.integer(year1),
         year2 = as.integer(year2),
         year_diff = abs(year1-year2)) %>%
  group_by(year2) %>%
  filter(year1<year2) %>%
  filter(year_diff == min(year_diff),
         year_diff<55,
         str_detect(Test, 
                    'Fst|gst')) %>%
  pivot_wider(names_from = measure, 
              values_from = value) %>%
  mutate(`5% CI > 0` = if_else(lower<0, 
                               'no',
                               'yes'),
         actual_per_year = actual / year_diff) %>%
  ggplot(aes(year2, 
             actual_per_year)) +
  geom_line(aes(group = Test)) +
  geom_point(aes(color = `5% CI > 0`, 
                 shape = Test), 
             size = 3) +
  theme_cowplot() +
  labs(y = 'Annual genetic\ndivergence') +
  xlim(xlims) +
  geom_vline(xintercept = 2000.5, 
             lty='dashed')  +
  theme(axis.title.x=element_blank(),
        axis.text.x = element_blank())

# Ne
# group fish into bins of three years, then exclude nests (will increase Ne estimate)
fam_prune<-2# how many members of each family should we grab?  no more than 2

geno_count<-annual_fst_subset %>% 
  genind2df() %>% 
  as_tibble(rownames = 'GENID_duplicate') %>% 
  pivot_longer(-GENID_duplicate) %>% 
  filter(!is.na(value)) %>% 
  group_by(GENID_duplicate) %>% 
  tally()

fst_grouped<-annual_fst_test %>% 
  genind2df() %>% 
  as_tibble(rownames = 'GENID_duplicate') %>%
  mutate(year = as.integer(as.character(pop))) %>% 
  mutate(pop =if_else(between(year, 
                              1994, 
                              1997), 
                      1996,
                      if_else(between(year, 
                                      1999, 
                                      2003), 
                              2002,
                              if_else(between(year, 
                                              2004, 
                                              2006), 
                                      2005,
                                      if_else(between(year, 
                                                      2007, 
                                                      2009), 
                                              2008,
                                              if_else(between(year, 
                                                              2010, 
                                                              2012), 
                                                      2011,
                                                      if_else(between(year, 
                                                                      2013, 
                                                                      2015), 
                                                              2014,
                                                              if_else(between(year,
                                                                              2016, 
                                                                              2018), 
                                                                      2017,
                                                                      if_else(between(year, 
                                                                                      2019, 
                                                                                      2023), 
                                                                              2020, 
                                                                              NA_integer_))))))))) %>% 
  filter(!is.na(pop)) %>% 
  left_join(dplyr::select(phenos, 
                          GENID_duplicate, 
                          SAMPLE)) %>% 
  filter(!str_detect(SAMPLE, 
                     'NEST') | is.na(SAMPLE)) %>% 
  dplyr::select(-c(SAMPLE,year))

tracked_out<-tibble()
for(year_test in unique(fst_grouped$pop)){
  
  inds_in_ne<-fst_grouped %>% 
    filter(pop == year_test) %>% 
    left_join(dplyr::select(obj_fams, 
                            GENID_duplicate, 
                            fam_index)) %>% 
    pivot_longer(-c(GENID_duplicate, 
                    fam_index, 
                    pop)) %>% 
    filter(!is.na(value)) %>% 
    group_by(GENID_duplicate, 
             fam_index) %>% 
    tally() %>% 
    group_by(fam_index) %>% 
    arrange(desc(n),
            .by_group = T) %>% 
    slice_sample(n=fam_prune) %>% 
    ungroup()      
  
  tracked_out<-bind_rows(tracked_out, 
                         inds_in_ne)
}

# Now with this pruned list, run LDNe
ne_intermediate<-fst_grouped %>% 
  filter(GENID_duplicate %in% tracked_out$GENID_duplicate) %>% 
  arrange(pop) %>% 
  mutate(ind_temp = paste0('ind-',
                           row_number()),
         pop_temp = paste0('pop-', 
                           as.integer(pop)))

ne_in<-ne_intermediate %>% 
  dplyr::select(-c(GENID_duplicate, 
                   pop)) %>% 
  relocate(ind_temp, 
           pop_temp)

setwd(paste0(basedir,
             'rLDNe/'))
wd<-paste0(basedir,'rLDNe/')

gp_file<-RLDNe::write_genepop_zlr(loci = ne_in[,3:ncol(ne_in)],
                                  pops =  ne_in$pop_temp, # to look at Ne across all pops, just set this as 1
                                  ind.ids = ne_in$ind_temp,
                                  folder = wd,
                                  filename ="genepop_output_smb.txt",
                                  missingVal = NA,
                                  ncode = 2,
                                  diploid = T)

param_files<- RLDNe::NeV2_LDNe_create(input_file = gp_file$Output_File,
                                      param_file = paste0(wd,
                                                          "Ne_params_smb.txt"), 
                                      NE_out_file = paste0(wd,
                                                           "Ne_out_smb.txt"), 
                                      matingsystem = 0, 
                                      crit_vals = 0.01)

RLDNe::run_LDNe(LDNe_params = param_files$param_file)

ne__out<-readLines('Ne_out_smbxLD.txt')


joiner<-
  ne_intermediate %>% 
  mutate(Population = str_replace(pop_temp, 
                                  'pop-', ''),
         pop = as.integer(as.character(pop))) %>% 
  dplyr::select(ind_temp, 
                pop, 
                Population) 

final_line<-grep('Total number of populations', 
                 ne__out)-4

ne_fig<-ne__out[seq(16, 
                    final_line, 
                    2)] %>% # need to set 40 to the last informative line
  as_tibble() %>% 
  separate(value, 
           into = c('Population',
                    'xx'), 
           sep = ':') %>% 
  mutate(xx = str_squish(xx)) %>%  # get rid of those rows of spaces
  separate(xx, 
           into = as.character(1:14), 
           sep = ' ') %>% 
  mutate(ind_temp = as.character(`1`), 
         n = as.double(`2`), 
         Ne = as.double(`8`), 
         low = as.double(`11`), 
         high = as.double(`12`)) %>% 
  mutate(Population = str_squish(Population)) %>%  # get rid of those rows of spaces
  left_join(joiner, 
            by = 'ind_temp') %>% 
  filter(Ne>0) %>% 
  write_csv(paste0(basedir,
                   'chapter_3_exports/ne_out.csv')) %>% 
  ggplot(aes(pop, 
             Ne)) + 
  geom_point() + 
  geom_line() + 
  geom_ribbon(aes(ymin = low, 
                  ymax = high), 
              alpha = 0.2) + 
  scale_y_log10() + 
  theme_cowplot() + 
  labs(x='', 
       y = 'Effective population\nsize') + 
  geom_vline(xintercept = 2000.5, 
             lty='dashed') +
  xlim(xlims)  +
  theme(axis.title.x=element_blank(),
        axis.text.x = element_blank())

# Bring in relatedness within cohort, excluding egg samples. just freee-swimming BEF fish
fs_in<-read_csv(paste0(basedir,
                   'chapter_3_exports/FS_potential.csv')) %>% 
  dplyr::rename(D1 = GENID_duplicate_D1_indiv, 
                D2 = GENID_duplicate_D2_indiv) %>% 
  filter(D1 %nin% filter(phenos, 
                         str_detect(SAMPLE, 
                                    'NEST'))$GENID_duplicate & 
           D2 %nin% filter(phenos, 
                           str_detect(SAMPLE, 
                                      'NEST'))$GENID_duplicate)

sampled_n<-15
n_boot<-1000
fams_rare_out<-tibble()
for(year_in in unique(fs_in$cohort)){
  fs_loop<-fs_in %>% 
    filter(cohort == year_in)
  
  build_fams<-fs_loop %>% 
    filter(confirmed == 1) %>% 
    dplyr::select(D1, 
                  D2)
  
  g3<-simplify(graph.data.frame(build_fams[order(build_fams[[1]]),], 
                                directed = F))
  
  fam_matrix<-
    components(g3)$membership %>% 
    as_tibble(rownames = 'GENID_duplicate') %>% 
    right_join(tibble(GENID_duplicate = unique(fs_loop$D1))) %>% 
    arrange(value) %>% 
    mutate(fam_index = if_else(is.na(value), 
                               as.double(row_number()), 
                               value), # add sequential numbers
           fam_index = as.double(as.factor(fam_index))) 
  
  if(nrow(fam_matrix)>sampled_n){
    for(boot in 1:n_boot){
      boot_in<-fam_matrix %>% 
        slice_sample(n=sampled_n, 
                     replace = F) %>% 
        filter(!duplicated(fam_index))
      fams_rare_out<-bind_rows(fams_rare_out,
                               tibble(year = year_in,
                                      boots = boot,
                                      n_fams = nrow(boot_in),
                                      n_total = nrow(fam_matrix)))
    }
  }
}

# Make a summarised dataset 
final_dat<-
  fams_rare_out %>% 
  mutate(n_sibs = sampled_n-n_fams,
         percent_sibs = n_sibs/sampled_n) %>% 
  group_by(year) %>% 
  summarise(mn = mean(percent_sibs), 
            sd_f = sd(percent_sibs), 
            n_total = unique(n_total)) %>% 
  mutate(se_f = sd_f / sqrt(n_total),
         lower_ci = mn - qt(1 - (0.05 / 2), 
                            n_total - 1) * se_f, # calculate 95% upper and lower confidence interval
         upper_ci = mn + qt(1 - (0.05 / 2), 
                            n_total - 1) * se_f) 

# Check if the number of samples in a year impacts the mean or CI. It doesn't change the mean or 95% CI
summary(lm(mn~n_total, 
           data = final_dat)) # mn, upper_ci, lower_ci
ggplot(final_dat, 
       aes(mn, 
           n_total)) + 
  geom_point() + 
  geom_smooth(method = 'lm')

# Plot with 95% CI
fs_cohort<-ggplot(final_dat, 
                  aes(year, 
                      mn)) + 
  geom_point() + 
  geom_line() + 
  geom_ribbon(aes(ymin = lower_ci, 
                  ymax = upper_ci), 
              alpha = 0.2) + 
  theme_cowplot() + 
  labs(y='Full-sibling\nproportion in cohort') + 
  xlim(xlims) + 
  geom_vline(xintercept = 2000.5, 
             lty='dashed') +
  theme(axis.title.x=element_blank(),
        axis.text.x = element_blank())

# include overall CPUE
cp_year<-read_csv(paste0(basedir,
                         'chapter_3_exports/cpue_overall.csv')) %>% 
  ggplot(aes(year, 
             cpue)) +
  geom_vline(xintercept = 2000.5, 
             lty = 'dashed') +
  geom_smooth(span = .1) +
  xlim(xlims) +
  theme_cowplot() +
  labs(x='Year', 
       y = 'Catch / minute')

# Sanity check (to go in the supplement) - do we see systematic bias in # of scoring loci?
annual_fst_test %>% 
  genind2df() %>% 
  as_tibble(rownames = 'ind') %>% 
  pivot_longer(-c(ind, 
                  pop)) %>% 
  filter(!is.na(value))  %>% 
  group_by(ind, 
           pop) %>% 
  summarise(prop_loci = n()/32) %>% 
  mutate(year = as.integer(as.character(pop))) %>% 
  ggplot(aes(year, 
             prop_loci)) +
  geom_count() +
  theme_cowplot() +
  labs(x = 'Year', 
       y = 'Proportion of scoring loci\nper individual')
ggsave(paste0(basedir,
              'chapter_3_exports/prop_scoring_loci_perInd.png'), 
       height = 4, 
       width = 7)
```

plot
```{r}
plot_grid(
  plot_grid(
    lcwgs_fst + ggtitle('a') + 
      scale_y_continuous(labels=function(x) sprintf("%.2f", x)) +
      xlab('Genomic position'),
    af_figs$`Chromosome 6` +
      ggtitle('b') +
      theme(legend.position = 'none'),
    af_figs$`Chromosome 7` +
      ggtitle('c') +
      theme(legend.position = 'none'),
    af_figs$`Chromosome 19` +
      ggtitle('d') +
      theme(legend.position = 'none'),
    Ho_out + 
      theme(legend.position = "none") + 
      scale_y_continuous(limits = c(0.4,0.6),
                         breaks = seq(0.4,0.6, 0.05)) +         
      ylab('\nHeterozygosity') +
      ggtitle('e'),
    ne_fig + 
      scale_y_continuous(limits = c(0,35),
                         labels=function(x) sprintf("%.1f", x)) +
      ggtitle('f'),
    Fst_out + 
      theme(legend.position = 'none')  + 
      ggtitle('g'),
    fs_cohort + 
      scale_y_continuous(labels=function(x) sprintf("%.2f", x)) +
      ggtitle('h'),
    cp_year + 
      ylab('\nCatch / minute') +
      scale_y_continuous(labels=function(x) sprintf("%.2f", x)) +
      ggtitle('i'),
    align = 'v',
    ncol = 1
  ),
  plot_grid(
    ggplot() + 
      theme(panel.background = element_blank()),
    get_legend(af_figs$`Chromosome 6`),
    theme(panel.background = element_blank()),
    theme(panel.background = element_blank()),
    get_legend(Ho_out),
    ggplot() + 
      theme(panel.background = element_blank()),
    get_legend(Fst_out),
    ggplot() + 
      theme(panel.background = element_blank()),
    ggplot() + 
      theme(panel.background = element_blank()),
    ncol =1),
  rel_widths = c(10,3)
)

ggsave(paste0(basedir,
              'chapter_3_exports/fig2.pdf'), 
       height=20, 
       width = 10)
```

# Supplement

## Biomass kilo/hour in the spring

```{r}
# Estimate weight for all LML fish to look at biomass cpue
AF_biomass<-allFish %>% 
  filter(!is.na(LENGTH), 
         !is.na(WEIGHT),
         WATER=='LML', 
         year>1994, 
         (GEAR_CODE=='NAF' | GEAR_CODE == 'NBO'), 
         between(month,
                 5,
                 6))

AF_LML<-allFish %>% 
  filter(!is.na(LENGTH), 
         WATER=='LML', 
         year>1994, 
         GEAR=='BEF', 
         (GEAR_CODE=='NAF' | GEAR_CODE == 'NBO'), 
         between(month,
                 5,
                 6))

# Tested R2 with and without year as a fixed variable - 0.98 with year, 0.97 without
# library(ggpmisc) # for putting R2 on graph

# LWdata_logModel <- lm(WEIGHT ~ LENGTH^3 + as.character(year), data = AF_biomass) 
LWdata_logModel <- lm(log(WEIGHT) ~ log(LENGTH) + as.character(year), 
                      data = AF_biomass) 

summary(LWdata_logModel)

AF_LML_weightPred<-
  predict(LWdata_logModel, 
          newdata=AF_LML, 
          interval = "confidence") %>% 
  as_tibble() %>% 
  bind_cols(AF_LML) %>% 
  mutate(weightPred=exp(fit))

# Plot the fit
ggplot(AF_LML_weightPred, 
       aes(WEIGHT, 
           weightPred)) +
  geom_point() +
  geom_abline()

# Plot the biomass per u e
AF_biomass<- AF_LML_weightPred %>%
  mutate(jDate = lubridate::yday(DATE_COL),
         ysamp = str_sub(YSAMP_N, 
                         -2)) %>% 
  filter(between(year, 
                 1998, 
                 2020), 
         !is.na(effortSec), 
         (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO'), 
         WATER == 'LML', 
         month<7) %>% 
  group_by(year, 
           SITE_N) %>% 
  filter(jDate == min(jDate)) %>% # Just grab the first jDate of the SITE_N of the year
  filter(ysamp == min(ysamp)) %>% # Just grab the first sampling site of the day
  ungroup() %>% 
  filter(SITE_N %nin% missing_sites$SITE_N,
         SITE_N %in% site_distances$Site) %>% 
  group_by(year, 
           SITE_N) %>% 
  summarise(cpue_kph = (sum(weightPred)/1000)/(unique(effortSec)/360)) %>% 
  ungroup()

# average before vs after biomass
bio_summ<-AF_biomass %>% 
  group_by(year) %>% 
  summarise(mean_kph = mean(cpue_kph)) %>% 
  mutate(cpue_gpm = (mean_kph*1000)/60) %>% 
  ungroup() %>% 
  mutate(before_after = if_else(year<2001, 
                                'bef', 
                                'aft')) %>% 
  group_by(before_after) %>% 
  summarise(mean_gpm = mean(cpue_gpm, 
                            na.rm = T))

# Biomass decreased by...
1-bio_summ$mean_gpm[1]/bio_summ$mean_gpm[2]

#Plot the kilo/hour
AF_biomass %>% 
  mutate(cpue_gpm = (cpue_kph*1000)/60) %>% 
  ggplot(aes(year, 
             cpue_gpm)) +
  geom_smooth(span=0.1) +
  labs(y = 'Grams / minute', 
       x = 'Year') + 
  geom_vline(xintercept = 2000.5, 
             lty = 'dotted') +
  geom_segment(aes(x = 1998, 
                   xend = 2000.5, 
                   y = bio_summ$mean_gpm[2], 
                   yend = bio_summ$mean_gpm[2])) +
  geom_segment(aes(x = 2000.5, 
                   xend = 2020, 
                   y = bio_summ$mean_gpm[1], 
                   yend = bio_summ$mean_gpm[1])) +
  theme_cowplot()
ggsave(paste0(basedir,
              'chapter_3_exports/supplement_biomass.png'), 
       height=4, 
       width=6)
```

## CPUE by size-class, most robust (seasonal window, first pass, shoreline lengths)

```{r}
allFish %>%
  mutate(jDate = lubridate::yday(DATE_COL),
         ysamp = str_sub(YSAMP_N, 
                         -2)) %>% 
  filter(between(year, 
                 1998, 
                 2020), 
         !is.na(effortSec), 
         (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO'), 
         WATER == 'LML', 
         month<7) %>% 
  group_by(year, 
           SITE_N) %>% 
  filter(jDate == min(jDate)) %>% # Just grab the first jDate of the SITE_N of the year
  filter(ysamp == min(ysamp)) %>% # Just grab the first sampling site of the day
  ungroup() %>% 
  filter(between(jDate, 
                 134, 
                 145)) %>% 
  mutate(lenBin = if_else((LENGTH < 100 | is.na(LENGTH)), 
                          '0-100',
                          if_else(between(LENGTH, 
                                          100, 
                                          200), 
                                  '100-200',
                                  if_else(LENGTH > 200, 
                                          '200+', 
                                          '0')))) %>% 
  group_by(year, 
           effortSec, 
           SITE_N, 
           lenBin) %>% # lenBin
  tally() %>% 
  ungroup() %>% 
  mutate(cpue = (n/effortSec)*60) %>%  # fish per minute 
  dplyr::select(year, 
                SITE_N, 
                lenBin, 
                cpue) %>% 
  pivot_wider(names_from=lenBin, 
              values_from=cpue) %>% 
  mutate_all(~ifelse(is.na(.), 
                     0, 
                     .)) %>% # fill in all NA's with zero
  pivot_longer(-c(year, 
                  SITE_N), 
               names_to='lenBin',
               values_to='cpue') %>% 
  group_by(SITE_N) %>% 
  filter(min(year) == 2000) %>% 
  ggplot(aes(year,
             cpue, 
             group = lenBin, 
             color = lenBin)) +
  geom_point() + 
  geom_line() + 
  facet_wrap(~SITE_N, 
             scales = 'free')  + 
  theme_cowplot() +
  theme(axis.text.x = element_text(angle = 45, 
                                   vjust = 1, 
                                   hjust=1)) +
  geom_vline(xintercept = 2000.5, 
             lty = 'dashed') +
  labs(y = 'Catch per minute of electrofishing', 
       x = 'Year', color = 'Length\nbin\n(mm)') +
  scale_color_viridis_d()
ggsave(paste0(basedir,
              'chapter_3_exportschapter_3_exports/conservative_filter_cpue.png'), 
       height = 10, 
       width = 10)
```

## Seasaonal shift in sampling effort

```{r}
naf_dates<-allFish %>%
  filter(WATER == 'LML', 
         GEAR_CODE == 'NAF') %>% 
  group_by(DATE_COL, 
           SITE_N_NEW) %>% 
  tally() %>% 
  ungroup() %>% 
  group_by(DATE_COL) %>% 
  tally() %>% 
  mutate(jDate = lubridate::yday(DATE_COL),
         year = lubridate::year(DATE_COL)) %>% 
  filter(between(jDate, 
                 100, 
                 200))

# plot
naf_dates %>% 
  ggplot(aes(year, 
             jDate, 
             color = n)) + 
  geom_point() + 
  geom_jitter(height=0, 
              width=0.2) +
  theme_cowplot() +
  scale_color_viridis_c() +
  geom_hline(yintercept = 134, 
             lty = 'dashed') +
  geom_hline(yintercept = 145, 
             lty = 'dashed') +
  labs(x = 'Year', 
       y = 'Julian date', 
       color = 'number\nof\nsites\nsampled')
ggsave(paste0(basedir,
              'chapter_3_exports/seasonal_sampling_shift.png'),
       height = 4,
       width = 6)

# get minimum dates
naf_dates %>% 
  group_by(year) %>% 
  summarise(min_julian = min(jDate))

```

## How many adults do we remove each year? CPUE of adults by shoreline length

```{r}
# adult catch through time
adults_allYears<-allFish %>% 
  filter(WATER == 'LML', 
         (LENGTH > 225 | mature == 1), 
         GEAR == 'BEF', 
         year > 1999) %>% 
  group_by(year) %>% 
  tally()

ggplot(adults_allYears, 
       aes(year, n)) + 
  geom_point() + 
  geom_line()

filter(adults_allYears, 
       year == 2000) # number of adults in 2000

filter(adults_allYears, 
       year > 2000) %>% 
  summarise(mean_n = mean(n), 
            sd_n = sd(n),
            min = min(n),
            max = max(n))  # number of adults after 2000

# CPUE of adults by shoreline length

# Plot
allFish %>%
  filter(!is.na(effortSec), 
         (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO'), 
         WATER == 'LML', 
         month<7, 
         between(year,
                 1998, 
                 2020)) %>% 
  left_join(site_distances,
            by = 'SITE_N') %>% 
  mutate(adults = if_else(LENGTH < 225 | is.na(LENGTH), 
                          0, 
                          1)) %>% # account for days with 0 adults
  filter(!is.na(SITE_N), 
         !is.na(Shape_Length)) %>% 
  group_by(year, 
           SITE_N, 
           DATE_COL, 
           Shape_Length) %>%
  summarise(n_adults = sum(adults),
            effortSec = unique(effortSec)) %>% # Number of fish over 225 caught on each date, site, and year
  ungroup() %>% 
  group_by(year, 
           SITE_N) %>% 
  mutate(day_index=as.numeric(factor(as.character(DATE_COL)))) %>% # Just grab the first day
  ungroup() %>% 
  filter(day_index==1) %>% # Just grab the first NAF days of each site of each year
  filter(SITE_N %nin% missing_sites$SITE_N, # exclude the sites that were not well-covered
         SITE_N != 'BEF.LML.001') %>% 
  mutate(cpue = (n_adults/effortSec)*60) %>%   #  effortSec OR Shape_Length
  ggplot(aes(year, 
             cpue)) + # , color = lenBin, lty = lenBin
  geom_boxplot(aes(group = year)) +
  geom_smooth(span=0.15) +
  #scale_y_continuous(trans='log10') +
  geom_vline(xintercept = 2000.5, 
             lty = 'dotted') +
  theme_cowplot() +
  labs(x='', 
       y = 'Adult catch / minute')
ggsave(paste0(basedir,
              'figures/lml_cpue_adults_shoreline.png'),
       height=4, 
       width=6)

allFish %>% 
  filter(GEAR == 'BEF' , 
         year == 1998, 
         WATER == 'LML') %>% 
  group_by(YSAMP_N, 
           SITE_N, 
           monthDay, 
           effortSec, 
           GEAR_CODE) %>% 
  tally()

allFish %>% 
  group_by(SITE_N) %>% 
  tally()

```

## CPUE without length bins

```{r}
# Generate the dataset
cpue_AF<-allFish %>%
  mutate(jDate = lubridate::yday(DATE_COL),
         ysamp = str_sub(YSAMP_N, 
                         -2)) %>% 
  filter(between(year, 
                 1998, 
                 2020), 
         !is.na(effortSec), 
         (GEAR_CODE == 'NAF' | GEAR_CODE == 'NBO'), 
         WATER == 'LML', 
         month<7) %>% 
  group_by(year, 
           SITE_N) %>% 
  filter(jDate == min(jDate)) %>% # Just grab the first jDate of the SITE_N of the year
  filter(ysamp == min(ysamp)) %>% # Just grab the first sampling site of the day
  ungroup() %>% 
  filter(SITE_N %nin% missing_sites$SITE_N,
         SITE_N %in% site_distances$SITE_N) %>% 
  group_by(year, 
           SITE_N) %>% 
  summarise(cpue = (n()/unique(effortSec))*60) %>% 
  ungroup() %>% 
  write_csv(paste0(basedir,
                   'chapter_3_exports/cpue_overall.csv'))

# average before vs after biomass
cpue_summ<-cpue_AF %>% 
  group_by(year) %>% 
  summarise(mean_kph = mean(cpue)) %>% 
  ungroup() %>% 
  mutate(before_after = if_else(year<2001, 
                                'bef', 
                                'aft')) %>% 
  group_by(before_after) %>% 
  summarise(mean_kph = mean(mean_kph, 
                            na.rm = T))

# CPUE increased by...
cpue_summ$mean_kph[1]/cpue_summ$mean_kph[2]-1

#Plot the cpue/hr
cpue_AF %>% 
  ggplot(aes(year, 
             cpue)) +
  geom_smooth(span=0.1) +
  labs(y = 'Fish / minute', x = 'Year') + 
  geom_vline(xintercept = 2000.5, lty = 'dotted') +
  geom_segment(aes(x = 1998, 
                   xend = 2000.5, 
                   y = cpue_summ$mean_kph[2], 
                   yend = cpue_summ$mean_kph[2])) +
  geom_segment(aes(x = 2000.5, 
                   xend = 2020, 
                   y = cpue_summ$mean_kph[1], 
                   yend = cpue_summ$mean_kph[1])) +
  theme_cowplot()
ggsave(paste0(basedir,
              '/chapter_3_exports/supplement_cpue.png'), 
       height=4, 
       width=6)
```


## Effort through suppression years

```{r}
# total BEF effort (days) across years
effort_BEF_years<-filter(allFish, 
                         WATER == 'LML', 
                         GEAR == 'BEF', 
                         between(year, 
                                 2000, 
                                 2020)) %>% 
  group_by(year, 
           month, 
           day) %>% 
  tally() %>% 
  ungroup() %>% 
  group_by(year) %>% 
  summarise(removal_electrofishing_days_nights = n())

# total BEF effort (hours) across years. There are quite a few missing values for effort, so just running with unique YSAMP_N's
filter(allFish, 
       WATER == 'LML', 
       GEAR == 'BEF', 
       between(year, 
               2000, 
               2020)) %>% 
  group_by(year, 
           YSAMP_N) %>% 
  summarise(effort = sum(effortSec), 
            n_bass = n()) %>% 
  filter(is.na(effort)) %>% 
  write_csv(paste0(basedir,
                   'chapter_3_exports/no_effort.csv'))

# total removal days all years - plot both days and fish removed
coeff <- 300 # the transformation to bring the second axis into line with the first

filter(allFish, 
       WATER == 'LML', 
       GEAR == 'BEF', 
       between(year,
               2000,
               2022)) %>% 
  group_by(year, 
           month, 
           day) %>% 
  tally() %>% 
  ungroup() %>% 
  group_by(year) %>% 
  summarise(Days_electrofished = n(),
            fish_captured = sum(n)) %>% 
  ggplot(aes(year)) +
  geom_point(aes(y=Days_electrofished), 
             color = 'blue') +
  geom_point(aes(y=fish_captured/coeff), 
             color = 'green') +
  geom_line(aes(y = Days_electrofished), 
            color = 'blue') +
  geom_line(aes(y = fish_captured/coeff), 
            color = 'green') +
  scale_y_continuous(
    name = "Days of electrofishing (blue)",
    sec.axis = sec_axis(~.*coeff, 
                        name="Total bass removed (green)")
  ) +
  theme_cowplot() +
  lims(x = c(1998, 
             2020)) +
  geom_vline(xintercept = 2000.5, 
             lty = 'dashed')

# Use Kurt's missing sites. Note - I consolidated 2000 across May and June
missing_sites_all_years<-read_xlsx('/workdir/smallmouth/ecological/kurt_matched_naf_surveys.xlsx', 
                                   sheet = 'missing_sites_2000consolidated') %>% 
  mutate(Site = paste0('BEF.LML.',
                       as.character(str_pad(Spring_NAF_missing_sites, 
                                            3, 
                                            pad = "0"))),
         keep = 0) %>% 
  dplyr::select(year, 
                Site, 
                keep)

# Total number of fish removed each year
fish_removed<-allFish %>% 
  filter(WATER == 'LML', 
         GEAR == 'BEF', 
         between(year, 
                 2000, 
                 2022)) %>% 
  group_by(year) %>% 
  summarise(n_fish = n())

# average number of fish removed yearly
summarise(fish_removed, 
          mean(n_fish), 
          sd(n_fish))

# How many days were there of electrofishing surveys in '98 and '99?
allFish %>% 
  filter(WATER == 'LML', 
         GEAR == 'BEF', 
         between(year, 
                 1998, 
                 1999)) %>% 
  group_by(year, 
           month, 
           day) %>% 
  tally() %>% 
  ungroup() %>% 
  group_by(year) %>% 
  tally()

# Make a table of total sites (number, percent) and distance of shoreline shocked (meters, percent)
tibble(year = rep(1998:2020, 
                  each=32), 
       Site = rep(site_distances$SITE_N[1:32], 23)) %>% 
  left_join(missing_sites_all_years, 
            by = c('year', 
                   'Site')) %>% 
  left_join(dplyr::rename(site_distances,
                          Site=SITE_N), 
            by = 'Site') %>% 
  mutate(keep = if_else(is.na(keep), 
                        1, 
                        0)) %>% 
  group_by(year, 
           keep) %>% 
  summarise(total_sites = n(),
            shoreline_shocked_km = round(sum(Shape_Length),
                                         -1)/1000) %>% 
  filter(keep == 1) %>% 
  mutate(site_proportion = round(total_sites/32,
                                 2),
         shoreline_shocked_proportion = round(shoreline_shocked_km/11.54,
                                              2)) %>% 
  left_join(effort_BEF_years, 
            by = 'year') %>% 
  left_join(fish_removed, 
            by = 'year') %>% 
  dplyr::select(year, 
                total_sites, 
                site_proportion, 
                shoreline_shocked_km, 
                shoreline_shocked_proportion, 
                removal_electrofishing_days_nights, 
                n_fish) %>% 
  write_csv(paste0(basedir,
                   'ecological/total_sites_missing_shoreline_missing.csv'))

```

## LD through removal for lg19
```{r}
lg_19_loci <-read_csv(paste0(basedir,
                             'chapter_3_exports/lg19_loci.csv'))

lg_in <- 'lg19'

yrs <- tibble(start = c(1950,
                        2009,
                        2016),
              end = c(2008,
                      2015,
                      2023))

for (yr_in in 1:nrow(yrs)) {
  yr_start <- yrs[yr_in, ]$start
  yr_end <- yrs[yr_in, ]$end
  
  # first, convert NA's to 0 and add 1 to other genotyp values. change locus name to position. set position
  adapt_gdat_prep <- microhap_snp %>%
    filter(
      str_detect(locus,
                 lg_in),
      str_detect(locus,
                 'adaptive'),
      locus %in% lg_19_loci$locus) %>% # This isjust for the interesting loci on lg19
    left_join(phenos, 
              by = 'GENID_duplicate') %>%
    filter(WATER == 'LML', 
           between(year, 
                   yr_start, 
                   yr_end)) %>%
    separate(locus, 
             into = c('locus', 
                      'pos1'), 
             sep = '-pos') %>%
    separate(locus,
             into = c('xx', 
                      'pos2'),
             sep = paste0(lg_in, 
                          '_')) %>%
    mutate(pos = round((as.double(pos1) + as.double(pos2)) / 1e6), 
           1) %>%
    dplyr::select(Ind = GENID_duplicate, 
                  pos, 
                  AlleIdx_genoty) %>%
    arrange(pos)
  
  adapt_gdat <-
    pivot_wider(adapt_gdat_prep,
                names_from = 'pos',
                values_from = AlleIdx_genoty) %>%
    dplyr::select(-Ind) %>%
    as.matrix()
  
  corplot <- as_tibble(adapt_gdat)
  colnames(corplot) <- paste0(colnames(corplot), 
                              ' Mbp')
  
  cor_year <- cor(corplot, method = 'spearman', use = 'pairwise.complete.obs')
  
  ggcorrplot::ggcorrplot(corr = cor_year,
                         lab_size = 3,
                         title = paste0(yr_start, 
                                        '-', 
                                        yr_end, 
                                        ' Little Moose ', 
                                        lg_in)) #  lab = T
  ggsave(paste0("/workdir/smallmouth/chapter_3_exports/corrplot-LML-",
                lg_in,
                "-start",
                yr_start,
                "-end",
                yr_end,
                ".png"),
         height = 4,
         width = 4
  )
}
```

## PMRN in Little Moose across the years
```{r}
year_sep <- 3 # how many years to bin by?

L50_out <- tibble()

quantiles <-
  c(0.25, 0.5, 0.75) # pick which quantiles we want to extract

for (sex_in in c('M', 'F')) {
  for (ageLengthed_in in 2:5) {
    for (year_in in seq(2000,
                        2023,
                        year_sep)) {
      glm_in <- allFish %>%
        filter(
          WATER == 'LML',
          !is.na(mature),
          sex == sex_in,
          ageLengthed == ageLengthed_in,
          between(year,
                  year_in,
                  year_in + (year_sep - 1))
        )
      try({
        L50 <- tibble(
          value = as.double(MASS::dose.p(
            glm(mature ~ LENGTH,
                family = binomial,
                data = glm_in),
            p = quantiles
          )),
          bin = quantiles,
          sex = if_else(sex_in == 'M',
                        'Male',
                        'Female'),
          ageLengthed = ageLengthed_in,
          year  = as.character(year_in),
          n = nrow(glm_in),
          n_mat = nrow(filter(glm_in,
                              mature == 1)),
          n_not_mat = nrow(filter(glm_in,
                                  mature == 0))
        )
        L50_out <- bind_rows(L50_out,
                             L50)
      })
    }
  }
}


L50_out %>%
  filter(n_mat > 1,
         n_not_mat > 1) %>%
  pivot_wider(names_from = bin,
              values_from = value) %>%
  ggplot(aes(ageLengthed,
             color = year,
             fill = year)) +
  geom_ribbon(
    aes(y = `0.5`,
        ymin = `0.25`,
        ymax = `0.75`),
    color = 'lightgrey',
    alpha = 0.5,
    position = position_dodge(width = 0.4)
  ) +
  geom_pointrange(aes(y = `0.5`,
                      ymin = `0.25`,
                      ymax = `0.75`),
                  position = position_dodge(width = 0.4)) +
  geom_line(aes(y = `0.5`),
            position = position_dodge(width = 0.4)) +
  facet_wrap(~ sex,
             ncol = 1,
             scales = 'free_y') +
  theme_cowplot() +
  scale_x_continuous(breaks = 2:4) +
  labs(x = 'Age',
       y = 'Total length (mm)',
       fill = 'Year',
       color = 'Year') +
  scale_color_viridis_d('year') +
  scale_fill_viridis_d('year')

ggsave(
  paste0(basedir,
         'chapter_3_exports/pmrn_plot.png'),
  height = 4,
  width = 6
)
```

## Compare neutral to adaptive AF change annually through the suppression, and make table of sample
sizes

do this again, but subsampling within each geneation (binned by 3 years)
```{r}
# decide on how many individuals per year we want
min_n <- 10 # number of distinct genomes, so n_ind * 2

# Build dataset
fst_test <-
  microhap_snp %>%
  left_join(dplyr::select(phenos, GENID_duplicate, WATER, year)) %>%
  filter(WATER == 'LML', (str_detect(locus, 'parentage') |
                            locus %in% gwas_hits$snp)) %>% # don't grab the lg7 or sex
  separate(locus,
           into = c('loc1', 'pos'),
           sep = 'pos',
           remove = F) %>% # grab the first SNP in each locus
  group_by(loc1) %>%
  filter(pos == min(pos)) %>%
  ungroup() %>%
  mutate(
    loc_type = if_else(
      str_detect(locus, 'parentage'),
      'neutral-',
      if_else(
        str_detect(locus, 'lg19'),
        'lg19-',
        if_else(str_detect(locus, 'lg6'), 'lg6-', 'lg7-')
      )
    ),
    locus = paste0(loc_type, as.integer(as.factor(locus))),
    year_bin = cut(year,  # bin into every 3 years, starting with 1995
                   breaks = seq(1970,
                                2025,
                                3)),
    # rename loci to work in genind
    year_bin = paste0(as.numeric(str_sub(year_bin, # had to re-name beacuse the bin names are confusing
                                         2,
                                         5)) + 1,
                      '-',
                      str_sub(year_bin,
                              7,
                              10))
  )

# Export sample sizes
fst_test %>%
  group_by(locus, year_bin) %>%
  tally() %>%
  arrange(year_bin) %>%
  pivot_wider(names_from = year_bin, values_from = n) %>%
  replace(is.na(.), 0) %>%
  separate(
    locus,
    into = c('name', 'name2'),
    sep = '-',
    remove = F
  ) %>%
  mutate(name2 = as.integer(name2)) %>%
  arrange(name2) %>%
  dplyr::select(-contains('name')) %>%
  write_csv(paste0(basedir,
                   'chapter_3_exports/af_sample_size.csv'))

# Calculate annual allele frequency change per locus
af_out <- tibble()
for (loc_in in unique(fst_test$locus)) {
  set.seed(1)
  af_temp <- filter(fst_test,
                    locus == loc_in) %>%
    group_by(year_bin) %>%
    filter(n() >= min_n) %>%
    slice_sample(n = min_n) %>%
    ungroup() %>%
    dplyr::select(locus,
                  GENID_duplicate,
                  genoty,
                  year_bin) %>%
    pivot_wider(names_from = locus,
                values_from = genoty) %>%
    filter(!is.na(.[[3]])) %>%
    separate(loc_in, into = c('a', 'b')) %>%
    pivot_longer(-c(GENID_duplicate,
                    year_bin))
  
  af_in <- af_temp %>%
    mutate(alidx = if_else(value == unique(af_temp$value)[1],
                           1,
                           0)) %>%
    group_by(year_bin) %>%
    summarise(af = mean(alidx)) %>%
    ungroup() %>%
    arrange(year_bin) %>%
    mutate(
      year_start = as.numeric(str_sub(year_bin,
                                      1,
                                      4)),
      gen_diff = (year_start - lag(year_start)) / 3,
      af_diff = abs(af - lag(af)) / gen_diff,
      loc = loc_in
    ) %>%
    filter(between(gen_diff, 1, 2))
  
  af_out <- bind_rows(af_out, af_in)
}

af_out <- af_out %>%
  mutate(
    loc_name = if_else(str_detect(loc,
                                  'neutral'),
                       ' Neutral',
                       loc),
    neut_af = if_else(loc_name == ' Neutral',
                      af_diff,
                      NA)
  )

# individually test each of the years to see if putatively adaptive loci are part of the distribution (sqrt makes it normal)
pv_out <- tibble()
for (year_grp in unique(af_out$year_start)) {
  dist_in <- af_out %>%
    filter(year_start == year_grp)
  
  # calculate quantiles
  # adapt_loci<-c("lg19-1","lg19-4","lg19-2","lg6-5","lg19-3","lg7-6")
  # adapt_quantiles<-ecdf(filter(dist_in,
  #                              loc_name == ' Neutral')$af_diff)(filter(dist_in,
  #                                                                      loc_name %in% adapt_loci)$af_diff)
  
  # run p-value test
  pnrom_in <- dist_in %>%
    group_by(loc_name) %>%
    summarise(mn = mean(sqrt(af_diff)),
              sd = sd(sqrt(af_diff)))
  
  pv_out <- pnrom_in %>%
    mutate(pv = 1 - pnorm(mn, pnrom_in$mn[1], pnrom_in$sd[1])) %>%
    filter(loc_name != 'Neutral') %>%
    mutate(yr = unique(dist_in$year_bin)) %>%
    bind_rows(pv_out)
}

# Plot the results
sigs <- pv_out %>%
  mutate(sig = if_else(pv < 0.01, '***',
                       if_else(pv < 0.05, '**',
                               if_else(pv < 0.1, '*', NA)))) %>%
  filter(!is.na(sig))

n_year <- af_out %>%
  group_by(year_bin) %>%
  tally()

af_out %>%
  ggplot() +
  geom_jitter(
    aes(year_bin,
        neut_af),
    height = 0,
    width = 0.1,
    alpha = 0.1,
    color = "#1B9E77"
  ) +
  geom_boxplot(aes(year_bin,
                   af_diff,
                   color = loc_name),
               outlier.shape = NA) +
  geom_text(data = n_year,
            aes(x = year_bin,
                y = -0.04,
                label = n),
            size = 4) +
  geom_text(data = sigs,
            aes(x = yr,
                y = -0.1,
                label = sig),
            size = 5) +
  theme_cowplot() +
  theme(axis.text.x = element_text(
    angle = 45,
    vjust = 1,
    hjust = 1
  )) +
  scale_color_brewer(palette = 'Dark2') +
  labs(x = 'Capture year', y = 'Allele frequency change per generation', color = '')
ggsave(paste0(basedir,
              'chapter_3_exports/neutral_adaptive_af.png'),
  height = 5,
  width = 8
)

# For the text, get the quantiles of years that exceed the normal distribution
pv_out %>%
  filter(pv < 0.1)
```

## run SLiM to get range of potential selection coefficients
```{r}
# number of generations between lcwgs scans
dat_in<-filter(phenos, # filter dataset
               !is.na(mature),
               !is.na(predict_age)) 

mod<-glm(mature ~ predict_age, # build GLM
         family = binomial, 
         data = dat_in)

MASS::dose.p(mod, # get dosage
             p=c(0.25, 
                 0.5, 
                 0.75)) %>% 
  tibble() %>% 
  mutate(gens = round((2019-2000)/`.`, 0))

af_change$af_2000 # list of starting AF to iterate over
mean(af_change$n_2019)# subsample 2019 individuals genotyped

# amplicon panel allele frequency change


# A_maf# actual Ne
# however, the jorde-ryman two-sample estimator is 59-79, so lets go with 69

```

run SLiM
```{bash}
cd slim

rm output.txt
for rep in {1..100}
  do
  for starting_frequency in 0.39 0.29 0.17 0.28
    do
    for selection_coefficient in $(seq 0 0.1 1)
      do
      /programs/SLiM/slim \
      -d selCoeff=$selection_coefficient \
      -d rep=$rep \
      -d Initial_AF=$starting_frequency \
      -d Subset_N=23 \
      sweep_code_v3.slim
    done
  done
done
```

plot results
```{r}
read_tsv("/workdir/smallmouth/slim/output.txt",
         col_names = c('rep', 
                       'selCoeff', 
                       'af_2000', 
                       'af_2019_simulated')) %>% 
  mutate(af_2019_simulated = replace_na(af_2019_simulated, 
                               0)) %>% # lost mutations go to NA rather than 0
  left_join(af_change,
            by = "af_2000") %>% 
  mutate(snp_facet = letters[as.integer(as.factor(snp))])  %>% 
  ggplot(aes(selCoeff, 
             af_2019_simulated, 
             group = selCoeff)) +
  geom_boxplot() +
  geom_point(alpha = 0.1) +
  geom_hline(aes(yintercept = af_2019),
             color = 'green') +
  geom_hline(aes(yintercept = af_2000),
             color = 'blue') +
  facet_wrap(~snp_facet) +
  labs(x = 'Selection coefficient',
       y = 'Allele frequency') +
  theme_cowplot()  +
  theme(strip.background = element_blank(),
        strip.text = element_text(hjust = 0,
                                  face='bold'))

ggsave(paste0(basedir,
              'chapter_3_exports/slim_output.png'), 
       height = 5, 
       width = 10)
```



# Misc paper stats

How many fish are removed each year?
```{r}
allFish %>%
  filter(WATER == 'LML', GEAR == 'BEF', between(year, 2000, 2020)) %>%
  group_by(year) %>%
  tally() %>%
  ggplot(aes(year, n)) +
  geom_point() +
  geom_line() +
  labs(x = 'year', y = 'bass removed per year') +
  theme_cowplot()
```

Are there consistent biases in fresh : frozen weights or legnths? 1998/9 bass were measured fresh
```{r}
# Weight
fresh %>%
  ggplot(aes(Weight_g, weight_fresh_frozen)) +
  geom_point() +
  geom_smooth(method = 'lm')

summary(lm(WEIGHT ~ Weight_g, data = fresh))

# Length
fresh %>%
  left_join(allFish, by = 'FISH_N') %>%
  ggplot(aes(Length_mm, length_fresh_frozen)) +
  geom_point() +
  geom_smooth(method = 'lm')

summary(lm(LENGTH ~ Length_mm, data = fresh))

fresh %>% 
  dplyr::select(Water,
                Date,
                FISH_N,
                Length_frozen=LENGTH,
                Length_fresh=Length_mm,
                Weight_frozen=WEIGHT,
                Weight_fresh=Weight_g) %>% 
  write_csv('/workdir/smallmouth/chapter_3_exports/fresh_frozen.csv')
```

how many fish in the gtseq panel?
```{r}
genos %>% # genos for final filtered numbers, phenos for input number of individual
  group_by(GENID_duplicate) %>% 
  summarise(n=n()) %>% 
  left_join(phenos, by = 'GENID_duplicate') %>% 
  filter(WATER == 'LML') %>% 
  group_by(year) %>% 
  summarise(prop_loci = mean(n)/94,
            n = n()) %>% 
  ggplot(aes(year, n)) +
  geom_vline(xintercept = 2000.5, lty = 'dashed') +
  geom_label(aes(label = n, fill = prop_loci), size = 2) +
  labs(x='year', y = 'number of fish\ngenotyped (GTseq)', fill = 'proportion\nloci\nsuccessful') 

ggsave(paste0(basedir,
              'chapter_3_exports/n_per_year_lml.png'), 
       height = 3, 
       width = 8)
```

table with sample size for each of our analyses
```{r}
allFish %>% 
  filter(WATER == 'LML', month < 7) %>% 
  dplyr::select(LENGTH, WEIGHT, ageTrue, newGSI, sex) %>% 
  map(~sum(!is.na(.)))

filter(phenos, GENID_duplicate %in% genos$GENID_duplicate) %>% 
  filter(WATER == 'LML', month < 7) %>% 
  dplyr::select(LENGTH, WEIGHT, ageTrue, newGSI, sex) %>% 
  map(~sum(!is.na(.)))
```

What is the allele frequency change in background regions vs three adaptive peaks?
```{r}
fst_adaptive<-read_csv(paste0(basedir,
                              'chapter_3_exports/fst_window_A_D.csv')) %>% 
  mutate(adaptive = if_else((name==19 & between(pos, 1.05e07, 2.8e07) | (name==6 & between(pos, 0.2e07, 0.5e07) | (name==7 & between(pos, 2.3e7, 2.6e7)))), 1, 0))

fst_adaptive %>% 
  group_by(adaptive) %>% 
  summarise(median_af = median(fst_mean),
            sd_af = sd(fst_mean))

fst_adaptive %>% 
  filter(fst_mean>0.2)

ggplot(aes(pos, fst_mean, color = adaptive)) +
  geom_point() +
  facet_wrap(~name)
```

Coverage and proportion of reference covered for lcwgs and amplicon
```{r}
# lcwgs pre-filter
read_csv("/workdir/smallmouth/sample_lists/full_read_count.csv") %>% 
  mutate(raw_depth=raw_bases/829000000) %>% 
  filter(str_detect(population, 'Little')) %>% 
  summarise(min(raw_depth), max(raw_depth))

# lcwgs post-filter
read_tsv("/workdir/smallmouth/sample_lists/bam_list_realigned_smb_anchored_mincov_filtered_depth_per_position_per_sample_summary.tsv") %>% 
  filter(str_detect(str_sub(sample_seq_id, 1,1), 'A|D')) %>% 
  summarise(maxdp = max(mean_depth),
            mindp = min(mean_depth),
            mmaxref = max(proportion_of_reference_covered),
            minref = min(proportion_of_reference_covered))

# amplicon
genos %>% 
  summarise(max(read_depth),
            min(read_depth),
            mean(read_depth),
            sd(read_depth))
```

# Submit sequences to NCBI

I've taken all the raw lcwgs files and added them to lcwgs_smb/all_raw
```{bash}
cd /workdir/backup/smallmouth/lcwgs_smb
ftp ftp-private.ncbi.nlm.nih.gov
# username: subftp
# pass: SniappegEtnurak3
cd uploads/zarriliam_gmail.com_GvUkLsf4
mkdir lcwgs_submission
cd lcwgs_submission
put ... # it would seem that I need to upload them individually. in the future, I should gzip all into a single file then upload that
```
